{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","mount_file_id":"10gXLmQ27fIVCJjdNzGlA_BCK4__lOpvQ","authorship_tag":"ABX9TyMsrS0C9cQgCTjoff2IPm4G"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**RNNs** : Used for sequential data processing. like languages, where there is a need of saving the memory or history of old data. Codebasics ne better samjhaya hai apne video me."],"metadata":{"id":"TiEdidJVPfEO"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.datasets import mnist"],"metadata":{"id":"P54z9SmMPnx7","executionInfo":{"status":"ok","timestamp":1706601660298,"user_tz":-330,"elapsed":12622,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["physical_devices = tf.config.list_physical_devices('GPU')\n","\n","if physical_devices:\n","  tf.config.experimental.set_memory_growth(physical_devices[0],True)\n","  print(\"GPU found and being used\")\n","else:\n","  print(\"Using CPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v2Rvxn0LP5mK","executionInfo":{"status":"ok","timestamp":1706601662632,"user_tz":-330,"elapsed":515,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"12714ec1-e9fb-4e9c-9319-6380d2256f86"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Using CPU\n"]}]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A5CWRxqsQaBa","executionInfo":{"status":"ok","timestamp":1706601670314,"user_tz":-330,"elapsed":1436,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"33769b7c-8bf3-491c-8052-fe0c5f8c7132"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["x_train.dtype"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_Ke2udlqQq_2","executionInfo":{"status":"ok","timestamp":1706601690296,"user_tz":-330,"elapsed":6,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"9709faa6-b1fc-4bbc-b32e-164cd3f72c0a"},"execution_count":4,"outputs":[{"output_type":"execute_result","data":{"text/plain":["dtype('uint8')"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["type(x_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fbAWGio-QuWJ","executionInfo":{"status":"ok","timestamp":1706601692090,"user_tz":-330,"elapsed":7,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"3d3014b7-4b08-4500-bf49-af6fee6f2206"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["x_train.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hb_Got8mQwzC","executionInfo":{"status":"ok","timestamp":1706601697629,"user_tz":-330,"elapsed":380,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"d0f3d45f-6f1d-4182-d98b-f9e4876b075e"},"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["type(y_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hBH9Egw8Qzvt","executionInfo":{"status":"ok","timestamp":1706601700693,"user_tz":-330,"elapsed":367,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"91438306-0aed-4a58-c267-9f58c2bcea5e"},"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["numpy.ndarray"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["y_train.shape  # 60,000 1D arrays"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XuM4rBY0Q3NE","executionInfo":{"status":"ok","timestamp":1706601702036,"user_tz":-330,"elapsed":4,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"aaf6871c-1ab2-4c1c-bdbd-cdab3c36ca2c"},"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000,)"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["x_train[0] # first image out of 60,000 images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNmm-5YUQ5E-","executionInfo":{"status":"ok","timestamp":1706601704401,"user_tz":-330,"elapsed":6,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"428bb4ee-a347-489b-8e7c-53c9b4561550"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n","        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n","        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n","        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n","        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n","         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n","        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n","        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n","        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n","        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n","        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n","        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n","        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n","         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["x_train[0].shape # 2D array of 28*28 shape : as expected since grayscale"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"haLAdfpXRSda","executionInfo":{"status":"ok","timestamp":1706601714581,"user_tz":-330,"elapsed":356,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"40cf168e-9b1f-4790-cc91-e69b7a3e223c"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["y_train[0] # scaler."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JP7r4MGJRk-_","executionInfo":{"status":"ok","timestamp":1706601716255,"user_tz":-330,"elapsed":3,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"1a959a40-e2cf-4e2b-d4cf-48f9b4f9a63d"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["y_train # 1D array"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MZBGdamORudl","executionInfo":{"status":"ok","timestamp":1706601718261,"user_tz":-330,"elapsed":2,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"03aa0470-4c64-4496-cd37-9a7c51dbeb82"},"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["x_train = x_train.astype(\"float32\")/255.0\n","x_test = x_test.astype(\"float32\")/255.0\n","# normalization pixel values between 0 and 1. This is super use of numpy , kaise sare elements pr apply ho jayega"],"metadata":{"id":"dHacQnjoRwgS","executionInfo":{"status":"ok","timestamp":1706601722550,"user_tz":-330,"elapsed":625,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["model = keras.Sequential()\n","model.add(keras.Input(shape=(None,28)))\n","model.add(\n","    layers.SimpleRNN(512, return_sequences=True, activation='relu') # output of this rnn 512 nodes\n",")\n","model.add(layers.SimpleRNN(512, activation='relu'))\n","model.add(layers.Dense(10))"],"metadata":{"id":"m_LT-wncSB9C","executionInfo":{"status":"ok","timestamp":1706601725733,"user_tz":-330,"elapsed":824,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RKjT89z-S8aj","executionInfo":{"status":"ok","timestamp":1706601731682,"user_tz":-330,"elapsed":449,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"b11f7079-eb54-45d5-9542-cdc21eaeb19f"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," simple_rnn (SimpleRNN)      (None, None, 512)         276992    \n","                                                                 \n"," simple_rnn_1 (SimpleRNN)    (None, 512)               524800    \n","                                                                 \n"," dense (Dense)               (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 806922 (3.08 MB)\n","Trainable params: 806922 (3.08 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), # since upar softmax nhi kiya\n","    optimizer = keras.optimizers.Adam(lr=0.001),\n","    metrics=['accuracy']\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H5qY6BZITAxN","executionInfo":{"status":"ok","timestamp":1704790455087,"user_tz":-330,"elapsed":20,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"73ef6ddf-b795-4509-d31e-add1d5f879f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]}]},{"cell_type":"code","source":["model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n","\n","model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Vy-Qt53IT1q0","executionInfo":{"status":"ok","timestamp":1704790902129,"user_tz":-330,"elapsed":447055,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"5a63d7b8-727c-44ea-c567-b40a469ef84f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","938/938 - 46s - loss: 0.3244 - accuracy: 0.9005 - 46s/epoch - 49ms/step\n","Epoch 2/10\n","938/938 - 43s - loss: 0.1348 - accuracy: 0.9626 - 43s/epoch - 46ms/step\n","Epoch 3/10\n","938/938 - 43s - loss: 0.1150 - accuracy: 0.9693 - 43s/epoch - 46ms/step\n","Epoch 4/10\n","938/938 - 43s - loss: 0.1090 - accuracy: 0.9714 - 43s/epoch - 46ms/step\n","Epoch 5/10\n","938/938 - 43s - loss: 0.1086 - accuracy: 0.9700 - 43s/epoch - 46ms/step\n","Epoch 6/10\n","938/938 - 43s - loss: 0.0807 - accuracy: 0.9776 - 43s/epoch - 46ms/step\n","Epoch 7/10\n","938/938 - 43s - loss: 0.0783 - accuracy: 0.9789 - 43s/epoch - 46ms/step\n","Epoch 8/10\n","938/938 - 43s - loss: 0.0755 - accuracy: 0.9797 - 43s/epoch - 46ms/step\n","Epoch 9/10\n","938/938 - 43s - loss: 0.0795 - accuracy: 0.9780 - 43s/epoch - 46ms/step\n","Epoch 10/10\n","938/938 - 43s - loss: 0.0622 - accuracy: 0.9829 - 43s/epoch - 46ms/step\n","313/313 [==============================] - 3s 7ms/step - loss: 0.1003 - accuracy: 0.9737\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.10033776611089706, 0.9736999869346619]"]},"metadata":{},"execution_count":20}]},{"cell_type":"markdown","source":["Recurrent Neural Networks (RNNs) are a type of neural network designed for sequential data processing. They have a form of memory that allows them to capture information from previous time steps, making them suitable for tasks like natural language processing, speech recognition, and time series prediction.\n","\n","Now, let's break down the code and the output:\n","\n","```python\n","model = keras.Sequential()\n","```\n","\n","This creates a sequential model using Keras, a high-level neural networks API. A sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.\n","\n","```python\n","model.add(keras.Input(shape=(None, 28)))\n","```\n","\n","This line adds the input layer to the model. The `shape=(None, 28)` indicates that the input has a variable length (None) along the time axis (assuming sequential data) and each time step has 28 features.\n","\n","The 'None' in the input shape means that the model can handle sequences of variable length. This is useful when working with sequences of different lengths, and the model will automatically adapt to the length of the input sequences during training and inference.\n","\n","```python\n","model.add(layers.SimpleRNN(512, return_sequences=True, activation='relu'))\n","```\n","\n","This line adds a SimpleRNN layer to the model with 512 units (nodes), the `return_sequences=True` parameter means that this layer returns the full sequence of outputs for each input sequence. The activation function used is ReLU.\n","\n","```python\n","model.add(layers.SimpleRNN(512, activation='relu'))\n","```\n","\n","This line adds another SimpleRNN layer with 512 units, but without `return_sequences=True`, meaning it only returns the output of the last time step in the sequence.\n","\n","```python\n","model.add(layers.Dense(10))\n","```\n","\n","This adds a dense (fully connected) layer with 10 units, which is the output layer since the MNIST dataset has 10 classes (digits 0 through 9).\n","\n","The summary output provides a summary of the model architecture and its parameters:\n","\n","- \"None\" in the output shape for SimpleRNN layers signifies that the model can handle variable sequence lengths during training and inference.\n","- \"None\" in the input shape also indicates that the model can handle variable sequence lengths.\n","- \"Param #\" represents the number of parameters in each layer, which includes weights and biases.\n","\n","In summary, this code defines a sequential model for processing sequences of 28-dimensional vectors. It uses two SimpleRNN layers with 512 units each and a ReLU activation function, and it concludes with a Dense layer for classification. The model is suitable for tasks like sequence processing and can handle variable-length sequences."],"metadata":{"id":"8auAWsdTWl0R"}},{"cell_type":"markdown","source":["In RNN, default activation function is tanh. If likhoge nhi to tanh will be used"],"metadata":{"id":"e9ktIWo_WqEC"}},{"cell_type":"code","source":["# USING GRU LAYER INSTEAD OF Simple RNN LAYER, REST EVERYTHING KEEPING SAME\n","model = keras.Sequential()\n","model.add(keras.Input(shape=(None,28)))\n","model.add(\n","    layers.GRU(512, return_sequences=True, activation='relu') # output of this rnn 512 nodes\n",")\n","model.add(layers.GRU(512, activation='relu'))\n","model.add(layers.Dense(10))\n","\n","print(model.summary())\n","\n","model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), # since upar softmax nhi kiya\n","    optimizer = keras.optimizers.Adam(lr=0.001),\n","    metrics=['accuracy']\n",")\n","\n","model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n","\n","model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"40zrIBy3UIf9","executionInfo":{"status":"ok","timestamp":1704791947007,"user_tz":-330,"elapsed":919315,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"eaa7332a-3909-4bd7-bbe1-9d730b170e5b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer gru_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer gru_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," gru_2 (GRU)                 (None, None, 512)         832512    \n","                                                                 \n"," gru_3 (GRU)                 (None, 512)               1575936   \n","                                                                 \n"," dense_2 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 2413578 (9.21 MB)\n","Trainable params: 2413578 (9.21 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["None\n","Epoch 1/10\n","938/938 - 93s - loss: 0.2875 - accuracy: 0.9026 - 93s/epoch - 99ms/step\n","Epoch 2/10\n","938/938 - 89s - loss: 0.0662 - accuracy: 0.9805 - 89s/epoch - 95ms/step\n","Epoch 3/10\n","938/938 - 92s - loss: 0.0473 - accuracy: 0.9857 - 92s/epoch - 98ms/step\n","Epoch 4/10\n","938/938 - 89s - loss: 0.0381 - accuracy: 0.9884 - 89s/epoch - 95ms/step\n","Epoch 5/10\n","938/938 - 89s - loss: 0.0306 - accuracy: 0.9906 - 89s/epoch - 95ms/step\n","Epoch 6/10\n","938/938 - 89s - loss: 0.0268 - accuracy: 0.9916 - 89s/epoch - 95ms/step\n","Epoch 7/10\n","938/938 - 94s - loss: 0.0219 - accuracy: 0.9930 - 94s/epoch - 100ms/step\n","Epoch 8/10\n","938/938 - 91s - loss: 0.0195 - accuracy: 0.9938 - 91s/epoch - 97ms/step\n","Epoch 9/10\n","938/938 - 99s - loss: 0.0177 - accuracy: 0.9938 - 99s/epoch - 105ms/step\n","Epoch 10/10\n","938/938 - 90s - loss: 0.0153 - accuracy: 0.9949 - 90s/epoch - 96ms/step\n","313/313 [==============================] - 4s 12ms/step - loss: 0.0328 - accuracy: 0.9912\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.03284318745136261, 0.9911999702453613]"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["GRU (Gated Recurrent Unit) and LSTM (Long Short-Term Memory) are advanced types of recurrent neural network (RNN) architectures designed to address the vanishing gradient problem, which is a challenge in training traditional RNNs on long sequences.\n","\n","### GRU (Gated Recurrent Unit):\n","\n","GRU is a type of RNN that aims to simplify the architecture of LSTM while maintaining similar performance. It uses gating mechanisms to control the flow of information within the network. The key components of a GRU unit are the update gate and the reset gate, which allow the model to selectively update its memory.\n","\n","### LSTM (Long Short-Term Memory):\n","\n","LSTM is another type of RNN that is designed to overcome the vanishing gradient problem by introducing a more complex memory cell structure. LSTM units have three gates: the input gate, the forget gate, and the output gate. These gates control the flow of information, allowing the model to capture long-range dependencies in sequential data.\n","\n","### Using GRU or LSTM instead of SimpleRNN:\n","\n","If you replace `layers.SimpleRNN` with `layers.GRU` or `layers.LSTM` in your code, the main difference will be in the complexity of the model's ability to capture long-term dependencies in sequential data.\n","\n","```python\n","# Example using GRU\n","model.add(layers.GRU(512, return_sequences=True, activation='relu'))\n","\n","# Example using LSTM\n","model.add(layers.LSTM(512, return_sequences=True, activation='relu'))\n","```\n","\n","Both GRU and LSTM layers have more sophisticated mechanisms for handling information over longer sequences compared to SimpleRNN. They are particularly useful when dealing with tasks that involve learning from sequences with long-term dependencies, such as natural language processing, speech recognition, and time series prediction.\n","\n","In general, LSTMs and GRUs are preferred over SimpleRNN when working with sequential data due to their improved ability to capture and remember long-term dependencies, making them more suitable for complex tasks. However, the choice between GRU and LSTM often depends on the specific characteristics of the data and the task at hand."],"metadata":{"id":"9OOGHmGKZ1DC"}},{"cell_type":"code","source":["# USING LSTM LAYER INSTEAD OF Simple RNN LAYER, REST EVERYTHING KEEPING SAME\n","model = keras.Sequential()\n","model.add(keras.Input(shape=(None,28)))\n","model.add(\n","    layers.LSTM(512, return_sequences=True, activation='relu') # output of this rnn 512 nodes\n",")\n","model.add(layers.LSTM(512, activation='relu'))\n","model.add(layers.Dense(10))\n","\n","print(model.summary())\n","\n","model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), # since upar softmax nhi kiya\n","    optimizer = keras.optimizers.Adam(lr=0.001),\n","    metrics=['accuracy']\n",")\n","\n","model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n","\n","model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qvNWnM-YXv-r","executionInfo":{"status":"ok","timestamp":1704792695442,"user_tz":-330,"elapsed":748448,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"8ec74726-7251-40ae-ea7f-3aeb07f58f9c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, None, 512)         1107968   \n","                                                                 \n"," lstm_1 (LSTM)               (None, 512)               2099200   \n","                                                                 \n"," dense_3 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 3212298 (12.25 MB)\n","Trainable params: 3212298 (12.25 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"output_type":"stream","name":"stdout","text":["None\n","Epoch 1/10\n","938/938 - 73s - loss: 0.4506 - accuracy: 0.8543 - 73s/epoch - 78ms/step\n","Epoch 2/10\n","938/938 - 71s - loss: 0.0926 - accuracy: 0.9732 - 71s/epoch - 75ms/step\n","Epoch 3/10\n","938/938 - 89s - loss: 0.0639 - accuracy: 0.9804 - 89s/epoch - 95ms/step\n","Epoch 4/10\n","938/938 - 69s - loss: 0.0502 - accuracy: 0.9849 - 69s/epoch - 74ms/step\n","Epoch 5/10\n","938/938 - 70s - loss: 0.0407 - accuracy: 0.9875 - 70s/epoch - 75ms/step\n","Epoch 6/10\n","938/938 - 72s - loss: 0.0343 - accuracy: 0.9892 - 72s/epoch - 77ms/step\n","Epoch 7/10\n","938/938 - 78s - loss: 0.0308 - accuracy: 0.9908 - 78s/epoch - 84ms/step\n","Epoch 8/10\n","938/938 - 69s - loss: 0.0271 - accuracy: 0.9919 - 69s/epoch - 74ms/step\n","Epoch 9/10\n","938/938 - 70s - loss: 0.0227 - accuracy: 0.9931 - 70s/epoch - 75ms/step\n","Epoch 10/10\n","938/938 - 77s - loss: 0.0228 - accuracy: 0.9930 - 77s/epoch - 82ms/step\n","313/313 [==============================] - 4s 10ms/step - loss: 0.0356 - accuracy: 0.9895\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.03560495376586914, 0.9894999861717224]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["# USING LSTM LAYER + Bidirectional(one gonna forward one gonna backword) INSTEAD OF Simple RNN LAYER, REST EVERYTHING KEEPING SAME\n","model = keras.Sequential()\n","model.add(keras.Input(shape=(None,28)))\n","model.add(\n","    layers.Bidirectional(\n","        layers.LSTM(512, return_sequences=True, activation='relu') # output of this rnn 512*2 = 1024 nodes, since bidirectional hai\n","    )\n",")\n","model.add(layers.LSTM(512, activation='relu'))\n","model.add(layers.Dense(10))\n","\n","print(model.summary())\n","\n","model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True), # since upar softmax nhi kiya\n","    optimizer = keras.optimizers.Adam(learning_rate=0.001),\n","    metrics=['accuracy']\n",")\n","\n","model.fit(x_train, y_train, batch_size=64, epochs=10, verbose=2)\n","\n","model.evaluate(x_test, y_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d01kr-3NbT-9","executionInfo":{"status":"ok","timestamp":1704793746891,"user_tz":-330,"elapsed":1051471,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"49686921-d1aa-48ee-ecee-c7c3bbeb59a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n","WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," bidirectional (Bidirection  (None, None, 1024)        2215936   \n"," al)                                                             \n","                                                                 \n"," lstm_3 (LSTM)               (None, 512)               3147776   \n","                                                                 \n"," dense_4 (Dense)             (None, 10)                5130      \n","                                                                 \n","=================================================================\n","Total params: 5368842 (20.48 MB)\n","Trainable params: 5368842 (20.48 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/10\n","938/938 - 106s - loss: 0.4543 - accuracy: 0.8519 - 106s/epoch - 113ms/step\n","Epoch 2/10\n","938/938 - 103s - loss: 0.0928 - accuracy: 0.9727 - 103s/epoch - 110ms/step\n","Epoch 3/10\n","938/938 - 102s - loss: 0.2943 - accuracy: 0.9767 - 102s/epoch - 109ms/step\n","Epoch 4/10\n","938/938 - 102s - loss: 0.0560 - accuracy: 0.9833 - 102s/epoch - 108ms/step\n","Epoch 5/10\n","938/938 - 102s - loss: 0.0405 - accuracy: 0.9877 - 102s/epoch - 109ms/step\n","Epoch 6/10\n","938/938 - 101s - loss: 0.0397 - accuracy: 0.9886 - 101s/epoch - 108ms/step\n","Epoch 7/10\n","938/938 - 101s - loss: 0.0404 - accuracy: 0.9883 - 101s/epoch - 108ms/step\n","Epoch 8/10\n","938/938 - 102s - loss: 0.0263 - accuracy: 0.9920 - 102s/epoch - 109ms/step\n","Epoch 9/10\n","938/938 - 102s - loss: 0.0214 - accuracy: 0.9936 - 102s/epoch - 109ms/step\n","Epoch 10/10\n","938/938 - 102s - loss: 0.0244 - accuracy: 0.9927 - 102s/epoch - 109ms/step\n","313/313 [==============================] - 5s 15ms/step - loss: 0.0402 - accuracy: 0.9880\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.04023962467908859, 0.9879999756813049]"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["Bidirectional RNNs (Recurrent Neural Networks) are a type of RNN architecture that processes input data in both forward and backward directions. In traditional (unidirectional) RNNs, information flows only from the past to the future, but bidirectional RNNs allow the model to consider information from both the past and the future at each time step.\n","\n","The idea behind bidirectionality is to capture dependencies in both directions, which can be particularly useful in tasks where context from both past and future information is important. Examples of such tasks include natural language processing, where understanding the context of a word may depend on both preceding and succeeding words.\n","\n","In a bidirectional RNN, the hidden state at each time step is computed by considering both the information from the past (forward direction) and the future (backward direction). This is achieved by having two separate sets of hidden states: one set computed from the forward pass and the other from the backward pass. The final hidden state at each time step is typically a concatenation of the forward and backward hidden states.\n","\n","Here is a simplified example of how a bidirectional RNN is implemented using Keras:\n","\n","```python\n","from tensorflow.keras.layers import Bidirectional, LSTM\n","\n","model = Sequential()\n","model.add(Bidirectional(LSTM(64, return_sequences=True), input_shape=(None, 28)))\n","model.add(Dense(10, activation='softmax'))\n","```\n","\n","In this example, a Bidirectional wrapper is applied to an LSTM layer. The `return_sequences=True` parameter indicates that the LSTM layer should return the full sequence of outputs, and the Bidirectional wrapper ensures that the input sequence is processed in both forward and backward directions.\n","\n","Bidirectional RNNs are beneficial when the context from both directions is relevant to the task. They can capture more complex patterns and dependencies in sequential data, making them suitable for various applications, such as machine translation, sentiment analysis, and named entity recognition. However, they also come with a higher computational cost compared to unidirectional RNNs."],"metadata":{"id":"x_BjA5RudWz4"}},{"cell_type":"markdown","source":["# More in depth Example on Functional API"],"metadata":{"id":"VafJkGW83Am_"}},{"cell_type":"markdown","source":["**Multi digit dataset** (Multi digits MNIST)"],"metadata":{"id":"Ll3PVyI63TG7"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers, regularizers\n","from tensorflow.keras.datasets import mnist"],"metadata":{"id":"E4TPsvDGdXll"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"LDFUFJ-B3_Om"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Sequential can only map one input to one output. But now we are gonna have two outputs.(as 2 digits in a number)"],"metadata":{"id":"WjSuVYys6M4Y"}},{"cell_type":"markdown","source":["Extracting a zip file using python."],"metadata":{"id":"ssF4GRvJCGoF"}},{"cell_type":"code","source":["import zipfile\n","import os\n","\n","zip_file_path = '/content/drive/MyDrive/multi_digit_mnist.zip'\n","extraction_path = '/content/multi_digit_mnist'\n","\n","# Check if the extraction directory already exists\n","if not os.path.exists(extraction_path):\n","    # Create the extraction directory if it doesn't exist\n","    os.makedirs(extraction_path)\n","\n","    # Extract the contents of the ZIP file\n","    with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n","        zip_ref.extractall(extraction_path)\n","\n","    print(f\"Extracted {zip_file_path} to {extraction_path}\")\n","else:\n","    print(f\"The file at {extraction_path} already exists.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-GZv1Ix4DCm","executionInfo":{"status":"ok","timestamp":1704793760114,"user_tz":-330,"elapsed":13242,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"63306d65-8aa8-4a44-8a96-bd32efc0b27b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted /content/drive/MyDrive/multi_digit_mnist.zip to /content/multi_digit_mnist\n"]}]},{"cell_type":"code","source":["# List the contents of the extraction directory\n","contents = os.listdir(extraction_path)\n","print(f\"Contents of {extraction_path}:\")\n","for item in contents:\n","    print(item)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gNfZLSn6Cn0_","executionInfo":{"status":"ok","timestamp":1704793760116,"user_tz":-330,"elapsed":36,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"4a68b949-f33f-492d-a87d-52367837ff61"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Contents of /content/multi_digit_mnist:\n","test_images\n","test.csv\n","train_images\n","train.csv\n"]}]},{"cell_type":"markdown","source":["Checking the number of files in a directory."],"metadata":{"id":"cg5blHKNDfjF"}},{"cell_type":"code","source":["import os\n","\n","directory_path = '/content/multi_digit_mnist/test_images'\n","\n","# List all items in the directory\n","all_items = os.listdir(directory_path)\n","\n","# Initialize a count variable\n","file_count = 0\n","\n","print(len(all_items))\n","\n","# Iterate through all items and count files\n","for item in all_items:\n","    # Check if the item is a file\n","    if os.path.isfile(os.path.join(directory_path, item)):\n","        file_count += 1\n","\n","print(f\"The number of files in the directory {directory_path} is: {file_count}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uHfYkiAjC_yu","executionInfo":{"status":"ok","timestamp":1704793760116,"user_tz":-330,"elapsed":27,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"46d28219-39dd-4557-ded1-4e3690288e40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["20000\n","The number of files in the directory /content/multi_digit_mnist/test_images is: 20000\n"]}]},{"cell_type":"code","source":["import os\n","\n","directory_path = '/content/multi_digit_mnist/train_images'\n","\n","# List all items in the directory\n","all_items = os.listdir(directory_path)\n","\n","# Initialize a count variable\n","file_count = 0\n","\n","print(len(all_items))\n","\n","# Iterate through all items and count files\n","for item in all_items:\n","    # Check if the item is a file\n","    if os.path.isfile(os.path.join(directory_path, item)):\n","        file_count += 1\n","\n","print(f\"The number of files in the directory {directory_path} is: {file_count}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"k-OIbiz3D9-B","executionInfo":{"status":"ok","timestamp":1704793761027,"user_tz":-330,"elapsed":928,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"19e88116-9567-49a9-a35a-e07fe1a0e55b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["64000\n","The number of files in the directory /content/multi_digit_mnist/train_images is: 64000\n"]}]},{"cell_type":"code","source":["train_df = pd.read_csv(\"/content/multi_digit_mnist/train.csv\")\n","test_df = pd.read_csv(\"/content/multi_digit_mnist/test.csv\")"],"metadata":{"id":"1icKNoX9EKFa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGwIsxoZEkIb","executionInfo":{"status":"ok","timestamp":1704793761028,"user_tz":-330,"elapsed":61,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"87633895-03c2-4843-c24e-d3ce655cae06"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(64000, 3)"]},"metadata":{},"execution_count":32}]},{"cell_type":"code","source":["test_df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lX2loM1xEmtz","executionInfo":{"status":"ok","timestamp":1704793761028,"user_tz":-330,"elapsed":50,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"219ef473-5497-449c-c013-d70b2fb46bec"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(20000, 3)"]},"metadata":{},"execution_count":33}]},{"cell_type":"code","source":["train_df.head() # so see image 2 digits ki hai, jiske labels are given in 2 coulumns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"iE1-2Zh6EoP3","executionInfo":{"status":"ok","timestamp":1704793761029,"user_tz":-330,"elapsed":45,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"d9d4d4ae-086e-41d8-a46a-9ccee4c42187"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Image  first_num  second_num\n","0    0_00.png          0           0\n","1  100_00.png          0           0\n","2  101_00.png          0           0\n","3  102_00.png          0           0\n","4  103_00.png          0           0"],"text/html":["\n","  <div id=\"df-fe7b0f0c-8818-42f1-b1e3-b1216a73f0a2\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image</th>\n","      <th>first_num</th>\n","      <th>second_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>101_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>102_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>103_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fe7b0f0c-8818-42f1-b1e3-b1216a73f0a2')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-fe7b0f0c-8818-42f1-b1e3-b1216a73f0a2 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-fe7b0f0c-8818-42f1-b1e3-b1216a73f0a2');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-9907acee-4fd6-4473-ac5c-e3bb78f86dd0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9907acee-4fd6-4473-ac5c-e3bb78f86dd0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-9907acee-4fd6-4473-ac5c-e3bb78f86dd0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["test_df.tail()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"AhmGeUrREp6P","executionInfo":{"status":"ok","timestamp":1704793761029,"user_tz":-330,"elapsed":40,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"acc01c2e-7c28-407f-a3e2-5163505023d6"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["            Image  first_num  second_num\n","19995  997_96.png          9           6\n","19996  998_96.png          9           6\n","19997  999_96.png          9           6\n","19998   99_96.png          9           6\n","19999    9_96.png          9           6"],"text/html":["\n","  <div id=\"df-d9db77e9-a248-4162-8575-a85a28bacc0c\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image</th>\n","      <th>first_num</th>\n","      <th>second_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>19995</th>\n","      <td>997_96.png</td>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19996</th>\n","      <td>998_96.png</td>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19997</th>\n","      <td>999_96.png</td>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19998</th>\n","      <td>99_96.png</td>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19999</th>\n","      <td>9_96.png</td>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d9db77e9-a248-4162-8575-a85a28bacc0c')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-d9db77e9-a248-4162-8575-a85a28bacc0c button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-d9db77e9-a248-4162-8575-a85a28bacc0c');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-fa6e7190-d868-4037-bdf7-82b4ae90d70d\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-fa6e7190-d868-4037-bdf7-82b4ae90d70d')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-fa6e7190-d868-4037-bdf7-82b4ae90d70d button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["Let's open some image, check their properties present in some directory using python."],"metadata":{"id":"Fz4BWGAqGQ1M"}},{"cell_type":"code","source":["# 1. Using PIL\n","\n","from PIL import Image, ImageShow\n","import os\n","\n","image_path = '/content/multi_digit_mnist/train_images/0_04.png'  # Replace with your image file path\n","\n","# Open the image\n","img = Image.open(image_path)\n","\n","# Get image properties\n","image_format = img.format\n","image_mode = img.mode\n","image_size = img.size\n","\n","# Display the image\n","img.show()\n","\n","# Print the properties\n","print(f\"Image format: {image_format}\")\n","print(f\"Image mode: {image_mode}\")\n","print(f\"Image size: {image_size}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JeP56oxMGYgu","executionInfo":{"status":"ok","timestamp":1704793761029,"user_tz":-330,"elapsed":38,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e74d5fd9-b5b1-437a-a74c-b0b09c174fe4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image format: PNG\n","Image mode: L\n","Image size: (64, 64)\n"]}]},{"cell_type":"markdown","source":["The output you provided indicates the properties of the image you loaded using PIL (Pillow):\n","\n","- `Image format: PNG`: This tells you that the format of the image is PNG.\n","- `Image mode: L`: The mode 'L' stands for \"Luminance,\" which means the image is grayscale (single-channel).\n","- `Image size: (64, 64)`: The size of the image is 64 pixels by 64 pixels.\n","\n","Regarding the issue with not being able to see the image using `img.show()`, when working in certain environments, such as Google Colab or some Jupyter notebooks, the `show()` method may not display the image as expected. Instead, you can use Matplotlib to display the image:\n","\n","```python\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","image_path = '/content/multi_digit_mnist/train_images/0_04.png'  # Replace with your image file path\n","\n","# Open the image\n","img = Image.open(image_path)\n","\n","# Get image properties\n","image_format = img.format\n","image_mode = img.mode\n","image_size = img.size\n","\n","# Display the image using Matplotlib\n","plt.imshow(img, cmap='gray')  # Assuming it's a grayscale image\n","plt.axis('off')  # Turn off axis labels\n","plt.show()\n","\n","# Print the properties\n","print(f\"Image format: {image_format}\")\n","print(f\"Image mode: {image_mode}\")\n","print(f\"Image size: {image_size}\")\n","```\n","\n","This code uses Matplotlib to display the image. The `plt.imshow()` function is used to show the image, and `plt.axis('off')` is used to turn off axis labels. Make sure you have Matplotlib installed (`pip install matplotlib`) if you haven't already. This should display the image in your environment."],"metadata":{"id":"1HIR_gmJHTMc"}},{"cell_type":"code","source":["from PIL import Image\n","import matplotlib.pyplot as plt\n","\n","image_path = '/content/multi_digit_mnist/train_images/0_04.png'  # Replace with your image file path\n","\n","# Open the image\n","img = Image.open(image_path)\n","\n","# Get image properties\n","image_format = img.format\n","image_mode = img.mode\n","image_size = img.size\n","\n","# Display the image using Matplotlib\n","plt.imshow(img, cmap='gray')  # Assuming it's a grayscale image\n","plt.axis('off')  # Turn off axis labels\n","plt.show()\n","\n","# Print the properties\n","print(f\"Image format: {image_format}\")\n","print(f\"Image mode: {image_mode}\")\n","print(f\"Image size: {image_size}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":458},"id":"lZpK_kkgHVHy","executionInfo":{"status":"ok","timestamp":1704793761030,"user_tz":-330,"elapsed":30,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"137d2ffa-77d9-4522-bca2-efbbdebf4acc"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Image format: PNG\n","Image mode: L\n","Image size: (64, 64)\n"]}]},{"cell_type":"markdown","source":["For RGB, image mode = RGB"],"metadata":{"id":"Ji96F6bWHpEh"}},{"cell_type":"code","source":["# Using cv2 doing the same\n","\n","import cv2\n","import os\n","\n","image_path = '/content/multi_digit_mnist/test_images/143_80.png'  # Replace with your image file path\n","\n","# Read the image\n","img = cv2.imread(image_path)\n","\n","# Get image properties\n","image_height, image_width, image_channels = img.shape\n","\n","# Display the image\n","# cv2.imshow('Image', img) # won't work in colab\n","from google.colab.patches import cv2_imshow as show_image\n","show_image(img) # also arguments 2 ki jagah 1 hi lagega.\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n","\n","# Print the properties\n","print(f\"Image width: {image_width}\")\n","print(f\"Image height: {image_height}\")\n","print(f\"Number of channels: {image_channels}\") # will show 3, altough it is 1 only. As by default cv2 assumes BGR image\n","\n","# yhan matplotlib ka use nhi hua show krne me, as colab ne alag function diya hai cv2_imshow()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":133},"id":"o1wf9S3kHuT5","executionInfo":{"status":"ok","timestamp":1704793761977,"user_tz":-330,"elapsed":974,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"6408f86d-ae96-485c-8736-5030066abb3f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<PIL.Image.Image image mode=RGB size=64x64>"],"image/png":"iVBORw0KGgoAAAANSUhEUgAAAEAAAABACAIAAAAlC+aJAAACQklEQVR4nO2Wv8rqMBjGcw4H3bwCb6D0Btyardu3lC6uLnYRHJwEm66KILkBt4JIFa+gHRwcFRwE0QsJwZyhfCHHFv8l33eOnPc3NU375nmT90mCEAAAAAAAAAAAAAAAAAAAwNsym80455fLhXNOKa3Van9b0TPYtr1erxljnHPGGGNsOBy+Uw5hGOa6ZQKMMUrpI//+/GpxL9Nutx/57N9NACG0Wq3MBMIYE0LST4QQQghCiH7kj48PrpCbWHI8Huv1uu4YUnERzRxc11WL/soDeTOO49tB7pQQxhhjnD9HUfRDQUc6xjgMw+l0qhMk59ft7jRN8wdVcT68zqiO4/T7fdmcz+eLxQIhNJvNng31kImjKFKbYRjKZTHC4XBIkiRJkmKX67pBELweuljr0hJycZ7F931p0/1+PxqNZJdt26qJhRCc88FgoJuAECJvYozlm5cXwfd9adOrrlarFcfxdruVJj6fz57n3Yh2p4SyLJPSEUKy9LMsk10GqVQqzWZzuVzKN5vNprS0nqB0G9UJqK7AeDwufqDeLHS3UVRwcOmblwmCQPXAFafTqdfrGRiGEKJOv/4WRAhRj15Kqf1Jt9tVLW5APSpU0cv7j6T0+lls3licJ7iafiOXCMdxdrvd3QQMqEfK9OeiTS1Co9HwPO9GAp1Ox4B6dfrz0jeyEUksy7Isi1KqJjCZTCzLqlarutFLjy2zCXwtV7cGjLH+PeJbKXrXiIO/j9Iz+G3Uoz89kKbpO0kHAAAAAAD4P/gNOMjAdZjv1tQAAAAASUVORK5CYII=\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Image width: 64\n","Image height: 64\n","Number of channels: 3\n"]}]},{"cell_type":"markdown","source":["The discrepancy between the reported number of channels in PIL (Pillow) and OpenCV might be due to how the image is encoded or saved.\n","\n","When you open an image using OpenCV (`cv2.imread()`), OpenCV may interpret a single-channel (grayscale) image as having three channels. This is because OpenCV loads images in BGR (Blue, Green, Red) order by default, and it assumes that even a grayscale image has three channels (though the values in each channel are the same).\n","\n","Here's how you can check and print the number of channels using OpenCV:\n","\n","```python\n","import cv2\n","\n","image_path = '/content/multi_digit_mnist/test_images/143_80.png'  # Replace with your image file path\n","\n","# Read the image\n","img = cv2.imread(image_path)\n","\n","# Get image properties\n","image_height, image_width, image_channels = img.shape\n","\n","# Print the properties\n","print(f\"Image width: {image_width}\")\n","print(f\"Image height: {image_height}\")\n","print(f\"Number of channels: {image_channels}\")\n","```\n","\n","If the reported number of channels is 3, it means OpenCV is treating the image as a BGR image, even if it's grayscale. You can use `cv2.cvtColor()` to convert it explicitly to grayscale:\n","\n","```python\n","# Convert BGR image to grayscale\n","gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","```\n","\n","Now, `gray_img` will be a true grayscale image, and `cv2.imshow()` will display it correctly:\n","\n","```python\n","# Display the grayscale image\n","cv2.imshow('Gray Image', gray_img)\n","cv2.waitKey(0)\n","cv2.destroyAllWindows()\n","```\n","\n","This should help you handle grayscale images consistently in OpenCV."],"metadata":{"id":"vpcEE8nYJ_LX"}},{"cell_type":"code","source":["from PIL import Image, ImageShow\n","import os\n","\n","image_path = '/content/multi_digit_mnist/test_images/143_80.png'  # Replace with your image file path\n","\n","# Open the image\n","img = Image.open(image_path)\n","\n","# Get image properties\n","image_format = img.format\n","image_mode = img.mode # this shows L for the same image cv2, says 3 channels, because cv2 assumes by default 3 channels : BGR\n","image_size = img.size\n","\n","\n","# Print the properties\n","print(f\"Image format: {image_format}\")\n","print(f\"Image mode: {image_mode}\")\n","print(f\"Image size: {image_size}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"95OVTMfTI_ai","executionInfo":{"status":"ok","timestamp":1704793761978,"user_tz":-330,"elapsed":89,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"fc7ee046-355d-411c-f3dd-a70601cfcb12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Image format: PNG\n","Image mode: L\n","Image size: (64, 64)\n"]}]},{"cell_type":"code","source":["os.getcwd() # pwd deta hai bs"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"SYfpsY4rE0pA","executionInfo":{"status":"ok","timestamp":1704793761978,"user_tz":-330,"elapsed":83,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"47e232b8-bd59-4270-b53b-d96fd4d95224"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/content'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","source":["So kafi visulaizations to revise ho gye."],"metadata":{"id":"yoTSqO8GMP5M"}},{"cell_type":"code","source":["train_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"bIW1TQiLFAI3","executionInfo":{"status":"ok","timestamp":1704793761978,"user_tz":-330,"elapsed":81,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"3343acb5-6c28-454e-8683-f72a92681f28"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Image  first_num  second_num\n","0    0_00.png          0           0\n","1  100_00.png          0           0\n","2  101_00.png          0           0\n","3  102_00.png          0           0\n","4  103_00.png          0           0"],"text/html":["\n","  <div id=\"df-600bd3ad-8625-4254-84f1-6321b6c7f72e\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image</th>\n","      <th>first_num</th>\n","      <th>second_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>101_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>102_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>103_00.png</td>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-600bd3ad-8625-4254-84f1-6321b6c7f72e')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-600bd3ad-8625-4254-84f1-6321b6c7f72e button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-600bd3ad-8625-4254-84f1-6321b6c7f72e');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0bb20d4b-e9a6-4073-95f7-2435e9c943e0\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0bb20d4b-e9a6-4073-95f7-2435e9c943e0')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0bb20d4b-e9a6-4073-95f7-2435e9c943e0 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":41}]},{"cell_type":"code","source":["test_df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"UrlJSL7GMr-t","executionInfo":{"status":"ok","timestamp":1704793761979,"user_tz":-330,"elapsed":81,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"1d352973-4815-4e03-ba36-50daa2c6f973"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Image  first_num  second_num\n","0    0_02.png          0           2\n","1  100_02.png          0           2\n","2  101_02.png          0           2\n","3  102_02.png          0           2\n","4  103_02.png          0           2"],"text/html":["\n","  <div id=\"df-c53eb32b-355a-4f7d-8c8c-8c06418a840b\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Image</th>\n","      <th>first_num</th>\n","      <th>second_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0_02.png</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>100_02.png</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>101_02.png</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>102_02.png</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>103_02.png</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c53eb32b-355a-4f7d-8c8c-8c06418a840b')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-c53eb32b-355a-4f7d-8c8c-8c06418a840b button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-c53eb32b-355a-4f7d-8c8c-8c06418a840b');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-c96bcb1c-09f8-4bde-bc44-ac6a848e79c5\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c96bcb1c-09f8-4bde-bc44-ac6a848e79c5')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-c96bcb1c-09f8-4bde-bc44-ac6a848e79c5 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":42}]},{"cell_type":"code","source":["train_df.iloc[:,0] # all rows , but 0th column only"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GtMYO4ZMu4h","executionInfo":{"status":"ok","timestamp":1704793761979,"user_tz":-330,"elapsed":79,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"cc9a6c2a-dd1d-4289-8ee7-711d063b6b0d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0          0_00.png\n","1        100_00.png\n","2        101_00.png\n","3        102_00.png\n","4        103_00.png\n","            ...    \n","63995    997_98.png\n","63996    998_98.png\n","63997    999_98.png\n","63998     99_98.png\n","63999      9_98.png\n","Name: Image, Length: 64000, dtype: object"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":["train_df.iloc[:,1] # all rows but first column(index wise) only"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Dq0kLuhOhHf","executionInfo":{"status":"ok","timestamp":1704793761979,"user_tz":-330,"elapsed":75,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"86eb18b0-07b0-44ba-d4d4-7792e6349843"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        0\n","1        0\n","2        0\n","3        0\n","4        0\n","        ..\n","63995    9\n","63996    9\n","63997    9\n","63998    9\n","63999    9\n","Name: first_num, Length: 64000, dtype: int64"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["train_df.iloc[:,2] # all rors and second column only"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7ErGwUUMOm-R","executionInfo":{"status":"ok","timestamp":1704793761979,"user_tz":-330,"elapsed":70,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"08042a37-7c13-4607-d90c-b62dbafedfed"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0        0\n","1        0\n","2        0\n","3        0\n","4        0\n","        ..\n","63995    8\n","63996    8\n","63997    8\n","63998    8\n","63999    8\n","Name: second_num, Length: 64000, dtype: int64"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["these train_df.iloc[:,0] , train_df.iloc[:,1] and train_df.iloc[:,2] all are pandas dataframe"],"metadata":{"id":"CqIxY0CuO4K3"}},{"cell_type":"code","source":["train_df.iloc[:,0].values"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zGLeVAfLOxsk","executionInfo":{"status":"ok","timestamp":1704793761979,"user_tz":-330,"elapsed":65,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"5246ba28-b7f6-4633-fb37-bf3fdc6a7f70"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['0_00.png', '100_00.png', '101_00.png', ..., '999_98.png',\n","       '99_98.png', '9_98.png'], dtype=object)"]},"metadata":{},"execution_count":46}]},{"cell_type":"markdown","source":["it is now numpy array. Juct .values() badha dene ka kamal"],"metadata":{"id":"xeY3htQ7PIXJ"}},{"cell_type":"code","source":["train_df.iloc[:,1].values # full column is now converted into a 1D list, more accuratlt 1D numpy array"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WELtLLC6PHI7","executionInfo":{"status":"ok","timestamp":1704793761979,"user_tz":-330,"elapsed":60,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"3bc1d146-0a65-4f12-886b-fde03c8db07e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, ..., 9, 9, 9])"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":["train_df.iloc[:,1:] # all rows, and all the columns from index 1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"6iWyb62KPSje","executionInfo":{"status":"ok","timestamp":1704793761980,"user_tz":-330,"elapsed":58,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"509eb1d2-72c2-433a-f38d-744b66a0615f"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       first_num  second_num\n","0              0           0\n","1              0           0\n","2              0           0\n","3              0           0\n","4              0           0\n","...          ...         ...\n","63995          9           8\n","63996          9           8\n","63997          9           8\n","63998          9           8\n","63999          9           8\n","\n","[64000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-8e82df1e-5a7b-4acc-8c98-a427cc13d8cc\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_num</th>\n","      <th>second_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>63995</th>\n","      <td>9</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>63996</th>\n","      <td>9</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>63997</th>\n","      <td>9</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>63998</th>\n","      <td>9</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>63999</th>\n","      <td>9</td>\n","      <td>8</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>64000 rows  2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e82df1e-5a7b-4acc-8c98-a427cc13d8cc')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8e82df1e-5a7b-4acc-8c98-a427cc13d8cc button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8e82df1e-5a7b-4acc-8c98-a427cc13d8cc');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3f556deb-0f75-4baa-87d6-9aebd49942b9\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3f556deb-0f75-4baa-87d6-9aebd49942b9')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3f556deb-0f75-4baa-87d6-9aebd49942b9 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":48}]},{"cell_type":"code","source":["train_df.iloc[:,1:].values # each label of image is now in form of separate 1D array, with all the values of a row into a separate 1D array"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V9BQYZ6bP1lD","executionInfo":{"status":"ok","timestamp":1704793761980,"user_tz":-330,"elapsed":56,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"37981bac-63d5-4ca2-8626-fa0c41eca0d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 0],\n","       [0, 0],\n","       [0, 0],\n","       ...,\n","       [9, 8],\n","       [9, 8],\n","       [9, 8]])"]},"metadata":{},"execution_count":49}]},{"cell_type":"code","source":["test_df.iloc[:,1:]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"eQsIhTbbP6He","executionInfo":{"status":"ok","timestamp":1704793761980,"user_tz":-330,"elapsed":52,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"ebfe0ca1-1e00-4c8f-92fd-84a54c3a12d4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["       first_num  second_num\n","0              0           2\n","1              0           2\n","2              0           2\n","3              0           2\n","4              0           2\n","...          ...         ...\n","19995          9           6\n","19996          9           6\n","19997          9           6\n","19998          9           6\n","19999          9           6\n","\n","[20000 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-74094e28-46b3-47b1-be76-b1c99465a3a1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>first_num</th>\n","      <th>second_num</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>19995</th>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19996</th>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19997</th>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19998</th>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>19999</th>\n","      <td>9</td>\n","      <td>6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>20000 rows  2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-74094e28-46b3-47b1-be76-b1c99465a3a1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-74094e28-46b3-47b1-be76-b1c99465a3a1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-74094e28-46b3-47b1-be76-b1c99465a3a1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-d7c93b54-a828-4ea6-890a-de9bf2ce4b84\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d7c93b54-a828-4ea6-890a-de9bf2ce4b84')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-d7c93b54-a828-4ea6-890a-de9bf2ce4b84 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["test_df.iloc[:,1:].values # kya badhiya tarika hai, pura row as numpy array me pane ka"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BzxZp7jYesLh","executionInfo":{"status":"ok","timestamp":1704793761980,"user_tz":-330,"elapsed":51,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"9f320cff-279a-49f5-faea-4ca43ce135a9"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0, 2],\n","       [0, 2],\n","       [0, 2],\n","       ...,\n","       [9, 6],\n","       [9, 6],\n","       [9, 6]])"]},"metadata":{},"execution_count":51}]},{"cell_type":"code","source":["train_labels = train_df.iloc[:,1:].values\n","test_labels = test_df.iloc[:,1:].values"],"metadata":{"id":"fblYi8QUewsQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(train_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Hi-etIGMfG6h","executionInfo":{"status":"ok","timestamp":1704793761980,"user_tz":-330,"elapsed":48,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"1c879da0-e14a-4f5c-cb40-50ad8a141b12"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 0]\n"," [0 0]\n"," [0 0]\n"," ...\n"," [9 8]\n"," [9 8]\n"," [9 8]]\n"]}]},{"cell_type":"code","source":["print(test_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgqARCjlfJak","executionInfo":{"status":"ok","timestamp":1704793761981,"user_tz":-330,"elapsed":45,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"78da3a96-58f0-4dfa-ef39-3f5d731d1a9b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[[0 2]\n"," [0 2]\n"," [0 2]\n"," ...\n"," [9 6]\n"," [9 6]\n"," [9 6]]\n"]}]},{"cell_type":"code","source":["train_images = \"/content/multi_digit_mnist/train_images/\" + train_df.iloc[:,0].values\n","test_images = \"/content/multi_digit_mnist/test_images/\" + test_df.iloc[:,0].values\n","# it will do for all the rows and 1st column(index 0 column) of the train_df, test_df"],"metadata":{"id":"0XqlbzWofMtX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NBs29Sh7f1BA","executionInfo":{"status":"ok","timestamp":1704793761982,"user_tz":-330,"elapsed":41,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"f26e452e-8482-45a8-cb59-aa580617e1f3"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['/content/multi_digit_mnist/train_images/0_00.png',\n","       '/content/multi_digit_mnist/train_images/100_00.png',\n","       '/content/multi_digit_mnist/train_images/101_00.png', ...,\n","       '/content/multi_digit_mnist/train_images/999_98.png',\n","       '/content/multi_digit_mnist/train_images/99_98.png',\n","       '/content/multi_digit_mnist/train_images/9_98.png'], dtype=object)"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["test_images"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v0NimoDSgyz9","executionInfo":{"status":"ok","timestamp":1704793761982,"user_tz":-330,"elapsed":39,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"75876b53-830d-4548-cf4f-89896c380f6b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['/content/multi_digit_mnist/test_images/0_02.png',\n","       '/content/multi_digit_mnist/test_images/100_02.png',\n","       '/content/multi_digit_mnist/test_images/101_02.png', ...,\n","       '/content/multi_digit_mnist/test_images/999_96.png',\n","       '/content/multi_digit_mnist/test_images/99_96.png',\n","       '/content/multi_digit_mnist/test_images/9_96.png'], dtype=object)"]},"metadata":{},"execution_count":57}]},{"cell_type":"markdown","source":["kya badiya tarika hai, kisi list ki sari strings me koi common line add karke, un sbko ek new list me store karne ka."],"metadata":{"id":"sqEN8wSgg37W"}},{"cell_type":"code","source":["# Hyperparameters\n","BATCH_SIZE = 64\n","WEIGHT_DECAY = 0.001\n","LEARNING_RATE = 0.001"],"metadata":{"id":"-ParO41GizpE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def read_image(image_path, label):\n","  image = tf.io.read_file(image_path)\n","  image = tf.image.decode_image(image, channels=1,dtype=tf.float32)\n","\n","  labels = {\"first_num\":label[0], \"second_num\":label[1]}\n","  return image, labels"],"metadata":{"id":"DD4aBHXpg08q"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Loading the data"],"metadata":{"id":"VFOD6elrh3m8"}},{"cell_type":"code","source":["AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","\n","train_dataset = (\n","    train_dataset.shuffle(buffer_size=len(train_labels))\n","    .map(read_image)\n","    .batch(batch_size=BATCH_SIZE)\n","    .prefetch(buffer_size=AUTOTUNE)\n",")\n"],"metadata":{"id":"iGbvjBzqh5dm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["`AUTOTUNE = tf.data.experimental.AUTOTUNE` =  TensorFlow will try to automatically tune the buffer size to balance the trade-off between CPU and GPU utilization, leading to more efficient data loading and training."],"metadata":{"id":"IP_pUNBPkhze"}},{"cell_type":"code","source":["test_dataset = tf.data.Dataset.from_tensor_slices((test_images,test_labels))\n","test_dataset = (\n","    test_dataset   # no need of shuffling in test\n","    .map(read_image)\n","    .batch(batch_size=BATCH_SIZE)\n","    .prefetch(buffer_size=AUTOTUNE)\n",")"],"metadata":{"id":"F8DPzeFhjNkX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Certainly! This code is creating TensorFlow datasets for training and testing a neural network. Let's break down the key components:\n","\n","### Hyperparameters:\n","\n","```python\n","BATCH_SIZE = 64\n","WEIGHT_DECAY = 0.001\n","LEARNING_RATE = 0.001\n","```\n","\n","These are hyperparameters that control the behavior of the training process:\n","\n","- `BATCH_SIZE`: The number of samples in each mini-batch during training.\n","- `WEIGHT_DECAY`: A regularization term to penalize large weights in the neural network.\n","- `LEARNING_RATE`: The rate at which the model's weights are updated during training.\n","\n","### Reading Images:\n","\n","```python\n","def read_image(image_path, label):\n","    image = tf.io.read_file(image_path)\n","    image = tf.image.decode_image(image, channels=1, dtype=tf.float32)\n","\n","    labels = {\"first_num\": label[0], \"second_num\": label[1]}\n","    return image, labels\n","```\n","\n","This function `read_image` takes an image file path and its corresponding label as input and performs the following operations:\n","\n","- `tf.io.read_file(image_path)`: Reads the contents of the image file.\n","- `tf.image.decode_image(image, channels=1, dtype=tf.float32)`: Decodes the image into a tensor with one channel (assuming grayscale) and converts the pixel values to floating-point numbers.\n","- `labels = {\"first_num\": label[0], \"second_num\": label[1]}`: Creates a dictionary of labels for the first and second numbers.\n","\n","### Creating TensorFlow Datasets:\n","\n","```python\n","AUTOTUNE = tf.data.experimental.AUTOTUNE\n","\n","train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n","\n","train_dataset = (\n","    train_dataset.shuffle(buffer_size=len(train_labels))\n","    .map(read_image)\n","    .batch(batch_size=BATCH_SIZE)\n","    .prefetch(buffer_size=AUTOTUNE)\n",")\n","\n","test_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n","test_dataset = (\n","    test_dataset\n","    .map(read_image)\n","    .batch(batch_size=BATCH_SIZE)\n","    .prefetch(buffer_size=AUTOTUNE)\n",")\n","```\n","\n","1. `tf.data.Dataset.from_tensor_slices((train_images, train_labels))`: Creates a TensorFlow dataset from the given image paths (`train_images`) and labels (`train_labels`).\n","\n","2. `train_dataset.shuffle(buffer_size=len(train_labels))`: Shuffles the training dataset. The buffer size determines the number of elements from the dataset from which the new dataset is randomly sampled.\n","\n","3. `.map(read_image)`: Applies the `read_image` function to each element of the dataset. This function reads and decodes the images.\n","\n","4. `.batch(batch_size=BATCH_SIZE)`: Batches the dataset into mini-batches of size `BATCH_SIZE`.\n","\n","5. `.prefetch(buffer_size=AUTOTUNE)`: Prefetches data from the dataset to improve training performance by overlapping data loading and model training.\n","\n","The same steps are repeated for the test dataset (`test_dataset`). The final result is two TensorFlow datasets ready for training and testing a neural network."],"metadata":{"id":"D-K4gonalTRK"}},{"cell_type":"code","source":["# model building, training and compilation : functional model, more than one output streams\n","\n","inputs = keras.Input(shape=(64, 64, 1))\n","x = layers.Conv2D(\n","    filters=32,\n","    kernel_size=3,\n","    padding=\"same\",\n","    kernel_regularizer=regularizers.l2(WEIGHT_DECAY), # regularization is for reducing overfitting\n",")(inputs)\n","x = layers.BatchNormalization()(x)\n","x = keras.activations.relu(x)\n","x = layers.Conv2D(64, 3, kernel_regularizer=regularizers.l2(WEIGHT_DECAY),)(x)\n","x = layers.BatchNormalization()(x)\n","x = keras.activations.relu(x)\n","x = layers.MaxPooling2D()(x)\n","x = layers.Conv2D(\n","    64, 3, activation=\"relu\", kernel_regularizer=regularizers.l2(WEIGHT_DECAY),\n",")(x)\n","x = layers.Conv2D(128, 3, activation=\"relu\")(x)\n","x = layers.MaxPooling2D()(x)\n","x = layers.Flatten()(x)\n","x = layers.Dense(128, activation=\"relu\")(x)\n","x = layers.Dropout(0.5)(x)\n","x = layers.Dense(64, activation=\"relu\")(x)\n","# now input x is going to be mapped to 2 different outputs : that's why functional api is more useful.\n","output1 = layers.Dense(10, activation=\"softmax\", name=\"first_num\")(x)\n","output2 = layers.Dense(10, activation=\"softmax\", name=\"second_num\")(x)\n","model = keras.Model(inputs=inputs, outputs=[output1, output2])\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(LEARNING_RATE),\n","    loss=keras.losses.SparseCategoricalCrossentropy(), # by default from_logits = False , as activation softmax upar use kr liay hai output layers me, also single loss function se dono outputs ho gye\n","    metrics=[\"accuracy\"],\n",")\n","\n","model.fit(train_dataset, epochs=5, verbose=2)\n","model.evaluate(test_dataset, verbose=2)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9cGaPrEbhqT_","executionInfo":{"status":"ok","timestamp":1704793936949,"user_tz":-330,"elapsed":175001,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"2d5c4ccf-ed4f-4fd0-f1a7-3b7ae1642df6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","1000/1000 - 39s - loss: 1.8015 - first_num_loss: 0.8469 - second_num_loss: 0.8682 - first_num_accuracy: 0.7028 - second_num_accuracy: 0.6919 - 39s/epoch - 39ms/step\n","Epoch 2/5\n","1000/1000 - 31s - loss: 0.5294 - first_num_loss: 0.2335 - second_num_loss: 0.2283 - first_num_accuracy: 0.9242 - second_num_accuracy: 0.9249 - 31s/epoch - 31ms/step\n","Epoch 3/5\n","1000/1000 - 30s - loss: 0.3669 - first_num_loss: 0.1580 - second_num_loss: 0.1506 - first_num_accuracy: 0.9492 - second_num_accuracy: 0.9509 - 30s/epoch - 30ms/step\n","Epoch 4/5\n","1000/1000 - 31s - loss: 0.2898 - first_num_loss: 0.1199 - second_num_loss: 0.1165 - first_num_accuracy: 0.9613 - second_num_accuracy: 0.9621 - 31s/epoch - 31ms/step\n","Epoch 5/5\n","1000/1000 - 30s - loss: 0.2388 - first_num_loss: 0.0990 - second_num_loss: 0.0899 - first_num_accuracy: 0.9688 - second_num_accuracy: 0.9711 - 30s/epoch - 30ms/step\n","313/313 - 4s - loss: 0.9940 - first_num_loss: 0.2690 - second_num_loss: 0.6768 - first_num_accuracy: 0.9275 - second_num_accuracy: 0.8159 - 4s/epoch - 12ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.9939947128295898,\n"," 0.26900845766067505,\n"," 0.6767992377281189,\n"," 0.9275000095367432,\n"," 0.8159000277519226]"]},"metadata":{},"execution_count":62}]},{"cell_type":"markdown","source":["good accuracy in both the digits prediction for test datasets. both digits have accuracy of 88 % and 84 % ."],"metadata":{"id":"lzufy3SDorva"}},{"cell_type":"markdown","source":["Sath-sath recognition of both the digits : quite interesting for me."],"metadata":{"id":"OgaSQhL2pW0B"}},{"cell_type":"markdown","source":["# Model Subclassing with Keras\n","\n","Incredibly flexible way to build the model. Most amount of flexibility."],"metadata":{"id":"nC1cZZM0tCJW"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.datasets import mnist"],"metadata":{"id":"cFUTJNpCo2Gj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["physical_devices = tf.config.list_physical_devices(\"GPU\")\n","\n","if physical_devices:\n","  tf.config.experimental.set_memory_growth(physical_devices[0], True)"],"metadata":{"id":"dhOEOf7vthkH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":[" you are trying to modify memory growth settings for a physical device (GPU) after the devices have already been initialized. TensorFlow doesn't allow changing these settings once the devices are initialized.\n","\n"," Upar ho chuka hai ye kam and gpu set ho chuka hai. Now change nhi hoga"],"metadata":{"id":"OVhEFtZAuYxT"}},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()"],"metadata":{"id":"RD8tQ9yrt_Zw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train # 1 = 2D array for each images as grayscale image, x_train abhi 3D array hai"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wdKySqSqu2_A","executionInfo":{"status":"ok","timestamp":1704793936951,"user_tz":-330,"elapsed":37,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e53424c9-15f8-472e-e7df-27f70b64fd51"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       ...,\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]],\n","\n","       [[0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        ...,\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0],\n","        [0, 0, 0, ..., 0, 0, 0]]], dtype=uint8)"]},"metadata":{},"execution_count":66}]},{"cell_type":"code","source":["x_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yy8fMPvGvSbe","executionInfo":{"status":"ok","timestamp":1704793936952,"user_tz":-330,"elapsed":29,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"4b147e93-fd31-4a4f-da2c-b599ccee1431"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n","         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n","        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n","        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n","        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n","        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n","         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n","        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n","        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n","        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n","        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n","        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n","        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n","        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n","         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0],\n","       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n","          0,   0]], dtype=uint8)"]},"metadata":{},"execution_count":67}]},{"cell_type":"code","source":["x_train = x_train.reshape(-1, 28,28,1).astype(\"float32\")/255.0\n","x_test = x_test.reshape(-1,28,28,1).astype(\"float32\")/255.0"],"metadata":{"id":"i44O9Ii1vcRb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x_train # 4D now"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"99zreSeDvexf","executionInfo":{"status":"ok","timestamp":1704793937666,"user_tz":-330,"elapsed":45,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"c0a4b4e9-f0c0-4993-a7b3-4f519252ee62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        ...,\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]]],\n","\n","\n","       [[[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        ...,\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]]],\n","\n","\n","       [[[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        ...,\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]]],\n","\n","\n","       ...,\n","\n","\n","       [[[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        ...,\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]]],\n","\n","\n","       [[[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        ...,\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]]],\n","\n","\n","       [[[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        ...,\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]],\n","\n","        [[0.],\n","         [0.],\n","         [0.],\n","         ...,\n","         [0.],\n","         [0.],\n","         [0.]]]], dtype=float32)"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["x_train[0] # first image : now each image is a 3D image. Ech scale pixel values have now been converted to a 1D array on only 1 element. Each row of previos array is now a 2D array and set of each rows is now 3D array that represents one image"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VzxRWISdvf68","executionInfo":{"status":"ok","timestamp":1704793937667,"user_tz":-330,"elapsed":43,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"a9b1f712-d2a2-429b-84c4-1af3a0f2ea7a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.01176471],\n","        [0.07058824],\n","        [0.07058824],\n","        [0.07058824],\n","        [0.49411765],\n","        [0.53333336],\n","        [0.6862745 ],\n","        [0.10196079],\n","        [0.6509804 ],\n","        [1.        ],\n","        [0.96862745],\n","        [0.49803922],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.11764706],\n","        [0.14117648],\n","        [0.36862746],\n","        [0.6039216 ],\n","        [0.6666667 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.88235295],\n","        [0.6745098 ],\n","        [0.99215686],\n","        [0.9490196 ],\n","        [0.7647059 ],\n","        [0.2509804 ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.19215687],\n","        [0.93333334],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.9843137 ],\n","        [0.3647059 ],\n","        [0.32156864],\n","        [0.32156864],\n","        [0.21960784],\n","        [0.15294118],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.07058824],\n","        [0.85882354],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.7764706 ],\n","        [0.7137255 ],\n","        [0.96862745],\n","        [0.94509804],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.3137255 ],\n","        [0.6117647 ],\n","        [0.41960785],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.8039216 ],\n","        [0.04313726],\n","        [0.        ],\n","        [0.16862746],\n","        [0.6039216 ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.05490196],\n","        [0.00392157],\n","        [0.6039216 ],\n","        [0.99215686],\n","        [0.3529412 ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.54509807],\n","        [0.99215686],\n","        [0.74509805],\n","        [0.00784314],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.04313726],\n","        [0.74509805],\n","        [0.99215686],\n","        [0.27450982],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.13725491],\n","        [0.94509804],\n","        [0.88235295],\n","        [0.627451  ],\n","        [0.42352942],\n","        [0.00392157],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.31764707],\n","        [0.9411765 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.46666667],\n","        [0.09803922],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.1764706 ],\n","        [0.7294118 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.5882353 ],\n","        [0.10588235],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.0627451 ],\n","        [0.3647059 ],\n","        [0.9882353 ],\n","        [0.99215686],\n","        [0.73333335],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.9764706 ],\n","        [0.99215686],\n","        [0.9764706 ],\n","        [0.2509804 ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.18039216],\n","        [0.50980395],\n","        [0.7176471 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.8117647 ],\n","        [0.00784314],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.15294118],\n","        [0.5803922 ],\n","        [0.8980392 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.98039216],\n","        [0.7137255 ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.09411765],\n","        [0.44705883],\n","        [0.8666667 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.7882353 ],\n","        [0.30588236],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.09019608],\n","        [0.25882354],\n","        [0.8352941 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.7764706 ],\n","        [0.31764707],\n","        [0.00784314],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.07058824],\n","        [0.67058825],\n","        [0.85882354],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.7647059 ],\n","        [0.3137255 ],\n","        [0.03529412],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.21568628],\n","        [0.6745098 ],\n","        [0.8862745 ],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.95686275],\n","        [0.52156866],\n","        [0.04313726],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.53333336],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.99215686],\n","        [0.83137256],\n","        [0.5294118 ],\n","        [0.5176471 ],\n","        [0.0627451 ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]],\n","\n","       [[0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ],\n","        [0.        ]]], dtype=float32)"]},"metadata":{},"execution_count":70}]},{"cell_type":"code","source":["# CNN -> BatchNorm -> Relu (common Structure)\n","# x10 write code : reusing multiple times, instead of writing multiple times : ideal way"],"metadata":{"id":"KuwNWnAGvthP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# create a class for this kind of blocks :\n","# keras subclassing is exactly same as creating pytorch model\n","class CNNBlock(layers.Layer):\n","  def __init__(self, out_channels, kernel_size=3):\n","    super(CNNBlock, self).__init__() # to run parent class layer by layer\n","    self.conv = layers.Conv2D(out_channels, kernel_size, padding='same') # convolutional layer\n","    self.bn = layers.BatchNormalization() # batch normalization\n","\n","  def call(self, input_tensor, training=False): # in pytorch call means = forward\n","    x = self.conv(input_tensor)\n","    x = self.bn(x, training = training)\n","    x = tf.nn.relu(x) # inbuilt relu from tf.nn is used\n","    return x"],"metadata":{"id":"fvkOM7lCw46y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = keras.Sequential(\n","    [\n","        CNNBlock(32), # consists of 3 layers conv, bn, and relu\n","        CNNBlock(64), # consists of 3 layers conv, bn, and relu\n","        CNNBlock(128), # consists of 3 layers conv, bn, and relu\n","        layers.Flatten(),\n","        layers.Dense(10)\n","    ]\n",")\n","# code seems to be readable. Also don't take unnecessary space"],"metadata":{"id":"C3wWHXpYzCls"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    optimizer = keras.optimizers.Adam(),\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics = ['accuracy']\n",")\n","model.fit(x_train, y_train, batch_size=64, epochs=5,verbose=2)\n","model.evaluate(x_test, y_test, batch_size=64, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSqGXohCzygi","executionInfo":{"status":"ok","timestamp":1704794022195,"user_tz":-330,"elapsed":84558,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e56ec43a-4a80-45fc-ebf9-0fc02213a5ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","938/938 - 14s - loss: 0.5796 - accuracy: 0.9463 - 14s/epoch - 15ms/step\n","Epoch 2/5\n","938/938 - 11s - loss: 0.0943 - accuracy: 0.9819 - 11s/epoch - 12ms/step\n","Epoch 3/5\n","938/938 - 11s - loss: 0.0327 - accuracy: 0.9901 - 11s/epoch - 12ms/step\n","Epoch 4/5\n","938/938 - 11s - loss: 0.0248 - accuracy: 0.9922 - 11s/epoch - 12ms/step\n","Epoch 5/5\n","938/938 - 11s - loss: 0.0246 - accuracy: 0.9925 - 11s/epoch - 12ms/step\n","157/157 - 1s - loss: 0.0838 - accuracy: 0.9810 - 1s/epoch - 7ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.08382377028465271, 0.9810000061988831]"]},"metadata":{},"execution_count":74}]},{"cell_type":"code","source":["class ResBlock(layers.Layer):\n","    def __init__(self, channels):\n","        super(ResBlock, self).__init__()\n","        self.channels = channels\n","        self.cnn1 = CNNBlock(channels[0], 3) # 3 kernel size\n","        self.cnn2 = CNNBlock(channels[1], 3)\n","        self.cnn3 = CNNBlock(channels[2], 3)\n","        self.pooling = layers.MaxPooling2D()\n","        self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n","\n","    def call(self, input_tensor, training=False):\n","        x = self.cnn1(input_tensor, training=training)\n","        x = self.cnn2(x, training=training)\n","        x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n","        x = self.pooling(x)\n","        return x"],"metadata":{"id":"FFW_WKoQ0P5B"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training = False\n","\n","\n","```python\n","def call(self, input_tensor, training=False):\n","    x = self.cnn1(input_tensor, training=training)\n","    x = self.cnn2(x, training=training)\n","    x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n","    x = self.pooling(x)\n","    return x\n","```\n","\n","The `training` parameter is a boolean that is used to indicate whether the layer should run in training mode or inference mode. This is particularly relevant for layers like dropout and batch normalization, which behave differently during training and inference.\n","\n","When calling this `call` method during the training phase of your model, you should set `training=True` to enable behaviors like dropout. When calling it during the inference (testing) phase, you can set `training=False` or omit the `training` argument (defaulting to `False`).\n","\n","In the code, `training` is passed as an argument to the `call` method of each `CNNBlock`. This allows the internal layers of the `ResBlock` to adjust their behavior based on whether the model is currently in training or inference(testing) mode."],"metadata":{"id":"25br32Ki1v1W"}},{"cell_type":"markdown","source":["Code samjhna\n","\n","This code defines a Residual Block (`ResBlock`) as a custom layer in a neural network. The architecture of a Residual Block is commonly used in deep neural networks to facilitate the training of very deep networks. Let's break down the code and understand its components:\n","\n","1. **Initialization:**\n","\n","   ```python\n","   def __init__(self, channels):\n","       super(ResBlock, self).__init__()\n","       self.channels = channels\n","       self.cnn1 = CNNBlock(channels[0], 3)  # 3 kernel size\n","       self.cnn2 = CNNBlock(channels[1], 3)\n","       self.cnn3 = CNNBlock(channels[2], 3)\n","       self.pooling = layers.MaxPooling2D()\n","       self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n","   ```\n","\n","   - `channels`: It's a list containing the number of output channels for each convolutional layer in the ResBlock.\n","   - `cnn1`, `cnn2`, `cnn3`: Instances of a custom `CNNBlock` class with specified output channels and a kernel size of 3.\n","   - `pooling`: A MaxPooling2D layer, which performs max pooling to downsample the spatial dimensions of the input.\n","   - `identity_mapping`: A convolutional layer used for the identity mapping (shortcut connection) with the same number of channels as the second convolutional layer.\n","\n","2. **Forward Pass (Call Method):**\n","\n","   ```python\n","   def call(self, input_tensor, training=False):\n","       x = self.cnn1(input_tensor, training=training)\n","       x = self.cnn2(x, training=training)\n","       x = self.cnn3(x + self.identity_mapping(input_tensor), training=training,)\n","       x = self.pooling(x)\n","       return x\n","   ```\n","\n","   - `input_tensor`: The input to the Residual Block.\n","   - `training`: A boolean flag indicating whether the model is in training mode or inference mode.\n","\n","   The forward pass of the ResBlock consists of the following steps:\n","\n","   - Pass the input through `cnn1`.\n","   - Pass the result through `cnn2`.\n","   - Create an identity mapping (shortcut connection) by passing the input through `identity_mapping` and add it to the output of `cnn2`.\n","   - Pass the combined result through `cnn3`.\n","   - Apply max pooling to downsample the spatial dimensions.\n","\n","The purpose of using a Residual Block is to facilitate the training of deep neural networks by mitigating the vanishing gradient problem. The shortcut connection allows the gradient to flow directly through the block, making it easier for the model to learn and optimize deep architectures. This kind of architecture is commonly used in models like ResNet (Residual Networks)."],"metadata":{"id":"XWbUcwL93R8s"}},{"cell_type":"markdown","source":["**The concept of identity mapping in the context of residual networks (ResNets)**\n","\n","Certainly! The concept of identity mapping in the context of residual networks (ResNets) is crucial for understanding how Residual Blocks work.\n","\n","In the code you provided:\n","\n","```python\n","self.identity_mapping = layers.Conv2D(channels[1], 3, padding=\"same\")\n","```\n","\n","This line creates a convolutional layer (`Conv2D`) that serves as the identity mapping (shortcut connection) within the Residual Block.\n","\n","Here's how it's used in the `call` method:\n","\n","```python\n","x = self.cnn3(x + self.identity_mapping(input_tensor), training=training)\n","```\n","\n","Now, let's break down the components:\n","\n","- `self.identity_mapping(input_tensor)`: This applies the convolutional layer to the `input_tensor`, creating a transformed version of the input.\n","\n","- `x + self.identity_mapping(input_tensor)`: This adds the transformed input (identity mapping) to the output of the previous convolutional layers (`cnn2`). This step forms a shortcut connection that bypasses the intermediate layers and directly adds the original input to the output.\n","\n","- `self.cnn3(...)`: Finally, the sum is passed through the third convolutional layer (`cnn3`). This layer processes the combined information.\n","\n","The purpose of the identity mapping (shortcut connection) is to allow the gradient to flow directly through the block during backpropagation. In traditional deep networks, as you go deeper into the network, gradients can become very small (vanish) during backpropagation, making it difficult for the model to learn. By having a shortcut connection, the identity mapping allows the gradient to flow directly without undergoing transformations, addressing the vanishing gradient problem.\n","\n","In summary, the identity mapping helps with the training of deep networks by providing a direct path for the gradient to flow through the network, enabling the optimization of very deep architectures like ResNets."],"metadata":{"id":"1Xq1GZ9l37sr"}},{"cell_type":"markdown","source":["Residual Networks Mean:\n","\n","Certainly! A Residual Network, often abbreviated as ResNet, is a type of deep neural network architecture designed to address the challenges of training very deep neural networks. It was introduced by Kaiming He, et al. in the paper \"Deep Residual Learning for Image Recognition\" in 2015.\n","\n","The key innovation of ResNet is the use of residual blocks, which incorporate shortcut connections (also known as skip connections or identity mappings). These shortcut connections allow the gradient to flow directly through the block during backpropagation, mitigating the vanishing gradient problem that can occur in very deep networks.\n","\n","### Components of Residual Network:\n","\n","1. **Residual Block:**\n","   - The fundamental building block of ResNet is the residual block. Each block contains two main paths: a shortcut connection and a main path with one or more convolutional layers.\n","   - The output of the convolutional layers is added to the input (identity mapping) through the shortcut connection.\n","\n","2. **Shortcut Connection:**\n","   - The shortcut connection is essentially an identity mapping (direct copy of the input) that bypasses the convolutional layers.\n","   - By adding the original input to the transformed output, the network is enabled to learn the residual (the difference between the input and the output).\n","\n","3. **Skip Connections:**\n","   - The term \"skip connections\" comes from the fact that the shortcut connections allow the network to \"skip\" certain layers during forward and backward passes.\n","\n","4. **Deep Stacking:**\n","   - ResNet architectures are known for their deep stacking of residual blocks. Stacking multiple blocks enables the construction of very deep networks with hundreds or even thousands of layers.\n","\n","### Benefits of Residual Networks:\n","\n","1. **Gradient Flow:**\n","   - The identity mapping in the shortcut connection helps gradients to flow more easily during backpropagation, addressing the vanishing gradient problem.\n","\n","2. **Ease of Training:**\n","   - ResNets are easier to train and converge faster compared to traditional deep networks, especially as the depth of the network increases.\n","\n","3. **Deep Architectures:**\n","   - ResNets have been successfully employed in extremely deep architectures, making them suitable for a wide range of computer vision tasks, including image classification and object detection.\n","\n","4. **State-of-the-Art Performance:**\n","   - ResNets have achieved state-of-the-art performance on various benchmark datasets and are widely used in both research and practical applications.\n","\n","Overall, Residual Networks have had a significant impact on the field of deep learning, and their architectural principles have influenced the design of subsequent neural network architectures."],"metadata":{"id":"ZRQ4e00O4eRt"}},{"cell_type":"code","source":["class ResNet_Like(keras.Model):\n","    def __init__(self, num_classes=10):\n","        super(ResNet_Like, self).__init__()\n","        self.block1 = ResBlock([32, 32, 64]) # bhai pura ka pura model hi lekar aa rhi ye layer from ResNet Class\n","        self.block2 = ResBlock([128, 128, 256]) # bhai pura ka pura model hi lekar aa rhi ye layer\n","        self.block3 = ResBlock([128, 256, 512]) # bhai pura ka pura model hi lekar aa rhi ye layer\n","        self.pool = layers.GlobalAveragePooling2D() # average pool the height and width\n","        self.classifier = layers.Dense(num_classes)\n","\n","    def call(self, input_tensor, training=False):\n","        x = self.block1(input_tensor, training=training)\n","        x = self.block2(x, training=training)\n","        x = self.block3(x, training=training)\n","        x = self.pool(x, training=training)\n","        x = self.classifier(x)\n","        return x\n","\n","    def model(self):\n","        x = keras.Input(shape=(28, 28, 1))\n","        return keras.Model(inputs=[x], outputs=self.call(x))\n","\n"],"metadata":{"id":"BpdSTDyV11VK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["About this code:\n","\n","This code defines a neural network model called `ResNet_Like` using the Keras Model subclassing API. The model architecture is inspired by ResNet but differs in the number of layers and blocks.\n","\n","### Key Components:\n","\n","1. **Initialization:**\n","    - The `__init__` method initializes the `ResNet_Like` model.\n","    - It creates three `ResBlock` instances (`block1`, `block2`, `block3`) with different channel configurations.\n","\n","2. **Forward Pass (Call Method):**\n","    - The `call` method defines the forward pass of the model.\n","    - It sequentially passes the input through the three blocks (`block1`, `block2`, `block3`).\n","    - After the blocks, it applies global average pooling (`GlobalAveragePooling2D`) to reduce the spatial dimensions to 1x1 per channel.\n","    - Finally, it passes the pooled features through a dense layer (`Dense`) for classification.\n","\n","3. **`model` Method:**\n","    - The `model` method creates the Keras model instance with defined input shape (28x28x1) and outputting the result of the `call` method.\n","    - This method essentially provides a clean interface to generate the model architecture when instantiated.\n","\n","### Difference from Previous Code: ResNet class\n","\n","The main differences between this code and the previous code are:\n","\n","1. **Architecture:**\n","    - This `ResNet_Like` model has a different architecture compared to the previous `ResBlock` implementation. It consists of multiple `ResBlock` instances (blocks 1, 2, and 3) stacked sequentially.\n","\n","2. **Usage of Keras Model Subclassing API:**\n","    - This code uses the Keras Model subclassing API to define the model architecture and the forward pass.\n","    - The previous code defined individual layers (`ResBlock`, `CNNBlock`) and used them within a custom `call` method of a `ResBlock` class.\n","\n","In summary, while both implementations share the concept of using blocks inspired by ResNet, the way the model architecture is defined and composed differs. The first code snippet defines a custom `ResBlock` class, while the second snippet directly constructs a model using multiple instances of this block, creating a higher-level architecture called `ResNet_Like`."],"metadata":{"id":"Uxx7iNFyglC-"}},{"cell_type":"markdown","source":["what is the use of this extra piece of code:\n","\n","    def model(self):\n","        x = keras.Input(shape=(28, 28, 1))\n","        return keras.Model(inputs=[x], outputs=self.call(x))\n","\n","What if I don't add this"],"metadata":{"id":"1hoEeDaGjwWa"}},{"cell_type":"markdown","source":["The extra piece of code you provided is a method named `model`. This method is intended to create and return a Keras model instance based on the architecture defined in the `ResNet_Like` class. It specifically defines an input shape and constructs a Keras Model using the `call` method as the output.\n","\n","```python\n","def model(self):\n","    x = keras.Input(shape=(28, 28, 1))\n","    return keras.Model(inputs=[x], outputs=self.call(x))\n","```\n","\n","When you call this method, it creates a new Keras model with the specified input shape `(28, 28, 1)` and the output defined by the `call` method.\n","\n","The purpose of providing this method is to make it convenient for users to instantiate the model when they want to use it. Without this method, users would need to create an instance of the `ResNet_Like` class and then call the `call` method separately. With this method, users can create a model instance with a single line of code:\n","\n","```python\n","resnet_like_model = ResNet_Like().model()\n","```\n","\n","This can be helpful for readability and usability. However, it's important to note that it's not strictly necessary. If you don't add this method, users can still create an instance of `ResNet_Like` and use it by calling the `call` method directly:\n","\n","```python\n","resnet_like_model = ResNet_Like()\n","output = resnet_like_model.call(input_tensor)\n","```\n","\n","So, the extra piece of code is a convenience method to create a model instance more easily, but its absence won't prevent the main functionality of the `ResNet_Like` class."],"metadata":{"id":"qq9ANZ0Uj1VE"}},{"cell_type":"code","source":["model = ResNet_Like().model()\n","base_input = model.layers[0].input\n","base_output = model.layers[2].output\n","output = layers.Dense(10)(layers.Flatten()(base_output))\n","model = keras.Model(base_input, output)"],"metadata":{"id":"IBG89WQFqh3M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The provided code appears to modify the architecture of the `ResNet_Like` model. Let's break down each step:\n","\n","```python\n","model = ResNet_Like().model()\n","```\n","\n","This line creates an instance of the `ResNet_Like` model using the `model` method, which was defined earlier in the `ResNet_Like` class. This method returns a Keras model based on the architecture specified in the `ResNet_Like` class.\n","\n","```python\n","base_input = model.layers[0].input\n","base_output = model.layers[2].output  # there are total 3 layers, 0,1 and 2 remember this\n","```\n","\n","These two lines extract the input and output tensors of the original `ResNet_Like` model. `model.layers[0]` corresponds to the first layer (input layer) of the model, and `model.layers[2]` corresponds to the third layer (output of the last block) of the model.\n","\n","```python\n","output = layers.Dense(10)(layers.Flatten()(base_output))  # read it right to left, Instead of 3 lines we are doing in 1 line\n","```\n","\n","This line introduces additional layers to the model. Let's break it down:\n","\n","- `layers.Flatten()(base_output)`: This flattens the output tensor from the original `ResNet_Like` model. It converts the 3D tensor (resulting from global average pooling) into a 1D tensor.\n","\n","- `layers.Dense(10)(...)`: This adds a dense layer with 10 units (assuming a classification task with 10 classes) on top of the flattened output.\n","\n","```python\n","model = keras.Model(base_input, output)  # functional api me models ese hi bnte hain.\n","```\n","\n","This line creates a new Keras model with the modified architecture. It takes the original input tensor (`base_input`) and the newly defined output tensor (`output`) to construct a new model. This new model includes the original ResNet-like blocks up to the last block's output, followed by a flattening operation and a dense layer for classification.\n","\n","In summary, this code extends the original `ResNet_Like` model by adding a dense layer on top for classification. It effectively modifies the output structure of the original model to suit a specific task, such as image classification with 10 classes."],"metadata":{"id":"F3Tb3-Qeq5C1"}},{"cell_type":"code","source":["model.compile(\n","    optimizer=keras.optimizers.Adam(),\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    metrics=[\"accuracy\"],\n",")"],"metadata":{"id":"4i-Om7uZsqRF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(x_train, y_train, batch_size=64, epochs=5, verbose=2)\n","model.evaluate(x_test, y_test, batch_size=64, verbose=2)\n","model.save(\"pretrained\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v4FTA_jbssfA","executionInfo":{"status":"ok","timestamp":1704795073483,"user_tz":-330,"elapsed":94958,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"fd873bfa-67c1-43ce-a891-39426f6bc02c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","938/938 - 23s - loss: 0.1067 - accuracy: 0.9668 - 23s/epoch - 24ms/step\n","Epoch 2/5\n","938/938 - 17s - loss: 0.0394 - accuracy: 0.9878 - 17s/epoch - 18ms/step\n","Epoch 3/5\n","938/938 - 17s - loss: 0.0305 - accuracy: 0.9902 - 17s/epoch - 18ms/step\n","Epoch 4/5\n","938/938 - 17s - loss: 0.0248 - accuracy: 0.9926 - 17s/epoch - 18ms/step\n","Epoch 5/5\n","938/938 - 17s - loss: 0.0200 - accuracy: 0.9939 - 17s/epoch - 18ms/step\n","157/157 - 1s - loss: 0.0308 - accuracy: 0.9913 - 1s/epoch - 9ms/step\n"]}]},{"cell_type":"markdown","source":["This Was all about the power of Subclassing"],"metadata":{"id":"fbx2FGpQtIsC"}},{"cell_type":"markdown","source":["# **Creating Custom Layer**"],"metadata":{"id":"WbfUwJPDqNng"}},{"cell_type":"code","source":["import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","from tensorflow.keras.datasets import mnist"],"metadata":{"id":"1QjMJBkmbWqi","executionInfo":{"status":"ok","timestamp":1706603708340,"user_tz":-330,"elapsed":413,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["(x_train, y_train), (x_test, y_test) = mnist.load_data()\n","x_train = x_train.reshape(-1, 28*28).astype(\"float32\")/255.0\n","x_test = x_test.reshape(-1, 28*28).astype(\"float32\")/255.0"],"metadata":{"id":"7N5NVgtcu5AL","executionInfo":{"status":"ok","timestamp":1706603720934,"user_tz":-330,"elapsed":1027,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["x_train[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zNLMz6vAvTfU","executionInfo":{"status":"ok","timestamp":1706603723398,"user_tz":-330,"elapsed":420,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"2d3d7bc5-98f4-4673-aff5-27b0f6245a23"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.01176471, 0.07058824, 0.07058824,\n","       0.07058824, 0.49411765, 0.53333336, 0.6862745 , 0.10196079,\n","       0.6509804 , 1.        , 0.96862745, 0.49803922, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.11764706, 0.14117648, 0.36862746, 0.6039216 ,\n","       0.6666667 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","       0.99215686, 0.88235295, 0.6745098 , 0.99215686, 0.9490196 ,\n","       0.7647059 , 0.2509804 , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n","       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","       0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n","       0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n","       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n","       0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.3137255 , 0.6117647 , 0.41960785, 0.99215686, 0.99215686,\n","       0.8039216 , 0.04313726, 0.        , 0.16862746, 0.6039216 ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.05490196,\n","       0.00392157, 0.6039216 , 0.99215686, 0.3529412 , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.54509807,\n","       0.99215686, 0.74509805, 0.00784314, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.04313726, 0.74509805, 0.99215686,\n","       0.27450982, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.13725491, 0.94509804, 0.88235295, 0.627451  ,\n","       0.42352942, 0.00392157, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.31764707, 0.9411765 , 0.99215686, 0.99215686, 0.46666667,\n","       0.09803922, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.1764706 ,\n","       0.7294118 , 0.99215686, 0.99215686, 0.5882353 , 0.10588235,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.0627451 , 0.3647059 ,\n","       0.9882353 , 0.99215686, 0.73333335, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.9764706 , 0.99215686,\n","       0.9764706 , 0.2509804 , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.18039216, 0.50980395,\n","       0.7176471 , 0.99215686, 0.99215686, 0.8117647 , 0.00784314,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.15294118,\n","       0.5803922 , 0.8980392 , 0.99215686, 0.99215686, 0.99215686,\n","       0.98039216, 0.7137255 , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.09411765, 0.44705883, 0.8666667 , 0.99215686, 0.99215686,\n","       0.99215686, 0.99215686, 0.7882353 , 0.30588236, 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.09019608, 0.25882354, 0.8352941 , 0.99215686,\n","       0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.31764707,\n","       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.07058824, 0.67058825, 0.85882354,\n","       0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.7647059 ,\n","       0.3137255 , 0.03529412, 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.21568628, 0.6745098 ,\n","       0.8862745 , 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n","       0.95686275, 0.52156866, 0.04313726, 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.53333336, 0.99215686, 0.99215686, 0.99215686,\n","       0.83137256, 0.5294118 , 0.5176471 , 0.0627451 , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        , 0.        ,\n","       0.        , 0.        , 0.        , 0.        ], dtype=float32)"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["# creating our own custom model\n","\n","class MyModel(keras.Model):\n","  def __init__(self, num_classes=10):\n","    super(MyModel, self).__init__()\n","    self.dense1 = layers.Dense(64)\n","    self.dense2 = layers.Dense(num_classes)\n","\n","  def call(self, input_tensor):\n","    x = tf.nn.relu(self.dense1(input_tensor))\n","    return self.dense2(x)\n"],"metadata":{"id":"gRArDE6lvVm3","executionInfo":{"status":"ok","timestamp":1706603724919,"user_tz":-330,"elapsed":1,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["model = MyModel()"],"metadata":{"id":"Rm8mt9LWwrE4","executionInfo":{"status":"ok","timestamp":1706603729039,"user_tz":-330,"elapsed":582,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["model.compile(\n","    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer = keras.optimizers.Adam(),\n","    metrics = ['accuracy']\n",")"],"metadata":{"id":"iXL-Y8V0wuQR","executionInfo":{"status":"ok","timestamp":1706603735122,"user_tz":-330,"elapsed":368,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["model.fit(x_train, y_train, batch_size=32, epochs=2,verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HaOwSJJbxEJ8","executionInfo":{"status":"ok","timestamp":1706603748001,"user_tz":-330,"elapsed":10894,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e4cf7b06-4c40-4d64-acf2-a86a17afed10"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1875/1875 - 5s - loss: 0.3027 - accuracy: 0.9151 - 5s/epoch - 3ms/step\n","Epoch 2/2\n","1875/1875 - 5s - loss: 0.1447 - accuracy: 0.9575 - 5s/epoch - 3ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7ff9ca31b1f0>"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["model.evaluate(x_test, y_test, batch_size=32,verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xOJDG5rAxVe-","executionInfo":{"status":"ok","timestamp":1706603752985,"user_tz":-330,"elapsed":1032,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"343ccaab-36f2-4e62-976a-98fc87e0377b"},"execution_count":23,"outputs":[{"output_type":"stream","name":"stdout","text":["313/313 - 1s - loss: 0.1293 - accuracy: 0.9612 - 607ms/epoch - 2ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["[0.12932689487934113, 0.9611999988555908]"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fcZc6k9nxikX","executionInfo":{"status":"ok","timestamp":1706603755674,"user_tz":-330,"elapsed":589,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"53df2c05-4163-4835-d07a-87a1f5584666"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"my_model\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_1 (Dense)             multiple                  50240     \n","                                                                 \n"," dense_2 (Dense)             multiple                  650       \n","                                                                 \n","=================================================================\n","Total params: 50890 (198.79 KB)\n","Trainable params: 50890 (198.79 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Going in more Low-Level Understanding\n","\n","But alwasys there is way to go more and more low level Archetecture and use your coding skills to write each and every code by yourself."],"metadata":{"id":"RNbR_ZkCzsrk"}},{"cell_type":"code","source":["class Dense(layers.Layer):\n","    def __init__(self, units, input_dim): # demand type as per implementation # out nodes, in nodes\n","        super(Dense, self).__init__()\n","        self.w = self.add_weight(\n","            name='w',\n","            shape=(input_dim, units),\n","            initializer='random_normal',\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            name='b',\n","            shape=(units, ),\n","            initializer='zero',\n","            trainable=True,\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","class MyModel(keras.Model):\n","    def __init__(self, num_classes=10):\n","        super(MyModel, self).__init__()\n","        self.dense1 = Dense(64, 784)  # out nodes, in nodes\n","        self.dense2 = Dense(10, 64)   # out nodes, in nodes\n","        # self.dense1 = layers.Dense(64)\n","        # self.dense2 = layers.Dense(num_classes)\n","\n","    def call(self, input_tensor):\n","        x = tf.nn.relu(self.dense1(input_tensor))\n","        return self.dense2(x)\n","\n","model = MyModel()\n","\n","model.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=['accuracy']\n",")\n","\n","model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=2)\n","\n","model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n","\n","model.summary()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BZ62O3XsxpdY","executionInfo":{"status":"ok","timestamp":1706603770703,"user_tz":-330,"elapsed":10703,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"5f187590-2837-4514-acf0-7f737f16e559"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1875/1875 - 6s - loss: 0.3507 - accuracy: 0.9042 - 6s/epoch - 3ms/step\n","Epoch 2/2\n","1875/1875 - 4s - loss: 0.1630 - accuracy: 0.9532 - 4s/epoch - 2ms/step\n","313/313 - 1s - loss: 0.1342 - accuracy: 0.9606 - 568ms/epoch - 2ms/step\n","Model: \"my_model_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             multiple                  50240     \n","                                                                 \n"," dense_4 (Dense)             multiple                  650       \n","                                                                 \n","=================================================================\n","Total params: 50890 (198.79 KB)\n","Trainable params: 50890 (198.79 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["# More deeper low - level archetecture : low lewel 2 :RelU bhi khud se implement kr do\n","\n","class Dense(layers.Layer):\n","    def __init__(self, units, input_dim):\n","        super(Dense, self).__init__()\n","        self.w = self.add_weight(\n","            name=\"w\",\n","            shape=(input_dim, units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            name=\"b\", shape=(units,), initializer=\"zeros\", trainable=True\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","\n","class Dense(layers.Layer):\n","    def __init__(self, units):\n","        super(Dense, self).__init__()\n","        self.units = units\n","\n","    def build(self, input_shape):  # to make input shape free : to make model worth regardless of the input dimension\n","        self.w = self.add_weight(\n","            name=\"w\",\n","            shape=(input_shape[-1], self.units),\n","            initializer=\"random_normal\",\n","            trainable=True,\n","        )\n","        self.b = self.add_weight(\n","            name=\"b\", shape=(self.units,), initializer=\"random_normal\", trainable=True,\n","        )\n","\n","    def call(self, inputs):\n","        return tf.matmul(inputs, self.w) + self.b\n","\n","\n","class MyReLU(layers.Layer):\n","    def __init__(self):\n","        super(MyReLU, self).__init__()\n","\n","    def call(self, x):\n","        return tf.math.maximum(x, 0) # return max of x and 0, that is the definition of relu\n","\n","\n","class MyModel(keras.Model):  # model.fit, model.evalute, model.predict\n","    def __init__(self, num_classes=10):\n","        super(MyModel, self).__init__()\n","        self.dense1 = Dense(64) # removed 784 using build\n","        self.dense2 = Dense(num_classes) # removed 64 using build\n","        self.relu = MyReLU()\n","\n","        # self.dense1 = layers.Dense(64)\n","        # self.dense3 = layers.Dense(num_classes)\n","\n","    def call(self, x):\n","        x = self.relu(self.dense1(x))\n","        return self.dense2(x)\n","\n","\n","model = MyModel()\n","model.compile(\n","    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","    optimizer=keras.optimizers.Adam(),\n","    metrics=[\"accuracy\"],\n",")\n","\n","model.fit(x_train, y_train, batch_size=32, epochs=2, verbose=2)\n","model.evaluate(x_test, y_test, batch_size=32, verbose=2)\n","\n","model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z1oZwkYS2GM7","executionInfo":{"status":"ok","timestamp":1706603794967,"user_tz":-330,"elapsed":12196,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"a6c13098-228d-4d08-838d-d44de2a2602d"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/2\n","1875/1875 - 5s - loss: 0.3521 - accuracy: 0.9013 - 5s/epoch - 3ms/step\n","Epoch 2/2\n","1875/1875 - 5s - loss: 0.1648 - accuracy: 0.9514 - 5s/epoch - 2ms/step\n","313/313 - 1s - loss: 0.1352 - accuracy: 0.9620 - 582ms/epoch - 2ms/step\n","Model: \"my_model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_5 (Dense)             multiple                  50240     \n","                                                                 \n"," dense_6 (Dense)             multiple                  650       \n","                                                                 \n"," my_re_lu (MyReLU)           multiple                  0         \n","                                                                 \n","=================================================================\n","Total params: 50890 (198.79 KB)\n","Trainable params: 50890 (198.79 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["# Save and Load model weights"],"metadata":{"id":"2wDYiQB98D7Z"}},{"cell_type":"code","source":["# 1. How to save and load model weights\n","# 2. Save and load entire model (Serializing model) : can be loaded anywhere\n","#        -  Saves weights (1st saving way me keval ye hi save hoga, neeche ke 3 nhi)\n","#        -  saves model architechure (info of layers)\n","#        -  saves Training configuration ( model.compile() vala part)\n","#        -  savesoptimizer and states\n"],"metadata":{"id":"VdIwZOiW8GFs","executionInfo":{"status":"ok","timestamp":1706603809913,"user_tz":-330,"elapsed":412,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":27,"outputs":[]},{"cell_type":"code","source":["# 1st method\n","\n","!mkdir saved_weights # actually no need, since : uplabdh na hone pr pwd me autometically bn jayegi\n","\n","model.save_weights('/content/saved_weightss/')\n","\n","model.load_weights('/content/saved_weightss/')\n","\n","# ese loaded model ko direct use nhi kr skte, Upar and neeche ke similar surroundings ko bhi save krna padega"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r7hqKKUH-9x-","executionInfo":{"status":"ok","timestamp":1706603817596,"user_tz":-330,"elapsed":415,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"cfaa1063-968d-40f9-fe97-fc3daa6a3cb0"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x7ff9ca1305b0>"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["# method 2: sb kuch save kr lo, direct use kr lo : save and load entire model\n","\n","model.save('complete_saved_model/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EzbU4J0h-bNz","executionInfo":{"status":"ok","timestamp":1706603820957,"user_tz":-330,"elapsed":608,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"cbace0da-8eb1-4863-b7be-cf03ba9cdd7d"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:absl:<__main__.Dense object at 0x7ff9ca01ebf0> has the same name 'Dense' as a built-in Keras object. Consider renaming <class '__main__.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n","WARNING:absl:<__main__.Dense object at 0x7ff9ca02f790> has the same name 'Dense' as a built-in Keras object. Consider renaming <class '__main__.Dense'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"]}]},{"cell_type":"code","source":["model = keras.models.load_model('complete_saved_model/') # will load entire archetecture"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"G8ylHc7U_-_8","executionInfo":{"status":"error","timestamp":1706603849214,"user_tz":-330,"elapsed":1260,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"b155ba8b-5d44-4406-a7ac-213cd655bcdf"},"execution_count":30,"outputs":[{"output_type":"error","ename":"AssertionError","evalue":"Found 4 Python objects that were not bound to checkpointed values, likely due to changes in the Python program. Showing 4 of 4 unmatched objects: [<tf.Variable 'bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'kernel:0' shape=(784, 64) dtype=float32, numpy=\narray([[-0.03421028,  0.07117168, -0.03264965, ..., -0.03778302,\n        -0.06360114,  0.05851977],\n       [ 0.05722163,  0.04302598, -0.06910507, ..., -0.07023036,\n         0.0379024 , -0.05932433],\n       [-0.02371076, -0.04598011,  0.07623091, ...,  0.07894888,\n         0.01953138,  0.0577205 ],\n       ...,\n       [-0.03515815, -0.02682489, -0.02171834, ..., -0.07322237,\n         0.0276304 ,  0.03923805],\n       [-0.06413319, -0.02217992, -0.0056648 , ...,  0.06032573,\n        -0.00458031,  0.07585067],\n       [ 0.02137367, -0.0508049 ,  0.03844219, ...,  0.06865103,\n         0.04134674, -0.07979234]], dtype=float32)>, <tf.Variable 'kernel:0' shape=(64, 10) dtype=float32, numpy=\narray([[-0.23176852,  0.20131132, -0.05187078, -0.2525146 , -0.11545853,\n        -0.21479307, -0.09631646, -0.26348373,  0.10136741, -0.20945176],\n       [-0.11837117,  0.27024814,  0.04293129,  0.05501208,  0.07423452,\n         0.15169778,  0.15845269, -0.26035097,  0.05380663,  0.19656906],\n       [ 0.02206951,  0.1373933 ,  0.09064353,  0.26758495, -0.19230196,\n        -0.04574555,  0.2325724 ,  0.08172405,  0.16643065, -0.09180619],\n       [ 0.12172544, -0.23216717,  0.03954083, -0.08542638,  0.23578349,\n        -0.2137995 ,  0.24206337,  0.10749331,  0.04975331,  0.08339596],\n       [ 0.10401842,  0.12610722, -0.154527  ,  0.24836722, -0.18740138,\n        -0.05178095,  0.18610111,  0.06068021,  0.01424149,  0.1613028 ],\n       [ 0.03955564, -0.08503832, -0.21294424, -0.2495869 ,  0.14488384,\n         0.02355364,  0.06112182, -0.05950864, -0.01141515,  0.0338423 ],\n       [-0.156915  ,  0.23847833,  0.08827955, -0.12474345, -0.14440942,\n         0.12376699,  0.15671656, -0.09765469,  0.08283186,  0.23864093],\n       [ 0.12084654,  0.09218684, -0.03328615,  0.24221817, -0.22831278,\n        -0.07439685, -0.00922728, -0.21083134, -0.04299796, -0.03758298],\n       [-0.24701044, -0.09558156, -0.03037724, -0.12277575, -0.09548971,\n         0.02062288, -0.00278434, -0.2584418 , -0.27855015,  0.10750362],\n       [ 0.00739297, -0.231554  , -0.2530041 ,  0.00285047,  0.1587989 ,\n         0.28216204,  0.21799573, -0.02161595, -0.10041866,  0.22565857],\n       [ 0.22495791, -0.08619162, -0.06826647,  0.21463454,  0.23692313,\n         0.25068226, -0.01064202, -0.00057787, -0.1653037 ,  0.06138909],\n       [ 0.07577175, -0.10797213, -0.1302056 ,  0.0780021 , -0.14932004,\n        -0.01455495,  0.05472219, -0.03076786, -0.05873314, -0.24434105],\n       [ 0.23879567,  0.21145442,  0.04583904,  0.22946355,  0.19176155,\n         0.17839068, -0.2722691 ,  0.03431115, -0.2708505 , -0.15163778],\n       [ 0.08992952, -0.14063594,  0.00472215,  0.23339507,  0.27687553,\n        -0.10791606,  0.0655224 , -0.22626232,  0.02429554, -0.00812408],\n       [-0.1402762 ,  0.22476819, -0.07904582, -0.05684549,  0.18431005,\n         0.26860324,  0.20854768, -0.07718255,  0.22804472, -0.1920315 ],\n       [-0.05279835, -0.2808538 ,  0.12383911, -0.27106625, -0.10097392,\n        -0.12617733, -0.09967962, -0.14069602,  0.04075339,  0.23382977],\n       [-0.05278578, -0.01264331, -0.02477136, -0.01125276, -0.12679805,\n        -0.06803042, -0.13216738, -0.07431626,  0.0639824 ,  0.09319669],\n       [-0.14001775,  0.26102892, -0.07816693,  0.2642828 ,  0.2033287 ,\n        -0.14405952, -0.2421185 , -0.26211902,  0.01932177,  0.05297548],\n       [-0.22560617,  0.04109916,  0.14748675, -0.04203169, -0.08562054,\n        -0.17363647, -0.03728563,  0.1496326 ,  0.1347414 ,  0.04104328],\n       [ 0.06027111,  0.04090738, -0.04192957, -0.23313697,  0.2583659 ,\n         0.22493723, -0.19282302, -0.08631104, -0.20328309,  0.09406546],\n       [ 0.04452327, -0.25581193, -0.03904878, -0.1517026 , -0.18401265,\n        -0.18388113, -0.06464329, -0.1675879 ,  0.15940332,  0.23092374],\n       [-0.12745331, -0.03318709,  0.1595766 ,  0.2391353 ,  0.11250746,\n        -0.10208799,  0.10944077, -0.13783939,  0.06095195,  0.07658789],\n       [ 0.12826669,  0.20648772,  0.26214072,  0.09567824, -0.2452348 ,\n        -0.1673342 ,  0.01891586, -0.12656878,  0.25087503, -0.16127367],\n       [-0.19801211,  0.21283767, -0.17508401, -0.2692991 ,  0.00719902,\n        -0.15994197, -0.2272596 , -0.12052652,  0.09089321,  0.22493371],\n       [-0.13064994,  0.05290467, -0.17072804,  0.02216774,  0.25185987,\n        -0.008964  ,  0.0949859 ,  0.24960884, -0.2595993 , -0.09083924],\n       [ 0.01774782, -0.17240769,  0.1396802 , -0.07216798,  0.10108742,\n        -0.28227812, -0.24009058,  0.0572975 , -0.03422573,  0.0170919 ],\n       [ 0.05851018, -0.01499406, -0.00406066, -0.16041203, -0.24360146,\n         0.24235329,  0.1600895 ,  0.20740315, -0.20553823, -0.26979992],\n       [ 0.08549392, -0.23891175,  0.00161693, -0.02150765, -0.26085275,\n        -0.09783779,  0.04295266,  0.24190083,  0.12888163, -0.15716897],\n       [ 0.13030404, -0.23595165,  0.075387  , -0.02864158, -0.07203661,\n         0.07654187,  0.1636669 , -0.01691613, -0.01063746,  0.28314933],\n       [-0.2530988 , -0.1259499 , -0.12566973, -0.24414206, -0.08099112,\n        -0.19671075, -0.1700624 ,  0.0798237 ,  0.12233779, -0.07873428],\n       [-0.03964688,  0.09050143, -0.0775023 , -0.02569282,  0.24496183,\n        -0.09897344,  0.2563325 , -0.01839691,  0.08647248,  0.02439913],\n       [-0.02190271, -0.22741982,  0.27482834, -0.14743789,  0.09709671,\n         0.1455234 ,  0.2718474 , -0.10651687, -0.25109172, -0.01606432],\n       [-0.08594783,  0.21888939, -0.05383548, -0.24780793,  0.21181524,\n         0.26593515,  0.27590945,  0.13157994,  0.21185571, -0.0852299 ],\n       [-0.22384594,  0.18773338, -0.13128999, -0.18969503,  0.04260528,\n         0.12588167,  0.16591334,  0.13864407,  0.16810092,  0.08674988],\n       [-0.17044908,  0.18092668, -0.13922419,  0.1339046 ,  0.00288346,\n         0.20052767,  0.21751073, -0.2489765 ,  0.19675332,  0.09531462],\n       [-0.07465075, -0.06882186, -0.23960951,  0.17568773, -0.18802957,\n         0.23313889,  0.22771081,  0.17794716, -0.08515386, -0.22702178],\n       [ 0.07540378,  0.2801241 ,  0.17238873, -0.17119294, -0.07726523,\n         0.17278779,  0.09056029,  0.09781653,  0.13301194,  0.21945569],\n       [-0.1117951 ,  0.04827464, -0.20066291, -0.11891836, -0.19393292,\n         0.04012224, -0.18609494, -0.16585605,  0.11169809,  0.17285168],\n       [-0.06974855,  0.14600134,  0.17768586, -0.26059458, -0.15693372,\n         0.11415616, -0.16936979,  0.02769873,  0.1253446 , -0.08041494],\n       [-0.12115531,  0.19776914,  0.14427641,  0.05426687,  0.15776375,\n         0.12886629,  0.1364522 , -0.12990384,  0.05358741,  0.09078249],\n       [-0.11653315,  0.18032756,  0.20358622,  0.11919019, -0.15578179,\n         0.11302641,  0.14828193,  0.13233751, -0.12748535, -0.16711119],\n       [-0.00039348, -0.13791291,  0.21320066, -0.08363064, -0.10846385,\n         0.16830108,  0.01440966,  0.1820814 , -0.07232827,  0.16502482],\n       [ 0.07878622, -0.00723332, -0.14622979, -0.15432617, -0.13633421,\n        -0.27385542,  0.11501914,  0.15195245, -0.17502908, -0.1204572 ],\n       [-0.03669438, -0.23445721,  0.1863299 ,  0.01042137,  0.19598815,\n        -0.2189753 , -0.22194356,  0.01219735,  0.17673072,  0.11230338],\n       [-0.22163744, -0.25714615, -0.14346053, -0.25608802,  0.00638089,\n         0.0235514 ,  0.00914344,  0.1519889 ,  0.0610643 ,  0.05600429],\n       [ 0.2470145 ,  0.04665533,  0.25347552, -0.26840833,  0.07027769,\n         0.19059768, -0.25666142,  0.19887158,  0.18005913,  0.01959836],\n       [-0.26809937, -0.01078349,  0.23049101, -0.13414194,  0.19781566,\n        -0.12430543,  0.27468005, -0.03300887,  0.03557366,  0.18686974],\n       [ 0.25762632,  0.07839674, -0.02298981,  0.02396449,  0.12855074,\n         0.10011384, -0.07581376,  0.18545467,  0.2682458 ,  0.20717767],\n       [ 0.12371439,  0.26395765,  0.06817168,  0.24482122,  0.1678198 ,\n         0.06705356, -0.17437232,  0.17281476, -0.07787046,  0.16781914],\n       [-0.18586248,  0.14511254, -0.07952709,  0.18301365,  0.05793849,\n         0.03612736, -0.28442764,  0.09383538,  0.1092082 , -0.19417611],\n       [ 0.17320225,  0.232582  ,  0.17046538, -0.13378538, -0.05140859,\n        -0.06131816, -0.08405162,  0.09996617,  0.21306014, -0.16062933],\n       [-0.04026935, -0.03173658, -0.10711789, -0.2211519 , -0.26009953,\n        -0.13296448, -0.24154565, -0.10029095,  0.04683992,  0.01043692],\n       [ 0.11313292,  0.13261527, -0.13482368,  0.17738965, -0.17210591,\n        -0.04483312,  0.12303346, -0.05337188,  0.2174891 , -0.04830702],\n       [ 0.10021201, -0.2552294 , -0.22780672, -0.24720412, -0.18768504,\n        -0.23313846,  0.09453717,  0.07757968, -0.18839766, -0.25556514],\n       [ 0.18118593, -0.05099413,  0.24348804, -0.2624594 , -0.23416345,\n        -0.2419641 ,  0.12157702,  0.24175945,  0.22166768, -0.18307266],\n       [-0.09305935,  0.03779867,  0.01156491, -0.2372184 , -0.21461657,\n         0.09184122, -0.16707453, -0.17736617, -0.11663105, -0.07365149],\n       [ 0.15081686, -0.28211275, -0.09507592,  0.17258874, -0.26828647,\n         0.27003106,  0.05515641, -0.03188932, -0.02044025, -0.15334335],\n       [-0.2401457 , -0.03189307, -0.12905923, -0.11305845,  0.19217604,\n        -0.21384507, -0.06549516,  0.24101213, -0.11089659, -0.06996858],\n       [ 0.15425551,  0.18640417,  0.16489276,  0.19972232, -0.14443447,\n         0.18936238, -0.02546594, -0.2722053 ,  0.10246769,  0.05509421],\n       [-0.01703587, -0.2490148 ,  0.25426725, -0.2605702 , -0.04012597,\n        -0.00662604,  0.20342892,  0.03520021, -0.09434862,  0.03608289],\n       [ 0.05563477, -0.03763641, -0.10833269, -0.12374955, -0.22587705,\n         0.1501464 ,  0.26105514,  0.22735962, -0.2235253 ,  0.20085081],\n       [-0.22589625, -0.27915707, -0.17572331,  0.0142495 , -0.27053544,\n        -0.25839713,  0.24972877, -0.04838522, -0.09234299,  0.15467864],\n       [-0.12323332,  0.2491881 ,  0.0862526 , -0.08226322, -0.26124534,\n         0.13826934,  0.11360916,  0.09156641,  0.11136076, -0.15503006],\n       [-0.2695731 , -0.15442231, -0.13849702,  0.04423237,  0.08271584,\n         0.25188795,  0.10231024, -0.12062408,  0.01589915, -0.07981731]],\n      dtype=float32)>, <tf.Variable 'bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-8bbfdb8c9de1>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'complete_saved_model/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# will load entire archetecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/saving/saving_api.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, safe_mode, **kwargs)\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[0;31m# Legacy case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m     return legacy_sm_saving_lib.load_model(\n\u001b[0m\u001b[1;32m    263\u001b[0m         \u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/checkpoint/checkpoint.py\u001b[0m in \u001b[0;36massert_existing_objects_matched\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0;31m# Display max number of 10 variables in error message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m       \u001b[0mnum_variables_to_show\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_unused_python_objects\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       raise AssertionError(\n\u001b[0m\u001b[1;32m    885\u001b[0m           \u001b[0;34mf\"Found {num_unused_python_objects} Python objects that were \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m           \u001b[0;34m\"not bound to checkpointed values, likely due to changes in the \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAssertionError\u001b[0m: Found 4 Python objects that were not bound to checkpointed values, likely due to changes in the Python program. Showing 4 of 4 unmatched objects: [<tf.Variable 'bias:0' shape=(64,) dtype=float32, numpy=\narray([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>, <tf.Variable 'kernel:0' shape=(784, 64) dtype=float32, numpy=\narray([[-0.03421028,  0.07117168, -0.03264965, ..., -0.03778302,\n        -0.06360114,  0.05851977],\n       [ 0.05722163,  0.04302598, -0.06910507, ..., -0.07023036,\n         0.0379024 , -0.05932433],\n       [-0.02371076, -0.04598011,  0.07623091, ...,  0.07894888,\n         0.01953138,  0.0577205 ],\n       ...,\n       [-0.03515815, -0.02682489, -0.02171834, ..., -0.07322237,\n         0.0276304 ,  0.03923805],\n       [-0.06413319, -0.02217992, -0.0056648 , ...,  0.06032573,\n        -0.00458031,  0.07585067],\n       [ 0.02137367, -0.0508049 ,  0.03844219, ...,  0.06865103,\n         0.04134674, -0.07979234]], dtype=float32)>, <tf.Variable 'kernel:0' shape=(64, 10) dtype=float32, numpy=\narray([[-0.23176852,  0.20131132, -0.05187078, -0.2525146 , -0.11545853,\n        -0.21479307, -0.09631646, -0.26348373,  0.10136741, -0.20945176],\n       [-0.11837117,  0.27024814,  0.04293129,  0.05501208,  0.07423452,\n         0.15169778,  0.15845269, -0.26035097,  0.05380663,  0.19656906],\n       [ 0.02206951,  0.1373933 ,  0.09064353,  0.26758495, -0.19230196,\n        -0.04574555,  0.2325724 ,  0.08172405,  0.16643065, -0.09180619],\n       [ 0.12172544, -0.23216717,  0.03954083, -0.08542638,  0.23578349,\n        -0.2137995 ,  0.24206337,  0.10749331,  0.04975331,  0.08339596],\n       [ 0.10401842,  0.12610722, -0.154527  ,  0.24836722, -0.18740138,\n        -0.05178095,  0.18610111,  0.06068021,  0.01424149,  0.1613028 ],\n       [ 0.03955564, -0.08503832, -0.21294424, -0.2495869 ,  0.14488384,\n         0.02355364,  0.06112182, -0.05950864, -0.01141515,  0.0338423 ],\n       [-0.156915  ,  0.23847833,  0.08827955, -0.12474345, -0.14440942,\n         0.12376699,  0.15671656, -0.09765469,  0.08283186,  0.23864093],\n       [ 0.12084654,  0.09218684, -0.03328615,  0.24221817, -0.22831278,\n        -0.07439685, -0.00922728, -0.21083134, -0.04299796, -0.03758298],\n       [-0.24701044, -0.09558156, -0.03037724, -0.12277575, -0.09548971,\n         0.02062288, -0.00278434, -0.2584418 , -0.27855015,  0.10750362],\n       [ 0.00739297, -0.231554  , -0.2530041 ,  0.00285047,  0.1587989 ,\n         0.28216204,  0.21799573, -0.02161595, -0.10041866,  0.22565857],\n       [ 0.22495791, -0.08619162, -0.06826647,  0.21463454,  0.23692313,\n         0.25068226, -0.01064202, -0.00057787, -0.1653037 ,  0.06138909],\n       [ 0.07577175, -0.10797213, -0.1302056 ,  0.0780021 , -0.14932004,\n        -0.01455495,  0.05472219, -0.03076786, -0.05873314, -0.24434105],\n       [ 0.23879567,  0.21145442,  0.04583904,  0.22946355,  0.19176155,\n         0.17839068, -0.2722691 ,  0.03431115, -0.2708505 , -0.15163778],\n       [ 0.08992952, -0.14063594,  0.00472215,  0.23339507,  0.27687553,\n        -0.10791606,  0.0655224 , -0.22626232,  0.02429554, -0.00812408],\n       [-0.1402762 ,  0.22476819, -0.07904582, -0.05684549,  0.18431005,\n         0.26860324,  0.20854768, -0.07718255,  0.22804472, -0.1920315 ],\n       [-0.05279835, -0.2808538 ,  0.12383911, -0.27106625, -0.10097392,\n        -0.12617733, -0.09967962, -0.14069602,  0.04075339,  0.23382977],\n       [-0.05278578, -0.01264331, -0.02477136, -0.01125276, -0.12679805,\n        -0.06803042, -0.13216738, -0.07431626,  0.0639824 ,  0.09319669],\n       [-0.14001775,  0.26102892, -0.07816693,  0.2642828 ,  0.2033287 ,\n        -0.14405952, -0.2421185 , -0.26211902,  0.01932177,  0.05297548],\n       [-0.22560617,  0.04109916,  0.14748675, -0.04203169, -0.08562054,\n        -0.17363647, -0.03728563,  0.1496326 ,  0.1347414 ,  0.04104328],\n       [ 0.06027111,  0.04090738, -0.04192957, -0.23313697,  0.2583659 ,\n         0.22493723, -0.19282302, -0.08631104, -0.20328309,  0.09406546],\n       [ 0.04452327, -0.25581193, -0.03904878, -0.1517026 , -0.18401265,\n        -0.18388113, -0.06464329, -0.1675879 ,  0.15940332,  0.23092374],\n       [-0.12745331, -0.03318709,  0.1595766 ,  0.2391353 ,  0.11250746,\n        -0.10208799,  0.10944077, -0.13783939,  0.06095195,  0.07658789],\n       [ 0.12826669,  0.20648772,  0.26214072,  0.09567824, -0.2452348 ,\n        -0.1673342 ,  0.01891586, -0.12656878,  0.25087503, -0.16127367],\n       [-0.19801211,  0.21283767, -0.17508401, -0.2692991 ,  0.00719902,\n        -0.15994197, -0.2272596 , -0.12052652,  0.09089321,  0.22493371],\n       [-0.13064994,  0.05290467, -0.17072804,  0.02216774,  0.25185987,\n        -0.008964  ,  0.0949859 ,  0.24960884, -0.2595993 , -0.09083924],\n       [ 0.01774782, -0.17240769,  0.1396802 , -0.07216798,  0.10108742,\n        -0.28227812, -0.24009058,  0.0572975 , -0.03422573,  0.0170919 ],\n       [ 0.05851018, -0.01499406, -0.00406066, -0.16041203, -0.24360146,\n         0.24235329,  0.1600895 ,  0.20740315, -0.20553823, -0.26979992],\n       [ 0.08549392, -0.23891175,  0.00161693, -0.02150765, -0.26085275,\n        -0.09783779,  0.04295266,  0.24190083,  0.12888163, -0.15716897],\n       [ 0.13030404, -0.23595165,  0.075387  , -0.02864158, -0.07203661,\n         0.07654187,  0.1636669 , -0.01691613, -0.01063746,  0.28314933],\n       [-0.2530988 , -0.1259499 , -0.12566973, -0.24414206, -0.08099112,\n        -0.19671075, -0.1700624 ,  0.0798237 ,  0.12233779, -0.07873428],\n       [-0.03964688,  0.09050143, -0.0775023 , -0.02569282,  0.24496183,\n        -0.09897344,  0.2563325 , -0.01839691,  0.08647248,  0.02439913],\n       [-0.02190271, -0.22741982,  0.27482834, -0.14743789,  0.09709671,\n         0.1455234 ,  0.2718474 , -0.10651687, -0.25109172, -0.01606432],\n       [-0.08594783,  0.21888939, -0.05383548, -0.24780793,  0.21181524,\n         0.26593515,  0.27590945,  0.13157994,  0.21185571, -0.0852299 ],\n       [-0.22384594,  0.18773338, -0.13128999, -0.18969503,  0.04260528,\n         0.12588167,  0.16591334,  0.13864407,  0.16810092,  0.08674988],\n       [-0.17044908,  0.18092668, -0.13922419,  0.1339046 ,  0.00288346,\n         0.20052767,  0.21751073, -0.2489765 ,  0.19675332,  0.09531462],\n       [-0.07465075, -0.06882186, -0.23960951,  0.17568773, -0.18802957,\n         0.23313889,  0.22771081,  0.17794716, -0.08515386, -0.22702178],\n       [ 0.07540378,  0.2801241 ,  0.17238873, -0.17119294, -0.07726523,\n         0.17278779,  0.09056029,  0.09781653,  0.13301194,  0.21945569],\n       [-0.1117951 ,  0.04827464, -0.20066291, -0.11891836, -0.19393292,\n         0.04012224, -0.18609494, -0.16585605,  0.11169809,  0.17285168],\n       [-0.06974855,  0.14600134,  0.17768586, -0.26059458, -0.15693372,\n         0.11415616, -0.16936979,  0.02769873,  0.1253446 , -0.08041494],\n       [-0.12115531,  0.19776914,  0.14427641,  0.05426687,  0.15776375,\n         0.12886629,  0.1364522 , -0.12990384,  0.05358741,  0.09078249],\n       [-0.11653315,  0.18032756,  0.20358622,  0.11919019, -0.15578179,\n         0.11302641,  0.14828193,  0.13233751, -0.12748535, -0.16711119],\n       [-0.00039348, -0.13791291,  0.21320066, -0.08363064, -0.10846385,\n         0.16830108,  0.01440966,  0.1820814 , -0.07232827,  0.16502482],\n       [ 0.07878622, -0.00723332, -0.14622979, -0.15432617, -0.13633421,\n        -0.27385542,  0.11501914,  0.15195245, -0.17502908, -0.1204572 ],\n       [-0.03669438, -0.23445721,  0.1863299 ,  0.01042137,  0.19598815,\n        -0.2189753 , -0.22194356,  0.01219735,  0.17673072,  0.11230338],\n       [-0.22163744, -0.25714615, -0.14346053, -0.25608802,  0.00638089,\n         0.0235514 ,  0.00914344,  0.1519889 ,  0.0610643 ,  0.05600429],\n       [ 0.2470145 ,  0.04665533,  0.25347552, -0.26840833,  0.07027769,\n         0.19059768, -0.25666142,  0.19887158,  0.18005913,  0.01959836],\n       [-0.26809937, -0.01078349,  0.23049101, -0.13414194,  0.19781566,\n        -0.12430543,  0.27468005, -0.03300887,  0.03557366,  0.18686974],\n       [ 0.25762632,  0.07839674, -0.02298981,  0.02396449,  0.12855074,\n         0.10011384, -0.07581376,  0.18545467,  0.2682458 ,  0.20717767],\n       [ 0.12371439,  0.26395765,  0.06817168,  0.24482122,  0.1678198 ,\n         0.06705356, -0.17437232,  0.17281476, -0.07787046,  0.16781914],\n       [-0.18586248,  0.14511254, -0.07952709,  0.18301365,  0.05793849,\n         0.03612736, -0.28442764,  0.09383538,  0.1092082 , -0.19417611],\n       [ 0.17320225,  0.232582  ,  0.17046538, -0.13378538, -0.05140859,\n        -0.06131816, -0.08405162,  0.09996617,  0.21306014, -0.16062933],\n       [-0.04026935, -0.03173658, -0.10711789, -0.2211519 , -0.26009953,\n        -0.13296448, -0.24154565, -0.10029095,  0.04683992,  0.01043692],\n       [ 0.11313292,  0.13261527, -0.13482368,  0.17738965, -0.17210591,\n        -0.04483312,  0.12303346, -0.05337188,  0.2174891 , -0.04830702],\n       [ 0.10021201, -0.2552294 , -0.22780672, -0.24720412, -0.18768504,\n        -0.23313846,  0.09453717,  0.07757968, -0.18839766, -0.25556514],\n       [ 0.18118593, -0.05099413,  0.24348804, -0.2624594 , -0.23416345,\n        -0.2419641 ,  0.12157702,  0.24175945,  0.22166768, -0.18307266],\n       [-0.09305935,  0.03779867,  0.01156491, -0.2372184 , -0.21461657,\n         0.09184122, -0.16707453, -0.17736617, -0.11663105, -0.07365149],\n       [ 0.15081686, -0.28211275, -0.09507592,  0.17258874, -0.26828647,\n         0.27003106,  0.05515641, -0.03188932, -0.02044025, -0.15334335],\n       [-0.2401457 , -0.03189307, -0.12905923, -0.11305845,  0.19217604,\n        -0.21384507, -0.06549516,  0.24101213, -0.11089659, -0.06996858],\n       [ 0.15425551,  0.18640417,  0.16489276,  0.19972232, -0.14443447,\n         0.18936238, -0.02546594, -0.2722053 ,  0.10246769,  0.05509421],\n       [-0.01703587, -0.2490148 ,  0.25426725, -0.2605702 , -0.04012597,\n        -0.00662604,  0.20342892,  0.03520021, -0.09434862,  0.03608289],\n       [ 0.05563477, -0.03763641, -0.10833269, -0.12374955, -0.22587705,\n         0.1501464 ,  0.26105514,  0.22735962, -0.2235253 ,  0.20085081],\n       [-0.22589625, -0.27915707, -0.17572331,  0.0142495 , -0.27053544,\n        -0.25839713,  0.24972877, -0.04838522, -0.09234299,  0.15467864],\n       [-0.12323332,  0.2491881 ,  0.0862526 , -0.08226322, -0.26124534,\n         0.13826934,  0.11360916,  0.09156641,  0.11136076, -0.15503006],\n       [-0.2695731 , -0.15442231, -0.13849702,  0.04423237,  0.08271584,\n         0.25188795,  0.10231024, -0.12062408,  0.01589915, -0.07981731]],\n      dtype=float32)>, <tf.Variable 'bias:0' shape=(10,) dtype=float32, numpy=array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)>]"]}]},{"cell_type":"code","source":[],"metadata":{"id":"3Vew35obAQnS"},"execution_count":null,"outputs":[]}]}