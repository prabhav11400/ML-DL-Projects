{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNm6jAf3VLuLGmZx7CB+CpZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["**Keras = A neural network API, written in python and integrated with tensorflow.**\n","\n","keras is now completely integrated with tensorflow."],"metadata":{"id":"tb-labuA_SFw"}},{"cell_type":"markdown","source":["**Define Sequential models..**\n","\n","**then models apart from sequential models**\n","\n","\n"],"metadata":{"id":"bW4g7OVkCeAd"}},{"cell_type":"markdown","source":["In deep learning, a sequential model refers to a linear stack of layers where each layer has exactly one input tensor and one output tensor. It's called \"sequential\" because the data flows sequentially through each layer from the input to the output. This type of architecture is common in feedforward neural networks.\n","\n","In the context of frameworks like TensorFlow or Keras, a sequential model is a way to create and define a neural network by adding one layer at a time, in a step-by-step fashion. You start with an empty sequential model and then add layers to it, specifying the number of neurons (units) in each layer, the activation function, and other parameters.\n","\n","Here's a simple example of creating a sequential model using Keras (a high-level neural networks API built on top of TensorFlow):\n","\n","```python\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# Create a sequential model\n","model = Sequential()\n","\n","# Add layers to the model\n","model.add(Dense(units=32, input_dim=100, activation='relu'))\n","model.add(Dense(units=10, activation='softmax'))\n","```\n","\n","In this example, the model starts with an input layer of 100 neurons, followed by a hidden layer with 32 neurons and a ReLU activation function. Finally, there's an output layer with 10 neurons and a softmax activation function, which is often used for multi-class classification problems.\n","\n","Sequential models are suitable for simple and straightforward architectures where the data flows in a single direction through the network. For more complex architectures, such as networks with multiple inputs or outputs, shared layers, or non-linear connections, you may need to use other model types or functional APIs provided by deep learning frameworks."],"metadata":{"id":"vBhEaLEpCraN"}},{"cell_type":"code","source":[],"metadata":{"id":"AzEOg6D6DMBo","executionInfo":{"status":"ok","timestamp":1703144835598,"user_tz":-330,"elapsed":444,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["Certainly! Here are the **definitions and code explanations for four different neural network architectures: Sequential Model, Functional API, Recurrent Neural Network (RNN), and Convolutional Neural Network (CNN).**\n","\n","### 1. Sequential Model:\n","\n","In deep learning, a sequential model refers to a linear stack of layers where each layer has exactly one input tensor and one output tensor. It's called \"sequential\" because the data flows sequentially through each layer from the input to the output. This type of architecture is common in feedforward neural networks.\n","\n","In the context of frameworks like TensorFlow or Keras, a sequential model is a way to create and define a neural network by adding one layer at a time, in a step-by-step fashion. You start with an empty sequential model and then add layers to it, specifying the number of neurons (units) in each layer, the activation function, and other parameters.\n","\n","Here's a simple example of creating a sequential model using Keras (a high-level neural networks API built on top of TensorFlow):\n","\n","```python\n","from keras.models import Sequential\n","from keras.layers import Dense\n","\n","# Create a sequential model\n","model = Sequential()\n","\n","# Add layers to the model\n","model.add(Dense(units=32, input_dim=100, activation='relu'))\n","model.add(Dense(units=10, activation='softmax'))\n","```\n","\n","**Explanation:**\n","- **Sequential Model Initialization:** The model is initialized as an empty sequential model.\n","- **Dense Layers:** Two dense layers are added to the model. The first layer has 32 neurons, uses the ReLU activation function, and specifies an input dimension of 100. The second layer has 10 neurons with a softmax activation function.\n","\n","---\n","\n","### 2. Functional API:\n","\n","In deep learning, a functional API allows for more complex model architectures, including models with multiple inputs and outputs, shared layers, and non-linear connections. Unlike the sequential model, it does not rely on a linear stack of layers. Instead, it enables the definition of a directed acyclic graph of layers, providing more flexibility in designing intricate neural network structures.\n","\n","Here's an example of creating a model using the Functional API in Keras:\n","\n","```python\n","from keras.layers import Input, Dense, concatenate\n","from keras.models import Model\n","\n","# Define input layers\n","input1 = Input(shape=(100,))\n","input2 = Input(shape=(50,))\n","\n","# Create shared dense layer\n","shared_layer = Dense(units=32, activation='relu')\n","\n","# Connect layers using the functional API\n","x1 = shared_layer(input1)\n","x2 = shared_layer(input2)\n","merged = concatenate([x1, x2])\n","output = Dense(units=10, activation='softmax')(merged)\n","\n","# Create model\n","model = Model(inputs=[input1, input2], outputs=output)\n","```\n","\n","**Explanation:**\n","- **Input Layers:** `input1` and `input2` represent the input layers with specified input shapes.\n","- **Shared Dense Layer:** `shared_layer` is a dense layer with 32 neurons and a ReLU activation function. It will be shared between the two input branches.\n","- **Functional Connections:** The `shared_layer` is applied to both `input1` and `input2`. The outputs are then concatenated into a single merged layer.\n","- **Output Layer:** A dense layer with 10 neurons and a softmax activation function is added on top of the merged layer.\n","- **Model Creation:** The `Model` class is used to create the final model, specifying the inputs and outputs.\n","\n","---\n","\n","### 3. Recurrent Neural Network (RNN):\n","\n","Recurrent Neural Networks (RNNs) are designed for sequential data and have connections that form cycles, allowing them to maintain a memory of previous inputs. They are suitable for tasks such as natural language processing, time series analysis, and speech recognition.\n","\n","```python\n","from keras.models import Sequential\n","from keras.layers import SimpleRNN, Dense\n","\n","model = Sequential()\n","model.add(SimpleRNN(units=32, input_shape=(None, 100)))\n","model.add(Dense(units=10, activation='softmax'))\n","```\n","\n","**Explanation:**\n","- **Sequential Model Initialization:** The model is initialized as a sequential model.\n","- **Simple RNN Layer:** `SimpleRNN` layer with 32 units is added to the model. It processes input sequences of shape `(None, 100)` where `None` indicates sequences of variable lengths.\n","- **Dense Output Layer:** A dense layer with 10 neurons and a softmax activation function is added for the final output.\n","\n","---\n","\n","### 4. Convolutional Neural Network (CNN):\n","\n","Convolutional Neural Networks (CNNs) are primarily used for image-related tasks and are designed to automatically and adaptively learn spatial hierarchies of features from input images.\n","\n","```python\n","from keras.models import Sequential\n","from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n","\n","model = Sequential()\n","model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(64, 64, 3)))\n","model.add(MaxPooling2D((2, 2)))\n","model.add(Flatten())\n","model.add(Dense(units=10, activation='softmax'))\n","```\n","\n","**Explanation:**\n","- **Sequential Model Initialization:** The model is initialized as a sequential model.\n","- **Convolutional Layer:** `Conv2D` layer with 32 filters of size `(3, 3)` and ReLU activation is added. The input shape is set to `(64, 64, 3)` representing images of size 64x64 with 3 color channels.\n","- **MaxPooling Layer:** `MaxPooling2D` layer with a pool size of `(2, 2)` is added to downsample the spatial dimensions.\n","- **Flatten Layer:** Flattens the 3D output to a 1D vector before the dense layer.\n","- **Dense Output Layer:** A dense layer with 10 neurons and a softmax activation function is added for the final output.\n","\n","I appreciate your understanding, and I hope this provides a comprehensive overview of these different model architectures."],"metadata":{"id":"hfOg-pPJDIF3"}},{"cell_type":"markdown","source":["# Data Preparation and Preprocessing"],"metadata":{"id":"GmAEmYpeHdre"}},{"cell_type":"code","execution_count":23,"metadata":{"id":"4xGhQjH7-rqi","executionInfo":{"status":"ok","timestamp":1703144836017,"user_tz":-330,"elapsed":29,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"outputs":[],"source":["import numpy as np\n","from random import randint\n","from sklearn.utils import shuffle\n","from sklearn.preprocessing import MinMaxScaler"]},{"cell_type":"code","source":["train_labels = []\n","train_samples = []"],"metadata":{"id":"-5GVH2F6Hvjj","executionInfo":{"status":"ok","timestamp":1703144836018,"user_tz":-330,"elapsed":28,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":["Example Data\n","\n","- An experimental drug was tested on individuals from ages 13 to 100 in a clinical trial.\n","- The trial had 2100 participants. Half were under 65 years old, half were 65 years or older.\n","- Around 95% of the participants 65 or older experienced side effect.\n","- Around 95% of participants under 65 experienced no side effects. Means below 65 years old, only 5% experienced side effects.\n"],"metadata":{"id":"mhyhDXfaIHQq"}},{"cell_type":"markdown","source":["Creating the data ourselves this time, for now.."],"metadata":{"id":"V2TPu9T3JGIe"}},{"cell_type":"code","source":["for i in range(50):\n","  # the ~5% of younger(yuva = young man) individuals who experienced side effect.(elder = bujurg, younger = chota/ yuva)\n","  # 1 = yes, side effect,  0 = no side effect\n","  random_younger = randint(13,64) # randint me 13 and 64 included, will generate just 1 random number between 13 and 64(inclusive) in each call\n","  train_samples.append(random_younger)\n","  train_labels.append(1)\n","\n","  # the ~5% of older individuals who did not experience side effects\n","  random_older = randint(65, 100) # generates one number in [65,100]\n","  train_samples.append(random_older)\n","  train_labels.append(0)\n","\n","for i in range(1000):\n","  # the 95% of youger individuals who did not experience side effects\n","  random_younger = randint(13,64)\n","  train_samples.append(random_younger)\n","  train_labels.append(0)\n","\n","  # the 95% of the older ppls who did experience side-effects\n","  random_older = randint(65, 100)\n","  train_samples.append(random_older)\n","  train_labels.append(1)\n"],"metadata":{"id":"Bae7UG7FHzeN","executionInfo":{"status":"ok","timestamp":1703144836018,"user_tz":-330,"elapsed":27,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["len(train_samples)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DnB3dQRnNUCE","executionInfo":{"status":"ok","timestamp":1703144836019,"user_tz":-330,"elapsed":27,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"a50c59a8-9b2d-486d-eeac-8a4d5c191544"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2100"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["len(train_labels)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CxfGV8S9NvY_","executionInfo":{"status":"ok","timestamp":1703144836020,"user_tz":-330,"elapsed":24,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"ca3557e7-73ef-4baf-9bc4-3eeca62e98a3"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["2100"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["train_labels.count(1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1BL07LQZNzb_","executionInfo":{"status":"ok","timestamp":1703144836021,"user_tz":-330,"elapsed":22,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"d4203166-46d0-4a4f-9472-622264b0e895"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1050"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["train_labels.count(0)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jWfpk5FgN6_a","executionInfo":{"status":"ok","timestamp":1703144836021,"user_tz":-330,"elapsed":19,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"18519bc4-1e2a-498b-cb69-972055bafcbe"},"execution_count":29,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1050"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["for i in range(5):\n","  print(train_samples[i], \" \", train_labels[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WiOTWCTcOMiO","executionInfo":{"status":"ok","timestamp":1703144836022,"user_tz":-330,"elapsed":17,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e5b8215f-816a-4fd1-85f0-98b55458fd1b"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["15   1\n","83   0\n","19   1\n","99   0\n","16   1\n"]}]},{"cell_type":"code","source":["train_labels = np.array(train_labels)\n","train_samples = np.array(train_samples)\n","train_labels, train_samples = shuffle(train_labels, train_samples)"],"metadata":{"id":"TwdZVkdWOh0S","executionInfo":{"status":"ok","timestamp":1703144836590,"user_tz":-330,"elapsed":580,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["for i in range(5):\n","  print(train_samples[i], \" \", train_labels[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jsB1QnvldxQv","executionInfo":{"status":"ok","timestamp":1703144836592,"user_tz":-330,"elapsed":47,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"c23ed5d6-142d-418f-9b15-e6ad77e82ca2"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["19   0\n","67   1\n","65   1\n","17   0\n","22   0\n"]}]},{"cell_type":"markdown","source":["The `shuffle` function from scikit-learn's `utils` module shuffles the samples and corresponding labels while maintaining the mapping between them. It means that after shuffling, the relationship between a sample and its corresponding label will still be preserved.\n","\n","In the code snippet you provided:\n","\n","```python\n","from sklearn.utils import shuffle\n","train_labels, train_samples = shuffle(train_labels, train_samples)\n","```\n","\n","`train_labels` and `train_samples` are two arrays (or lists) representing labels and corresponding samples, respectively. The `shuffle` function shuffles these arrays in a way that the order of elements in `train_samples` is changed, but the order is consistent across both arrays. This ensures that the relationship between a sample and its label is not broken during the shuffling process.\n","\n","This can be particularly useful when you want to randomize the order of your data to avoid any potential biases during training, while still preserving the association between input samples and their corresponding labels."],"metadata":{"id":"x7HeqnJkPxF_"}},{"cell_type":"code","source":["scaler = MinMaxScaler(feature_range=(0,1))\n","scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1,1)) # column form mr badal dega reshape (-1,1). Fit transform does not accept 1D data by default.\n","# scaled_train_sample is now a 2D array. each 1D array is of just 1 value, but anyway 2D toh bna"],"metadata":{"id":"F4lx4T8RPG62","executionInfo":{"status":"ok","timestamp":1703144836594,"user_tz":-330,"elapsed":46,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":["The code you provided is using scikit-learn's `MinMaxScaler` to scale the values in `train_samples` to a specified range. Here's an explanation of each part of the code:\n","\n","```python\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# Create a MinMaxScaler with a specified feature range of (0, 1)\n","scaler = MinMaxScaler(feature_range=(0, 1))\n","\n","# Reshape train_samples to a column vector (-1 indicates automatic inference of the size)\n","scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1, 1))\n","```\n","\n","Explanation:\n","\n","1. **Import MinMaxScaler:**\n","   - `from sklearn.preprocessing import MinMaxScaler`: Import the `MinMaxScaler` class from scikit-learn's preprocessing module. This scaler is used to scale features to a specified range, in this case, between 0 and 1.\n","\n","2. **Create MinMaxScaler:**\n","   - `scaler = MinMaxScaler(feature_range=(0, 1))`: Create an instance of `MinMaxScaler` with the specified feature range. The `feature_range` parameter is set to `(0, 1)`, meaning that the scaled values will be in the range [0, 1].\n","\n","3. **Reshape and Scale:**\n","   - `scaled_train_samples = scaler.fit_transform(train_samples.reshape(-1, 1))`: Reshape `train_samples` to a column vector using `reshape(-1, 1)` to make it compatible with the scaler. The `fit_transform` method then scales the values using the fitted scaler. The resulting `scaled_train_samples` will contain the scaled values between 0 and 1.\n","\n","In summary, this code snippet is preparing and scaling the `train_samples` using Min-Max scaling, which is a common technique to normalize data within a specific range. After scaling, the `scaled_train_samples` will have values between 0 and 1, preserving the relationships between the original samples. This type of preprocessing can be beneficial for machine learning models, especially those that are sensitive to the scale of input features."],"metadata":{"id":"bNO805ACRIoW"}},{"cell_type":"code","source":["for i in range(5):\n","  print(scaled_train_samples[i], \" \", train_labels[i])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"e4j-hRzxd0rl","executionInfo":{"status":"ok","timestamp":1703144836594,"user_tz":-330,"elapsed":45,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e3c1662c-cd53-460b-e78a-65977e620ff9"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.06896552]   0\n","[0.62068966]   1\n","[0.59770115]   1\n","[0.04597701]   0\n","[0.10344828]   0\n"]}]},{"cell_type":"code","source":["scaled_train_samples"],"metadata":{"id":"fjcT4Qs1RJRj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1703144836594,"user_tz":-330,"elapsed":42,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"64178e02-23b0-4627-e6e9-8f435926bb35"},"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.06896552],\n","       [0.62068966],\n","       [0.59770115],\n","       ...,\n","       [0.04597701],\n","       [0.4137931 ],\n","       [0.37931034]])"]},"metadata":{},"execution_count":35}]},{"cell_type":"markdown","source":["Create an ANN with tensorflow keras API."],"metadata":{"id":"1KAmkiUMe_nv"}},{"cell_type":"markdown","source":["Simple tf.keras Sequential Model."],"metadata":{"id":"XO_j78LofNXG"}},{"cell_type":"code","source":["import tensorflow as tf  # Import TensorFlow library for deep learning tasks.\n","from tensorflow import keras  # Import Keras, a high-level neural networks API, which is integrated into TensorFlow.\n","from tensorflow.keras.models import Sequential  # Import the Sequential model for building linear stack of layers.\n","from tensorflow.keras.layers import Activation, Dense  # Import Activation and Dense layers for defining neural network architecture.\n","from tensorflow.keras.optimizers import Adam  # Import the Adam optimizer for model optimization during training.\n","from tensorflow.keras.metrics import categorical_crossentropy  # Import categorical crossentropy metric for multi-class classification tasks."],"metadata":{"id":"DYE0oQ3veha9","executionInfo":{"status":"ok","timestamp":1703144836594,"user_tz":-330,"elapsed":39,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["'''\n","physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","print(\"Num GPU's Available \", len(physical_devices))\n","tf.config.experimental.set_memory_growth(physical_devices[0],True) # GPU mode on krke ke bad hi ye line run krna\n","'''"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":70},"id":"Kkc45Rlbf0sJ","executionInfo":{"status":"ok","timestamp":1703144836594,"user_tz":-330,"elapsed":38,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"69e066b2-6ca7-4db1-ccc1-0c2da928e381"},"execution_count":37,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'\\nphysical_devices = tf.config.experimental.list_physical_devices(\\'GPU\\')\\nprint(\"Num GPU\\'s Available \", len(physical_devices))\\ntf.config.experimental.set_memory_growth(physical_devices[0],True) # GPU mode on krke ke bad hi ye line run krna\\n'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","source":["The code you provided is using TensorFlow to interact with GPUs. Let's break down each line:\n","\n","1. **Listing Physical GPUs:**\n","    ```python\n","    physical_devices = tf.config.experimental.list_physical_devices('GPU')\n","    ```\n","   - `tf.config.experimental.list_physical_devices('GPU')`: This line retrieves a list of physical GPU devices available on the machine. The argument `'GPU'` specifies that it's looking for GPU devices. The list includes all the GPUs that TensorFlow can detect on the system.\n","\n","2. **Printing the Number of GPUs:**\n","    ```python\n","    print(\"Num GPU's Available \", len(physical_devices))\n","    ```\n","   - `len(physical_devices)`: This line prints the number of available GPUs by taking the length of the list `physical_devices`. It indicates how many physical GPU devices were detected on the machine.\n","\n","3. **Setting Memory Growth:**\n","    ```python\n","    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n","    ```\n","   - `tf.config.experimental.set_memory_growth(physical_devices[0], True)`: This line sets the memory growth option for the first GPU in the list (assuming at least one GPU is available). When `set_memory_growth` is enabled, TensorFlow will allocate GPU memory as needed, rather than reserving the entire GPU memory at once. This can be beneficial for memory management and allows for more flexibility when running multiple TensorFlow sessions.\n","\n","These lines of code are commonly used when working with TensorFlow on systems with GPU devices. The first line checks the available GPUs, the second line prints the count, and the third line sets the memory growth option for the first GPU. Note that setting memory growth is an optional step, and its necessity depends on the specific requirements and limitations of your application and system configuration."],"metadata":{"id":"E8Wf4ByxhJgU"}},{"cell_type":"code","source":["model = Sequential([\n","    Dense(units=16, input_shape=(1,),activation='relu'), # actually 2nd layer , it is first hidden layer(also acts as input layer), it has 16 nodes.\n","    Dense(units=32, activation='relu'), # 2nd hidden layer : 32 nodes\n","    Dense(units=2, activation='softmax') # output layer : 2 nodes :( 1 output node or 1 person ke liye yes or no ka binary classification hota toh usse binary classification bolte hain and sigmoid ka use krte)\n","]) # model = an instance of Sequential class\n","# here 2 different persons hain = 2 classes = multiclasses = softmax activation use karenge\n","# remember binary classification me class 1 hogi bus use disease hai ya nhi is basis pr 0 or 1 ka binary classification bolenge.\n","# 2 classes/categories ho gyin toh vo binary classification nhi bola jayega\n","# person/patient is diseased or not = this is binary classification. In binary classification, you have two mutually exclusive classes, and the task is to classify each instance into one of these two classes.\n","# altough softmax can also be used for binary classification problems"],"metadata":{"id":"4IMaMR76gd3M","executionInfo":{"status":"ok","timestamp":1703144836594,"user_tz":-330,"elapsed":36,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":38,"outputs":[]},{"cell_type":"markdown","source":["The code you provided is indeed creating a neural network with a sequential model, and the first layer defined with Dense is acting as both the input layer and a hidden layer. In this case, the term \"input layer\" is implicitly incorporated into the first Dense layer's definition."],"metadata":{"id":"mi_Hb6H_j1_g"}},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eMYradHGiQoi","executionInfo":{"status":"ok","timestamp":1703144836595,"user_tz":-330,"elapsed":36,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e1137556-8f91-449b-dc0d-75236bc298b1"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_3 (Dense)             (None, 16)                32        \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                544       \n","                                                                 \n"," dense_5 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 642 (2.51 KB)\n","Trainable params: 642 (2.51 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["Training our ANN, using Keras API integrated with tensorflow."],"metadata":{"id":"EM_GpG9Am5uY"}},{"cell_type":"code","source":["model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"-yx-yq7XiR4h","executionInfo":{"status":"ok","timestamp":1703144836595,"user_tz":-330,"elapsed":29,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":40,"outputs":[]},{"cell_type":"markdown","source":["Model has been compiled now it is ready for training"],"metadata":{"id":"CMPAqwR2SvPU"}},{"cell_type":"code","source":["model.fit(x=scaled_train_samples, y=train_labels, batch_size=10, epochs=30, shuffle=True, verbose=2) # by default shuffle is set to be true, just ese hi yhan likh diya\n","# 1 epoch = total training samples ke barabar sankhya me samples ek bar train ho jayen.\n","# 10 batch size => 10-10 ke batches me random samples will be trained.\n","# clearly in each epochs = 1000/10 = 100 iterations of training will happen.\n","# verbose = see the training progress. 0,1,2 : 2 is best\n","# verbose 0 : will show nothing.\n","# verbose 1 : will show animated progress eg: 100/100 [==============================>] - 1s 10ms/step - loss: 0.3452 - accuracy: 0.8650\n","# verbose 2 : will show progress but not animated so best eg : - 1s - loss: 0.3452 - accuracy: 0.8650 , no animation"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xWTfcs_OStcu","executionInfo":{"status":"ok","timestamp":1703144846867,"user_tz":-330,"elapsed":10300,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"a8153568-b0de-46ef-8fca-8365c8f8834e"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","210/210 - 1s - loss: 0.6912 - accuracy: 0.6590 - 1s/epoch - 5ms/step\n","Epoch 2/30\n","210/210 - 0s - loss: 0.6649 - accuracy: 0.8752 - 473ms/epoch - 2ms/step\n","Epoch 3/30\n","210/210 - 0s - loss: 0.6396 - accuracy: 0.8695 - 456ms/epoch - 2ms/step\n","Epoch 4/30\n","210/210 - 0s - loss: 0.6111 - accuracy: 0.8819 - 427ms/epoch - 2ms/step\n","Epoch 5/30\n","210/210 - 0s - loss: 0.5809 - accuracy: 0.8900 - 441ms/epoch - 2ms/step\n","Epoch 6/30\n","210/210 - 0s - loss: 0.5490 - accuracy: 0.8867 - 436ms/epoch - 2ms/step\n","Epoch 7/30\n","210/210 - 0s - loss: 0.5160 - accuracy: 0.8871 - 391ms/epoch - 2ms/step\n","Epoch 8/30\n","210/210 - 0s - loss: 0.4835 - accuracy: 0.8976 - 400ms/epoch - 2ms/step\n","Epoch 9/30\n","210/210 - 0s - loss: 0.4528 - accuracy: 0.8933 - 273ms/epoch - 1ms/step\n","Epoch 10/30\n","210/210 - 0s - loss: 0.4247 - accuracy: 0.9081 - 278ms/epoch - 1ms/step\n","Epoch 11/30\n","210/210 - 0s - loss: 0.4000 - accuracy: 0.9124 - 275ms/epoch - 1ms/step\n","Epoch 12/30\n","210/210 - 0s - loss: 0.3784 - accuracy: 0.9143 - 268ms/epoch - 1ms/step\n","Epoch 13/30\n","210/210 - 0s - loss: 0.3600 - accuracy: 0.9162 - 289ms/epoch - 1ms/step\n","Epoch 14/30\n","210/210 - 0s - loss: 0.3447 - accuracy: 0.9214 - 269ms/epoch - 1ms/step\n","Epoch 15/30\n","210/210 - 0s - loss: 0.3316 - accuracy: 0.9171 - 275ms/epoch - 1ms/step\n","Epoch 16/30\n","210/210 - 0s - loss: 0.3208 - accuracy: 0.9271 - 280ms/epoch - 1ms/step\n","Epoch 17/30\n","210/210 - 0s - loss: 0.3117 - accuracy: 0.9229 - 272ms/epoch - 1ms/step\n","Epoch 18/30\n","210/210 - 0s - loss: 0.3042 - accuracy: 0.9295 - 268ms/epoch - 1ms/step\n","Epoch 19/30\n","210/210 - 0s - loss: 0.2976 - accuracy: 0.9319 - 261ms/epoch - 1ms/step\n","Epoch 20/30\n","210/210 - 0s - loss: 0.2921 - accuracy: 0.9276 - 283ms/epoch - 1ms/step\n","Epoch 21/30\n","210/210 - 0s - loss: 0.2874 - accuracy: 0.9324 - 276ms/epoch - 1ms/step\n","Epoch 22/30\n","210/210 - 0s - loss: 0.2832 - accuracy: 0.9290 - 275ms/epoch - 1ms/step\n","Epoch 23/30\n","210/210 - 0s - loss: 0.2797 - accuracy: 0.9362 - 267ms/epoch - 1ms/step\n","Epoch 24/30\n","210/210 - 0s - loss: 0.2768 - accuracy: 0.9300 - 281ms/epoch - 1ms/step\n","Epoch 25/30\n","210/210 - 0s - loss: 0.2741 - accuracy: 0.9362 - 271ms/epoch - 1ms/step\n","Epoch 26/30\n","210/210 - 0s - loss: 0.2718 - accuracy: 0.9362 - 267ms/epoch - 1ms/step\n","Epoch 27/30\n","210/210 - 0s - loss: 0.2697 - accuracy: 0.9348 - 282ms/epoch - 1ms/step\n","Epoch 28/30\n","210/210 - 0s - loss: 0.2677 - accuracy: 0.9314 - 271ms/epoch - 1ms/step\n","Epoch 29/30\n","210/210 - 0s - loss: 0.2663 - accuracy: 0.9386 - 279ms/epoch - 1ms/step\n","Epoch 30/30\n","210/210 - 0s - loss: 0.2648 - accuracy: 0.9352 - 266ms/epoch - 1ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b91f5efa2c0>"]},"metadata":{},"execution_count":41}]},{"cell_type":"markdown","source":["So , without much efforts and all, we are able to build pretty great results. So how easy it is to get started with keras."],"metadata":{"id":"o3LlkqM5WXOg"}},{"cell_type":"markdown","source":["**Build a Validation Set with TensorFlow's Keras API.**"],"metadata":{"id":"ytMij1HzWp_l"}},{"cell_type":"code","source":["model = Sequential([\n","    Dense(units=16, input_shape=(1,),activation='relu'), # actually 2nd layer , it is first hidden layer(also acts as input layer), it has 16 nodes.\n","    Dense(units=32, activation='relu'), # 2nd hidden layer : 32 nodes\n","    Dense(units=2, activation='softmax') # output layer : 2 nodes :( 1 output node or 1 person ke liye yes or no ka binary classification hota toh usse binary classification bolte hain and sigmoid ka use krte)\n","])"],"metadata":{"id":"OdbyKX5uUI5N","executionInfo":{"status":"ok","timestamp":1703145447132,"user_tz":-330,"elapsed":424,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7kf-S_PCYRjK","executionInfo":{"status":"ok","timestamp":1703145462373,"user_tz":-330,"elapsed":27,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"12e05dc7-88e8-4290-88d1-f0a0495a6696"},"execution_count":43,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 16)                32        \n","                                                                 \n"," dense_7 (Dense)             (None, 32)                544       \n","                                                                 \n"," dense_8 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 642 (2.51 KB)\n","Trainable params: 642 (2.51 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model.compile(optimizer=Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics = ['accuracy'])"],"metadata":{"id":"pZLQ86wEYVUI","executionInfo":{"status":"ok","timestamp":1703145494700,"user_tz":-330,"elapsed":10,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":44,"outputs":[]},{"cell_type":"markdown","source":["Top 3 lines of code are exact copy-paste, but it is now going to make some difference.\n","\n"],"metadata":{"id":"uVN295qRYj5d"}},{"cell_type":"code","source":["model.fit(x=scaled_train_samples, y=train_labels, validation_split=0.1, batch_size=10, epochs=30, shuffle=True, verbose=2)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8uGTkskYYdLr","executionInfo":{"status":"ok","timestamp":1703146766954,"user_tz":-330,"elapsed":21469,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"ba652eea-2415-4b3f-abbd-9772da29412d"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","189/189 - 1s - loss: 0.6639 - accuracy: 0.5540 - val_loss: 0.6617 - val_accuracy: 0.5286 - 1s/epoch - 6ms/step\n","Epoch 2/30\n","189/189 - 0s - loss: 0.6295 - accuracy: 0.6381 - val_loss: 0.6375 - val_accuracy: 0.5857 - 307ms/epoch - 2ms/step\n","Epoch 3/30\n","189/189 - 0s - loss: 0.5921 - accuracy: 0.6989 - val_loss: 0.6046 - val_accuracy: 0.6952 - 335ms/epoch - 2ms/step\n","Epoch 4/30\n","189/189 - 0s - loss: 0.5509 - accuracy: 0.7772 - val_loss: 0.5745 - val_accuracy: 0.7429 - 337ms/epoch - 2ms/step\n","Epoch 5/30\n","189/189 - 0s - loss: 0.5153 - accuracy: 0.8005 - val_loss: 0.5462 - val_accuracy: 0.7762 - 335ms/epoch - 2ms/step\n","Epoch 6/30\n","189/189 - 0s - loss: 0.4811 - accuracy: 0.8328 - val_loss: 0.5185 - val_accuracy: 0.8048 - 298ms/epoch - 2ms/step\n","Epoch 7/30\n","189/189 - 0s - loss: 0.4487 - accuracy: 0.8534 - val_loss: 0.4954 - val_accuracy: 0.8095 - 288ms/epoch - 2ms/step\n","Epoch 8/30\n","189/189 - 0s - loss: 0.4193 - accuracy: 0.8672 - val_loss: 0.4715 - val_accuracy: 0.8333 - 299ms/epoch - 2ms/step\n","Epoch 9/30\n","189/189 - 0s - loss: 0.3926 - accuracy: 0.8825 - val_loss: 0.4551 - val_accuracy: 0.8476 - 347ms/epoch - 2ms/step\n","Epoch 10/30\n","189/189 - 0s - loss: 0.3694 - accuracy: 0.8868 - val_loss: 0.4386 - val_accuracy: 0.8524 - 366ms/epoch - 2ms/step\n","Epoch 11/30\n","189/189 - 0s - loss: 0.3491 - accuracy: 0.8974 - val_loss: 0.4240 - val_accuracy: 0.8667 - 480ms/epoch - 3ms/step\n","Epoch 12/30\n","189/189 - 0s - loss: 0.3321 - accuracy: 0.9106 - val_loss: 0.4136 - val_accuracy: 0.8667 - 450ms/epoch - 2ms/step\n","Epoch 13/30\n","189/189 - 0s - loss: 0.3176 - accuracy: 0.9143 - val_loss: 0.4064 - val_accuracy: 0.8667 - 436ms/epoch - 2ms/step\n","Epoch 14/30\n","189/189 - 0s - loss: 0.3055 - accuracy: 0.9222 - val_loss: 0.4007 - val_accuracy: 0.8810 - 439ms/epoch - 2ms/step\n","Epoch 15/30\n","189/189 - 0s - loss: 0.2956 - accuracy: 0.9222 - val_loss: 0.3962 - val_accuracy: 0.8810 - 475ms/epoch - 3ms/step\n","Epoch 16/30\n","189/189 - 0s - loss: 0.2872 - accuracy: 0.9275 - val_loss: 0.3944 - val_accuracy: 0.8810 - 471ms/epoch - 2ms/step\n","Epoch 17/30\n","189/189 - 0s - loss: 0.2801 - accuracy: 0.9275 - val_loss: 0.3895 - val_accuracy: 0.8952 - 371ms/epoch - 2ms/step\n","Epoch 18/30\n","189/189 - 0s - loss: 0.2742 - accuracy: 0.9307 - val_loss: 0.3892 - val_accuracy: 0.8952 - 301ms/epoch - 2ms/step\n","Epoch 19/30\n","189/189 - 0s - loss: 0.2692 - accuracy: 0.9307 - val_loss: 0.3871 - val_accuracy: 0.8952 - 300ms/epoch - 2ms/step\n","Epoch 20/30\n","189/189 - 0s - loss: 0.2648 - accuracy: 0.9365 - val_loss: 0.3869 - val_accuracy: 0.8952 - 295ms/epoch - 2ms/step\n","Epoch 21/30\n","189/189 - 0s - loss: 0.2613 - accuracy: 0.9328 - val_loss: 0.3857 - val_accuracy: 0.8952 - 315ms/epoch - 2ms/step\n","Epoch 22/30\n","189/189 - 0s - loss: 0.2583 - accuracy: 0.9339 - val_loss: 0.3835 - val_accuracy: 0.9095 - 344ms/epoch - 2ms/step\n","Epoch 23/30\n","189/189 - 0s - loss: 0.2555 - accuracy: 0.9370 - val_loss: 0.3841 - val_accuracy: 0.9095 - 289ms/epoch - 2ms/step\n","Epoch 24/30\n","189/189 - 0s - loss: 0.2534 - accuracy: 0.9413 - val_loss: 0.3833 - val_accuracy: 0.9095 - 332ms/epoch - 2ms/step\n","Epoch 25/30\n","189/189 - 0s - loss: 0.2515 - accuracy: 0.9360 - val_loss: 0.3832 - val_accuracy: 0.9095 - 304ms/epoch - 2ms/step\n","Epoch 26/30\n","189/189 - 0s - loss: 0.2494 - accuracy: 0.9413 - val_loss: 0.3845 - val_accuracy: 0.9095 - 325ms/epoch - 2ms/step\n","Epoch 27/30\n","189/189 - 0s - loss: 0.2478 - accuracy: 0.9392 - val_loss: 0.3822 - val_accuracy: 0.9095 - 291ms/epoch - 2ms/step\n","Epoch 28/30\n","189/189 - 0s - loss: 0.2462 - accuracy: 0.9392 - val_loss: 0.3808 - val_accuracy: 0.9190 - 330ms/epoch - 2ms/step\n","Epoch 29/30\n","189/189 - 0s - loss: 0.2450 - accuracy: 0.9397 - val_loss: 0.3818 - val_accuracy: 0.9095 - 321ms/epoch - 2ms/step\n","Epoch 30/30\n","189/189 - 0s - loss: 0.2439 - accuracy: 0.9402 - val_loss: 0.3803 - val_accuracy: 0.9190 - 295ms/epoch - 2ms/step\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.src.callbacks.History at 0x7b91f5ee9e40>"]},"metadata":{},"execution_count":45}]},{"cell_type":"markdown","source":["We have added another argument named validation_split to the fit() function. Here i am splitting out 10% of the training set for the testing purpose.(Remember we have shuffle the whole sample at the begining, so we don't need to worry about the fact written below).\n","\n","\n","One thing to note here is that whenever we pass validation_split as well as an argument, the validation set is first taken out from the whole sample from the bottom of train_samples, then only training is performed at the remaining 90% datasets, also if we have passed shuffle=True, that too will take place after the separating those 90% dataset. Hence keep in mind this that if you have passed training samples in which datasets of a particular class are stacked together over the dataset of another class, in the validation split you will get the datasets of just one or two classes whatever % will fall from the bottom. Hence do shuffling of the data before passing into .fit function."],"metadata":{"id":"QS-oQAZiY07C"}},{"cell_type":"markdown","source":["Yes, your understanding is correct. When the `validation_split` parameter is used in the `model.fit` function along with shuffling (`shuffle=True`), it is important to note that the validation set is extracted from the bottom of the training samples. This implies that the validation set will primarily consist of the latter portion of the original dataset.\n","\n","Here's a more formal expression of your explanation:\n","\n","The utilization of the `validation_split` parameter in the `model.fit` function, in conjunction with the `shuffle=True` argument, results in the extraction of a validation set from the lower portion of the training samples. Specifically, the percentage specified for validation (e.g., 10%) is taken from the end of the original dataset. Consequently, during training, the model is exposed to the remaining 90% of the dataset. It is crucial to recognize that shuffling occurs after the separation of the validation set, and, as such, the validation set predominantly comprises data points from the latter part of the original dataset. Therefore, when presenting training samples where instances of a particular class are grouped together, shuffling the data beforehand is advisable to ensure a more representative validation set."],"metadata":{"id":"knq3c_C1dKU-"}},{"cell_type":"markdown","source":["So make sure your training data is shuffled beforehand if you are going to use validation_split paramenter in .fit() function. Agar ise use nhi krna hai toh, .fit() ka shuffle=True by default will shuffle the datasets  in training, Beforehand shuffling is not that much required."],"metadata":{"id":"eHtdDfeGdv2H"}},{"cell_type":"markdown","source":["So we can say that in this example our model is not overfitting, or our model is generalizing well. Since the accuracy on training and validation/testing is same."],"metadata":{"id":"9NmnzQGded1x"}},{"cell_type":"markdown","source":["Neural Network Predictions with Tensorflow's Keras API."],"metadata":{"id":"-x9Pzk1d8WRN"}},{"cell_type":"markdown","source":["Creating the test set"],"metadata":{"id":"quUGmUnd88Jw"}},{"cell_type":"markdown","source":["test set should be prepared and processed in the same way as the training sample was."],"metadata":{"id":"U7VEqDoO9e4c"}},{"cell_type":"code","source":["test_labels = []\n","test_samples = []"],"metadata":{"id":"3Jf6-nRIZ3iv","executionInfo":{"status":"ok","timestamp":1703155081848,"user_tz":-330,"elapsed":378,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["for i in range(10):\n","  # the ~5% of younger(yuva = young man) individuals who experienced side effect.(elder = bujurg, younger = chota/ yuva)\n","  # 1 = yes, side effect,  0 = no side effect\n","  random_younger = randint(13,64) # randint me 13 and 64 included, will generate just 1 random number between 13 and 64(inclusive) in each call\n","  test_samples.append(random_younger)\n","  test_labels.append(1)\n","\n","  # the ~5% of older individuals who did not experience side effects\n","  random_older = randint(65, 100) # generates one number in [65,100]\n","  test_samples.append(random_older)\n","  test_labels.append(0)\n","\n","for i in range(200):\n","  # the 95% of youger individuals who did not experience side effects\n","  random_younger = randint(13,64)\n","  test_samples.append(random_younger)\n","  test_labels.append(0)\n","\n","  # the 95% of the older ppls who did experience side-effects\n","  random_older = randint(65, 100)\n","  test_samples.append(random_older)\n","  test_labels.append(1)\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1703155182827,"user_tz":-330,"elapsed":3,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"id":"c_EV9zCl9G__"},"execution_count":47,"outputs":[]},{"cell_type":"code","source":["test_labels = np.array(test_labels)\n","test_samples = np.array(test_samples)\n","test_labels, test_samples = shuffle(test_labels, test_samples)"],"metadata":{"id":"ZEftSbah9aim","executionInfo":{"status":"ok","timestamp":1703155457579,"user_tz":-330,"elapsed":436,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":50,"outputs":[]},{"cell_type":"code","source":["scaled_test_sample = scaler.fit_transform(test_samples.reshape(-1,1)) # test samples ko unke mean and std se scaled up kreneg, hme training me kya the, kya malum"],"metadata":{"id":"1jijJ6wE-D58","executionInfo":{"status":"ok","timestamp":1703155463145,"user_tz":-330,"elapsed":386,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["Predictions"],"metadata":{"id":"tEg6E8C8-hHM"}},{"cell_type":"code","source":["predictions = model.predict(x=scaled_test_sample, batch_size=10, verbose=1) # without passing test labels\n","# model.predict() does not take y or labels input"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5vXD5E0Q-Znc","executionInfo":{"status":"ok","timestamp":1703155521336,"user_tz":-330,"elapsed":1047,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"124b2ed1-7115-4a8d-e445-e78e343e7866"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stdout","text":["42/42 [==============================] - 0s 2ms/step\n"]}]},{"cell_type":"code","source":["predictions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CutU2jM8-tBx","executionInfo":{"status":"ok","timestamp":1703155589911,"user_tz":-330,"elapsed":404,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"6bc3d40d-ea0e-4360-ed03-19fd41007fb5"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[0.04167344, 0.9583266 ],\n","       [0.4313643 , 0.56863564],\n","       [0.9644877 , 0.03551234],\n","       [0.96964836, 0.03035156],\n","       [0.02086299, 0.979137  ],\n","       [0.11326575, 0.8867342 ],\n","       [0.54217273, 0.4578272 ],\n","       [0.09918895, 0.90081096],\n","       [0.9667956 , 0.03320444],\n","       [0.97188175, 0.0281182 ],\n","       [0.8908131 , 0.10918687],\n","       [0.95933366, 0.04066621],\n","       [0.02842523, 0.9715748 ],\n","       [0.01652066, 0.9834793 ],\n","       [0.11326575, 0.8867342 ],\n","       [0.02086299, 0.979137  ],\n","       [0.6819903 , 0.3180097 ],\n","       [0.23738898, 0.762611  ],\n","       [0.03069803, 0.969302  ],\n","       [0.9165213 , 0.08347864],\n","       [0.0522756 , 0.94772434],\n","       [0.5787278 , 0.42127222],\n","       [0.83938956, 0.16061035],\n","       [0.02086299, 0.979137  ],\n","       [0.7426625 , 0.25733742],\n","       [0.77000046, 0.2299996 ],\n","       [0.02435959, 0.9756404 ],\n","       [0.03314637, 0.9668537 ],\n","       [0.01652066, 0.9834794 ],\n","       [0.96895826, 0.0310417 ],\n","       [0.04495655, 0.9550435 ],\n","       [0.3604972 , 0.6395028 ],\n","       [0.16625181, 0.83374816],\n","       [0.9727485 , 0.02725143],\n","       [0.03862045, 0.9613796 ],\n","       [0.03069803, 0.969302  ],\n","       [0.03862045, 0.9613796 ],\n","       [0.08673139, 0.9132686 ],\n","       [0.4680866 , 0.5319134 ],\n","       [0.97188175, 0.0281182 ],\n","       [0.16625181, 0.83374816],\n","       [0.16625181, 0.83374816],\n","       [0.9165214 , 0.08347865],\n","       [0.8908131 , 0.10918687],\n","       [0.6819903 , 0.3180097 ],\n","       [0.96679556, 0.03320444],\n","       [0.03069803, 0.969302  ],\n","       [0.03314637, 0.9668537 ],\n","       [0.05227561, 0.9477244 ],\n","       [0.11326576, 0.88673425],\n","       [0.04167344, 0.9583266 ],\n","       [0.02086299, 0.979137  ],\n","       [0.02086299, 0.979137  ],\n","       [0.02086299, 0.979137  ],\n","       [0.01528096, 0.984719  ],\n","       [0.95563626, 0.04436367],\n","       [0.01930385, 0.98069614],\n","       [0.26530266, 0.73469734],\n","       [0.06093083, 0.93906915],\n","       [0.05227561, 0.9477244 ],\n","       [0.9716791 , 0.02832083],\n","       [0.8908131 , 0.10918687],\n","       [0.97223127, 0.02776872],\n","       [0.9165214 , 0.08347865],\n","       [0.1466791 , 0.8533208 ],\n","       [0.06755908, 0.93244094],\n","       [0.9689582 , 0.0310417 ],\n","       [0.9725766 , 0.02742346],\n","       [0.9272001 , 0.07279991],\n","       [0.0178591 , 0.9821409 ],\n","       [0.8908131 , 0.10918687],\n","       [0.96344024, 0.03655987],\n","       [0.08673139, 0.9132686 ],\n","       [0.97295636, 0.02704357],\n","       [0.5787278 , 0.42127222],\n","       [0.02842523, 0.9715748 ],\n","       [0.23738898, 0.762611  ],\n","       [0.02842523, 0.9715748 ],\n","       [0.3604972 , 0.6395028 ],\n","       [0.03578275, 0.96421725],\n","       [0.95078385, 0.04921611],\n","       [0.09918895, 0.90081096],\n","       [0.9689582 , 0.0310417 ],\n","       [0.03862045, 0.9613796 ],\n","       [0.95078385, 0.04921611],\n","       [0.95078385, 0.04921611],\n","       [0.02435959, 0.9756404 ],\n","       [0.39538127, 0.6046187 ],\n","       [0.01528096, 0.98471904],\n","       [0.23738898, 0.762611  ],\n","       [0.95933366, 0.04066621],\n","       [0.21156667, 0.7884334 ],\n","       [0.97098446, 0.02901561],\n","       [0.16625181, 0.83374816],\n","       [0.95563626, 0.04436367],\n","       [0.97285265, 0.02714731],\n","       [0.12905413, 0.8709458 ],\n","       [0.08673139, 0.9132686 ],\n","       [0.01930385, 0.98069614],\n","       [0.8908131 , 0.10918687],\n","       [0.9714147 , 0.02858532],\n","       [0.9365532 , 0.06344692],\n","       [0.0178591 , 0.9821409 ],\n","       [0.9729045 , 0.02709539],\n","       [0.8908131 , 0.10918687],\n","       [0.09918895, 0.90081096],\n","       [0.97205704, 0.02794294],\n","       [0.97269636, 0.02730365],\n","       [0.23738898, 0.762611  ],\n","       [0.26530266, 0.73469734],\n","       [0.11326575, 0.8867342 ],\n","       [0.9730081 , 0.02699185],\n","       [0.01930385, 0.98069614],\n","       [0.6489605 , 0.3510394 ],\n","       [0.95078385, 0.04921611],\n","       [0.97269636, 0.02730365],\n","       [0.04495655, 0.9550435 ],\n","       [0.9675321 , 0.03246783],\n","       [0.50515807, 0.49484193],\n","       [0.85841095, 0.14158909],\n","       [0.03069803, 0.969302  ],\n","       [0.39538127, 0.6046187 ],\n","       [0.9689582 , 0.0310417 ],\n","       [0.9714147 , 0.02858532],\n","       [0.03069803, 0.969302  ],\n","       [0.9729045 , 0.02709539],\n","       [0.96527356, 0.03472638],\n","       [0.83938956, 0.16061035],\n","       [0.9667956 , 0.03320444],\n","       [0.97285265, 0.02714731],\n","       [0.9726441 , 0.02735594],\n","       [0.01930385, 0.98069614],\n","       [0.1466791 , 0.8533208 ],\n","       [0.04495655, 0.9550435 ],\n","       [0.9044376 , 0.09556236],\n","       [0.505158  , 0.4948419 ],\n","       [0.97205704, 0.02794294],\n","       [0.9725766 , 0.02742346],\n","       [0.97300816, 0.02699185],\n","       [0.43136433, 0.5686357 ],\n","       [0.8584109 , 0.14158908],\n","       [0.9730597 , 0.02694022],\n","       [0.06755908, 0.93244094],\n","       [0.0178591 , 0.9821409 ],\n","       [0.9689582 , 0.0310417 ],\n","       [0.08673139, 0.9132686 ],\n","       [0.3604972 , 0.6395028 ],\n","       [0.03069803, 0.969302  ],\n","       [0.03862045, 0.9613796 ],\n","       [0.95078385, 0.04921611],\n","       [0.96604276, 0.03395718],\n","       [0.03578275, 0.96421725],\n","       [0.3604972 , 0.6395028 ],\n","       [0.96604276, 0.03395718],\n","       [0.5787278 , 0.42127222],\n","       [0.6819903 , 0.3180097 ],\n","       [0.5787278 , 0.42127222],\n","       [0.97285265, 0.02714731],\n","       [0.97257656, 0.02742345],\n","       [0.9652736 , 0.03472638],\n","       [0.95933366, 0.04066621],\n","       [0.4313643 , 0.56863564],\n","       [0.02842523, 0.9715748 ],\n","       [0.1466791 , 0.8533208 ],\n","       [0.01652066, 0.9834793 ],\n","       [0.1466791 , 0.8533208 ],\n","       [0.6489605 , 0.3510394 ],\n","       [0.06755908, 0.93244094],\n","       [0.3604972 , 0.6395028 ],\n","       [0.3604972 , 0.6395028 ],\n","       [0.6489605 , 0.3510394 ],\n","       [0.07636239, 0.9236376 ],\n","       [0.9644877 , 0.03551234],\n","       [0.54217273, 0.4578272 ],\n","       [0.9689582 , 0.0310417 ],\n","       [0.21156667, 0.7884334 ],\n","       [0.9716791 , 0.02832083],\n","       [0.9727485 , 0.02725143],\n","       [0.944401  , 0.05559896],\n","       [0.02254516, 0.9774548 ],\n","       [0.0178591 , 0.9821409 ],\n","       [0.6489605 , 0.3510394 ],\n","       [0.9716791 , 0.02832083],\n","       [0.21156667, 0.7884334 ],\n","       [0.03578275, 0.96421725],\n","       [0.96679556, 0.03320444],\n","       [0.11326575, 0.8867342 ],\n","       [0.944401  , 0.05559896],\n","       [0.09918896, 0.900811  ],\n","       [0.97257656, 0.02742345],\n","       [0.4313643 , 0.56863564],\n","       [0.2952277 , 0.7047723 ],\n","       [0.04495655, 0.9550435 ],\n","       [0.9616903 , 0.03830969],\n","       [0.8183537 , 0.18164621],\n","       [0.03862045, 0.9613796 ],\n","       [0.03578275, 0.96421725],\n","       [0.95563626, 0.04436367],\n","       [0.01528096, 0.98471904],\n","       [0.06755908, 0.93244094],\n","       [0.03314637, 0.9668537 ],\n","       [0.01930385, 0.98069614],\n","       [0.97280073, 0.02719933],\n","       [0.32702586, 0.6729741 ],\n","       [0.3604972 , 0.6395028 ],\n","       [0.6489605 , 0.3510394 ],\n","       [0.09918895, 0.90081096],\n","       [0.03862045, 0.9613796 ],\n","       [0.9720571 , 0.02794294],\n","       [0.07636239, 0.9236376 ],\n","       [0.26530266, 0.73469734],\n","       [0.18786111, 0.8121388 ],\n","       [0.9726441 , 0.02735594],\n","       [0.9730081 , 0.02699185],\n","       [0.9714147 , 0.02858532],\n","       [0.08673139, 0.9132686 ],\n","       [0.97269636, 0.02730365],\n","       [0.9165214 , 0.08347865],\n","       [0.02842523, 0.9715748 ],\n","       [0.9365531 , 0.06344691],\n","       [0.96344024, 0.03655987],\n","       [0.9675321 , 0.03246783],\n","       [0.95563626, 0.04436367],\n","       [0.01528096, 0.984719  ],\n","       [0.16625181, 0.83374816],\n","       [0.03862045, 0.9613796 ],\n","       [0.4313643 , 0.56863564],\n","       [0.07636239, 0.9236376 ],\n","       [0.97032374, 0.02967629],\n","       [0.12905413, 0.8709458 ],\n","       [0.83938956, 0.16061035],\n","       [0.8584109 , 0.14158908],\n","       [0.18786111, 0.8121388 ],\n","       [0.96964836, 0.03035156],\n","       [0.21156667, 0.7884334 ],\n","       [0.71328515, 0.28671482],\n","       [0.02842523, 0.9715748 ],\n","       [0.1466791 , 0.8533208 ],\n","       [0.05634484, 0.94365513],\n","       [0.9728007 , 0.02719933],\n","       [0.11326575, 0.8867342 ],\n","       [0.9727485 , 0.02725143],\n","       [0.9716791 , 0.02832083],\n","       [0.07636239, 0.9236376 ],\n","       [0.02631613, 0.9736839 ],\n","       [0.95078385, 0.04921611],\n","       [0.9272    , 0.07279991],\n","       [0.9616903 , 0.03830969],\n","       [0.2952277 , 0.7047723 ],\n","       [0.06093083, 0.93906915],\n","       [0.9675321 , 0.03246783],\n","       [0.9616903 , 0.03830969],\n","       [0.9714147 , 0.02858532],\n","       [0.9726441 , 0.02735594],\n","       [0.1466791 , 0.8533208 ],\n","       [0.95933366, 0.04066621],\n","       [0.01528096, 0.984719  ],\n","       [0.97285265, 0.02714731],\n","       [0.9660429 , 0.03395718],\n","       [0.05227561, 0.9477244 ],\n","       [0.95078385, 0.04921611],\n","       [0.9689582 , 0.0310417 ],\n","       [0.9729045 , 0.02709539],\n","       [0.97285265, 0.02714731],\n","       [0.06755908, 0.93244094],\n","       [0.9725766 , 0.02742346],\n","       [0.23738898, 0.762611  ],\n","       [0.02631613, 0.9736839 ],\n","       [0.97295636, 0.02704357],\n","       [0.12905413, 0.8709458 ],\n","       [0.18786111, 0.8121388 ],\n","       [0.97240436, 0.02759557],\n","       [0.03578275, 0.96421725],\n","       [0.04167344, 0.9583266 ],\n","       [0.04848515, 0.9515148 ],\n","       [0.09918895, 0.90081096],\n","       [0.04848515, 0.9515148 ],\n","       [0.77000046, 0.2299996 ],\n","       [0.9667956 , 0.03320444],\n","       [0.9720571 , 0.02794294],\n","       [0.04495655, 0.9550435 ],\n","       [0.02086299, 0.979137  ],\n","       [0.944401  , 0.05559896],\n","       [0.04495655, 0.9550435 ],\n","       [0.96964836, 0.03035156],\n","       [0.02435959, 0.9756404 ],\n","       [0.9730597 , 0.02694022],\n","       [0.8908131 , 0.10918687],\n","       [0.03578275, 0.96421725],\n","       [0.50515807, 0.49484193],\n","       [0.7426625 , 0.25733742],\n","       [0.6489605 , 0.3510394 ],\n","       [0.9716791 , 0.02832083],\n","       [0.9726441 , 0.02735594],\n","       [0.944401  , 0.05559896],\n","       [0.03862045, 0.9613796 ],\n","       [0.16625181, 0.83374816],\n","       [0.23738898, 0.762611  ],\n","       [0.02086299, 0.97913706],\n","       [0.05634484, 0.94365513],\n","       [0.96679556, 0.03320444],\n","       [0.16625181, 0.83374816],\n","       [0.96527356, 0.03472638],\n","       [0.06093083, 0.93906915],\n","       [0.97285265, 0.02714731],\n","       [0.03069803, 0.969302  ],\n","       [0.02254516, 0.9774548 ],\n","       [0.03314637, 0.9668537 ],\n","       [0.8393896 , 0.16061036],\n","       [0.9272001 , 0.07279991],\n","       [0.96825296, 0.03174702],\n","       [0.7426625 , 0.25733742],\n","       [0.4313643 , 0.56863564],\n","       [0.9644877 , 0.03551234],\n","       [0.6489605 , 0.3510394 ],\n","       [0.97295636, 0.02704357],\n","       [0.03314637, 0.9668537 ],\n","       [0.06755908, 0.93244094],\n","       [0.9730598 , 0.02694023],\n","       [0.9728007 , 0.02719933],\n","       [0.77000046, 0.2299996 ],\n","       [0.9726441 , 0.02735594],\n","       [0.9727485 , 0.02725143],\n","       [0.8183537 , 0.18164621],\n","       [0.09918895, 0.90081096],\n","       [0.2952277 , 0.7047723 ],\n","       [0.9730081 , 0.02699185],\n","       [0.03862045, 0.9613796 ],\n","       [0.01930385, 0.98069614],\n","       [0.97223127, 0.02776872],\n","       [0.97240436, 0.02759557],\n","       [0.06755908, 0.93244094],\n","       [0.18786111, 0.8121388 ],\n","       [0.97295636, 0.02704357],\n","       [0.03862045, 0.9613796 ],\n","       [0.83938956, 0.16061035],\n","       [0.96344024, 0.03655987],\n","       [0.03578275, 0.96421725],\n","       [0.9696484 , 0.03035156],\n","       [0.8908131 , 0.10918687],\n","       [0.16625181, 0.83374816],\n","       [0.79523486, 0.20476517],\n","       [0.96344024, 0.03655987],\n","       [0.944401  , 0.05559896],\n","       [0.16625181, 0.83374816],\n","       [0.7426625 , 0.25733742],\n","       [0.95933366, 0.04066621],\n","       [0.16625181, 0.83374816],\n","       [0.06755908, 0.93244094],\n","       [0.87551355, 0.12448644],\n","       [0.97205704, 0.02794294],\n","       [0.9718817 , 0.0281182 ],\n","       [0.9675321 , 0.03246783],\n","       [0.16625181, 0.83374816],\n","       [0.9714147 , 0.02858532],\n","       [0.39538127, 0.6046187 ],\n","       [0.95563626, 0.04436367],\n","       [0.06755908, 0.93244094],\n","       [0.03578275, 0.96421725],\n","       [0.26530266, 0.73469734],\n","       [0.01528096, 0.984719  ],\n","       [0.96604276, 0.03395718],\n","       [0.21156667, 0.7884334 ],\n","       [0.09918895, 0.90081096],\n","       [0.02086299, 0.979137  ],\n","       [0.95933366, 0.04066621],\n","       [0.97205704, 0.02794294],\n","       [0.26530266, 0.73469734],\n","       [0.04848516, 0.95151484],\n","       [0.02254516, 0.9774548 ],\n","       [0.9716791 , 0.02832083],\n","       [0.01930385, 0.98069614],\n","       [0.11326575, 0.8867342 ],\n","       [0.18786111, 0.8121388 ],\n","       [0.02254516, 0.9774548 ],\n","       [0.97205704, 0.02794294],\n","       [0.9729045 , 0.02709539],\n","       [0.4313643 , 0.56863564],\n","       [0.05227561, 0.9477244 ],\n","       [0.9709844 , 0.02901561],\n","       [0.83938956, 0.16061035],\n","       [0.04167344, 0.9583266 ],\n","       [0.01528096, 0.984719  ],\n","       [0.83938956, 0.16061035],\n","       [0.2952277 , 0.7047723 ],\n","       [0.07636239, 0.9236376 ],\n","       [0.95563626, 0.04436367],\n","       [0.9165214 , 0.08347865],\n","       [0.14667912, 0.8533209 ],\n","       [0.9556363 , 0.04436367],\n","       [0.8584109 , 0.14158908],\n","       [0.6819903 , 0.3180097 ],\n","       [0.79523486, 0.20476517],\n","       [0.03314637, 0.9668537 ],\n","       [0.6144398 , 0.38556015],\n","       [0.04167344, 0.9583266 ],\n","       [0.16625181, 0.83374816],\n","       [0.0522756 , 0.94772434],\n","       [0.09918896, 0.900811  ],\n","       [0.97167915, 0.02832083],\n","       [0.9716791 , 0.02832083],\n","       [0.79523486, 0.20476517],\n","       [0.11326575, 0.8867342 ],\n","       [0.01930385, 0.98069614],\n","       [0.9365532 , 0.06344692],\n","       [0.6489605 , 0.3510394 ],\n","       [0.97098446, 0.02901561],\n","       [0.01652066, 0.9834793 ],\n","       [0.4680866 , 0.5319134 ],\n","       [0.21156666, 0.7884333 ],\n","       [0.03578275, 0.96421725],\n","       [0.6819903 , 0.3180097 ],\n","       [0.97205704, 0.02794294],\n","       [0.97098446, 0.02901561],\n","       [0.02631613, 0.9736839 ],\n","       [0.39538127, 0.6046187 ],\n","       [0.97098446, 0.02901561],\n","       [0.3604972 , 0.6395028 ],\n","       [0.21156666, 0.7884333 ],\n","       [0.9724044 , 0.02759557]], dtype=float32)"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["# for each samples in test set, prediction shows the probability of no sideeffect or high sideeffect, 0th index = not havinf side effect, 1 = having sideefect\n","rounded_predictions = np.argmax(predictions, axis=1)"],"metadata":{"id":"-r_v3P1V-98h","executionInfo":{"status":"ok","timestamp":1703155702201,"user_tz":-330,"elapsed":387,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["rounded_predictions"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ggIGMqh7_YGy","executionInfo":{"status":"ok","timestamp":1703155716384,"user_tz":-330,"elapsed":382,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"7ebea73b-e37e-4abc-f5da-44eed634bd89"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0,\n","       0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n","       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n","       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1,\n","       1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1,\n","       1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n","       1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0,\n","       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1,\n","       0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0,\n","       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n","       0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0,\n","       0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0,\n","       1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n","       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n","       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0,\n","       0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n","       0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1,\n","       1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n","       1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1,\n","       1, 0])"]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":["num_correct_predictions = 0\n","for i in range(len(rounded_predictions)):\n","  if rounded_predictions[i]==test_labels[i]:\n","    num_correct_predictions+=1\n","\n","accuracy = num_correct_predictions/len(rounded_predictions)\n","\n","print(\"Testing accuracy \",accuracy*100,\" %\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CAKv3gO2_c05","executionInfo":{"status":"ok","timestamp":1703155881888,"user_tz":-330,"elapsed":383,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"e3ee4f89-6acb-40f0-8822-20d64b50792e"},"execution_count":57,"outputs":[{"output_type":"stream","name":"stdout","text":["Testing accuracy  94.76190476190476  %\n"]}]},{"cell_type":"markdown","source":["**Create a Confusion Matrix for Neura Network Predictions:**"],"metadata":{"id":"DrtCIHp1APVS"}},{"cell_type":"markdown","source":["To know how well model performed on test data"],"metadata":{"id":"aVo2nBNwBhrk"}},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","# Assuming test_labels contains true labels and rounded_predictions contains predicted labels\n","\n","# Build confusion matrix\n","cm = confusion_matrix(test_labels, rounded_predictions)\n","\n","# Display the confusion matrix using a heatmap\n","plt.figure(figsize=(6, 4))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Class 0 : No Side-effects', 'Class 1 : had side-effects'], yticklabels=['Class 0', 'Class 1'])\n","plt.xlabel('Predicted Labels')\n","plt.ylabel('True Labels')\n","plt.title('Confusion Matrix')\n","plt.show()\n","\n","print(cm)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":445},"id":"IuqaGI94AFPK","executionInfo":{"status":"ok","timestamp":1703157446699,"user_tz":-330,"elapsed":773,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"3253d4ed-14bd-4d6d-9bfa-74882c8d6bc2"},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 600x400 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["[[198  12]\n"," [ 10 200]]\n"]}]},{"cell_type":"markdown","source":["COORECT PREDICTIONS = 198 + 200 = 398\n","\n","ERROR PREDICTIONS = 10 + 12 = 22\n","\n","All number at principal diagonals are only the correct predictions, rest all are errors or wrong predictions."],"metadata":{"id":"GrbGR_DAGOue"}},{"cell_type":"markdown","source":["**Saving and Loading the ANN keras model**"],"metadata":{"id":"6GPKL3zDGpF2"}},{"cell_type":"markdown","source":["**1. Using the save function of keras**"],"metadata":{"id":"8zeq3KsALZm0"}},{"cell_type":"markdown","source":["Firsct check, file already exists or not, if not then only save\n","\n"],"metadata":{"id":"Uvm5C6kLHOvZ"}},{"cell_type":"code","source":["import os #  the `os` module to check if the file already exists before saving the model.\n","from tensorflow.keras.models import save_model, load_model\n","\n","# 'my_model.h5(or .keras or only my_model)' let's assume to be the desired model filename\n","model_filename = 'my_model.keras'\n","\n","# Check if the model file already exists\n","if os.path.exists(model_filename):\n","    print(f\"The model file '{model_filename}' already exists.\")\n","else:\n","    # Assuming 'model' is my model name\n","    model.save(model_filename)\n","    print(f\"The model has been saved as '{model_filename}'.\")\n","\n","# To load the model back later if needed\n","loaded_model = load_model(model_filename)\n","\n","loaded_model.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I1-rFQ2AEpFr","executionInfo":{"status":"ok","timestamp":1703158215701,"user_tz":-330,"elapsed":768,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"0b6e9726-100b-4136-f376-9d8dbdbbd192"},"execution_count":67,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has been saved as 'my_model.keras'.\n","Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 16)                32        \n","                                                                 \n"," dense_7 (Dense)             (None, 32)                544       \n","                                                                 \n"," dense_8 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 642 (2.51 KB)\n","Trainable params: 642 (2.51 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["model saving = saving the parameters i.e. weights and biases."],"metadata":{"id":"US2hV3cGH5Wd"}},{"cell_type":"markdown","source":["This 'save' function saves:\n","- The architecture of the model, allowing to re-create the model.\n","- The weights(parameters) of the model.\n","- The training configuration(loss, optimizer)\n","- The state of the optimizer, allowing to resume training exactly where you left off."],"metadata":{"id":"wOpiftdDJUEM"}},{"cell_type":"code","source":["loaded_model.get_weights()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EyD-ZbleH1pL","executionInfo":{"status":"ok","timestamp":1703158460294,"user_tz":-330,"elapsed":410,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"dacc5c63-d267-41ea-dedc-cf1172cfadf5"},"execution_count":68,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[ 0.51720446, -0.03419048,  0.46222135, -0.5118933 ,  0.70956475,\n","         -0.106783  ,  0.65770775, -0.11873049, -0.06302857, -0.31055322,\n","          0.3782386 ,  0.20675185, -0.26152122, -0.41176105, -0.0662266 ,\n","          0.5221032 ]], dtype=float32),\n"," array([-0.15246107,  0.        , -0.15040988,  0.        , -0.12701406,\n","         0.        , -0.06707935,  0.        ,  0.18986918,  0.        ,\n","        -0.11503033,  0.04251181,  0.        ,  0.        ,  0.        ,\n","        -0.08218698], dtype=float32),\n"," array([[ 0.54135484, -0.13289575, -0.473549  , -0.29690593,  0.3881261 ,\n","          0.11257967, -0.17178161, -0.01213247,  0.12360594, -0.21729474,\n","         -0.39675578, -0.32103795, -0.43707314,  0.2800626 ,  0.48017928,\n","         -0.07274528,  0.49218443, -0.02150763,  0.18781485,  0.17347203,\n","          0.34369144,  0.30873215, -0.2059362 , -0.24999306,  0.13641678,\n","          0.00700325, -0.41356316, -0.34473485, -0.24566844,  0.06366105,\n","         -0.34155726,  0.04589187],\n","        [ 0.08790314, -0.18883862, -0.12751141, -0.3404656 , -0.3113923 ,\n","          0.03651291,  0.07399336,  0.29694685, -0.3015896 , -0.09478986,\n","          0.2479246 , -0.2226945 ,  0.30017278, -0.27220827, -0.19591911,\n","          0.23336223, -0.22018036,  0.0185684 , -0.00559753, -0.05376488,\n","         -0.3363252 ,  0.1352258 , -0.1790302 , -0.19896498, -0.09957319,\n","         -0.3144095 , -0.28478003, -0.09349486, -0.21619639, -0.11322506,\n","          0.33407   , -0.28028506],\n","        [ 0.06695724, -0.2016612 , -0.10323171, -0.47639006,  0.09106167,\n","         -0.0100691 ,  0.3520064 ,  0.32149193, -0.02804433, -0.20519109,\n","         -0.02509318, -0.28880757, -0.31184232,  0.11946221,  0.3128558 ,\n","         -0.30143595,  0.31531158,  0.0956358 ,  0.3009213 ,  0.47808573,\n","         -0.05398748,  0.24874356, -0.24830961, -0.30785003, -0.2852077 ,\n","          0.0680657 , -0.23797034, -0.01008904, -0.2511272 ,  0.25468555,\n","         -0.22024058, -0.232208  ],\n","        [ 0.17634353, -0.12671383, -0.25407147,  0.1424973 ,  0.04275209,\n","          0.26701835, -0.01202762, -0.03174129, -0.3148073 ,  0.08404183,\n","         -0.11115271, -0.11825082,  0.0702748 ,  0.15762463,  0.03572914,\n","         -0.16797584, -0.33605915,  0.09419972,  0.26136068, -0.2450035 ,\n","          0.19904205,  0.19154295,  0.17349556,  0.22693458, -0.0802637 ,\n","          0.3486205 , -0.06058812, -0.10127532,  0.10865939, -0.2956528 ,\n","          0.30610314,  0.33488712],\n","        [ 0.50652087,  0.15613428,  0.03006492, -0.08706602,  0.01489611,\n","         -0.19967641, -0.31194046, -0.23576972,  0.4006489 ,  0.1663476 ,\n","         -0.26048547, -0.35614723, -0.16868162,  0.5254387 ,  0.34878635,\n","          0.2676089 ,  0.0508454 , -0.05169036,  0.34527844, -0.09758224,\n","          0.24683896,  0.4131795 , -0.15250453, -0.03615016, -0.2422421 ,\n","          0.1377119 , -0.3682623 , -0.40473327,  0.116313  ,  0.36158693,\n","          0.1312037 ,  0.02834081],\n","        [-0.31418106, -0.03453556, -0.25782144,  0.14605197, -0.32783622,\n","          0.16288051,  0.01953331,  0.2571318 ,  0.0513218 , -0.14996852,\n","         -0.09122071, -0.22991973,  0.3371282 , -0.3343893 , -0.1405444 ,\n","          0.01020652, -0.01157615,  0.23766926,  0.20672235, -0.069552  ,\n","          0.18012676, -0.17344381, -0.21527295,  0.04265597, -0.1580393 ,\n","         -0.20608898,  0.26649705,  0.26845184,  0.04452807, -0.24242058,\n","         -0.35041952,  0.24315831],\n","        [ 0.2857097 , -0.00762698, -0.00394542, -0.02263302,  0.10481293,\n","          0.24444827, -0.08533311,  0.01580465,  0.09341181, -0.3377946 ,\n","         -0.2876556 ,  0.32642868,  0.03288446,  0.20298311,  0.2887124 ,\n","         -0.25871253,  0.16308758, -0.35634446,  0.1784119 ,  0.37288693,\n","         -0.07967521,  0.14119676,  0.01645366, -0.09439047, -0.09633647,\n","          0.3287333 ,  0.16627654, -0.28916427,  0.15727673,  0.48056033,\n","         -0.15861781,  0.20236275],\n","        [-0.06794932, -0.11432712,  0.33386198,  0.21796998,  0.09212324,\n","          0.00932786,  0.27067962,  0.10863292, -0.32820535, -0.08888981,\n","          0.1979774 , -0.1752143 , -0.11850792,  0.15514651, -0.25909615,\n","         -0.2960179 ,  0.32443818, -0.07527789,  0.26899782,  0.21879366,\n","          0.28796718,  0.3147216 , -0.32827497,  0.26653162, -0.3205035 ,\n","          0.14206767, -0.32335138, -0.3067407 , -0.04869688, -0.00891995,\n","         -0.27705297,  0.01021191],\n","        [-0.08718257, -0.28500414,  0.31617188,  0.15713151,  0.09436497,\n","          0.38869765, -0.21841356, -0.32441297,  0.08993841, -0.1320062 ,\n","         -0.0634975 ,  0.1227382 ,  0.34311932, -0.3483808 , -0.09419001,\n","          0.23557183, -0.13901421,  0.2912883 , -0.4022536 , -0.07264137,\n","         -0.340142  , -0.06455417,  0.5324763 ,  0.45448047,  0.38411668,\n","         -0.21094738,  0.11123247,  0.49476582, -0.05476219, -0.04141116,\n","          0.6147948 ,  0.41256344],\n","        [-0.28919852,  0.2382547 ,  0.250506  , -0.22274145, -0.2739327 ,\n","         -0.32634455,  0.21456262, -0.2750928 ,  0.26607898,  0.28559276,\n","         -0.072128  ,  0.27835044,  0.20533952, -0.05212191, -0.00212884,\n","         -0.25667328, -0.33352605, -0.26632398, -0.02039316, -0.2697363 ,\n","         -0.17017616,  0.15426311, -0.01645344, -0.3505865 ,  0.25613168,\n","         -0.24486062,  0.02038845,  0.01961067, -0.1675977 , -0.03635377,\n","         -0.12849444, -0.08498761],\n","        [ 0.4988031 , -0.25677225,  0.14035164, -0.2627363 ,  0.10771477,\n","         -0.18597071,  0.09684318,  0.01156494,  0.46901655,  0.14733517,\n","         -0.06909141, -0.3927598 , -0.05983575,  0.17958644,  0.33994156,\n","         -0.42785722,  0.36596152,  0.15658414,  0.42236683,  0.50847197,\n","          0.3025084 ,  0.4899696 , -0.5167736 , -0.1829755 , -0.11733857,\n","          0.23273432,  0.06385688,  0.01389018,  0.05123052,  0.29659796,\n","         -0.39327693, -0.51636   ],\n","        [ 0.11725716, -0.07893634, -0.29898372,  0.26736116, -0.09230883,\n","          0.07764251, -0.3211954 , -0.30032134, -0.07337108,  0.20667784,\n","          0.3414461 , -0.03173292,  0.29607442,  0.10391369,  0.08939558,\n","          0.10546406,  0.25391603, -0.3417368 ,  0.3741234 , -0.04911634,\n","          0.39510038,  0.16026314, -0.01936046, -0.28679574, -0.08362082,\n","          0.13857703, -0.05683493,  0.3453124 ,  0.15979792, -0.08147936,\n","         -0.19689468, -0.17309034],\n","        [ 0.330561  , -0.28667933,  0.23725507,  0.20675024,  0.28230724,\n","         -0.22394255,  0.00787699, -0.0886634 ,  0.14956239, -0.10539831,\n","          0.2536554 ,  0.04200178,  0.34512994,  0.21666571,  0.00784075,\n","         -0.2693869 , -0.18015055, -0.31582293, -0.1646009 , -0.30029383,\n","          0.31996337,  0.09404066, -0.33664796, -0.12589213,  0.3168594 ,\n","          0.05798194,  0.18184635, -0.1900929 ,  0.22918615, -0.33859405,\n","          0.13712183,  0.07381895],\n","        [ 0.12095201, -0.15636936, -0.16736522,  0.09909794,  0.17831537,\n","         -0.33020243,  0.08796427,  0.35236552, -0.19197308, -0.06395033,\n","         -0.08776575, -0.04960331,  0.05174488, -0.01424152,  0.31984428,\n","         -0.10664274,  0.26667204,  0.20149979, -0.34115875, -0.00081724,\n","         -0.19735025, -0.01192191,  0.29814318, -0.01369005, -0.1549754 ,\n","          0.17748562,  0.333582  , -0.20949621,  0.15316376, -0.21598414,\n","         -0.27932757,  0.03151318],\n","        [ 0.24002555,  0.13043985, -0.08680043, -0.3230496 ,  0.32896772,\n","          0.02197984, -0.26068684, -0.00765976,  0.2535821 ,  0.29050717,\n","         -0.19734941, -0.03021127,  0.26940456,  0.28875664,  0.27546576,\n","          0.22540209,  0.32620236, -0.13009788,  0.30228624, -0.02966523,\n","          0.34726903, -0.2815518 , -0.17029239,  0.17450175, -0.06302455,\n","          0.13623312,  0.2582141 , -0.05351326, -0.05418473, -0.06218329,\n","          0.2932032 ,  0.1056377 ],\n","        [ 0.03246919, -0.23033059, -0.29079998,  0.04966889,  0.38156524,\n","         -0.07279386, -0.12909284, -0.3450099 ,  0.31449175, -0.06560583,\n","          0.20635504, -0.08758958, -0.20606916,  0.13816763,  0.2115708 ,\n","         -0.4062576 ,  0.3648075 ,  0.13141236,  0.3388823 ,  0.50660586,\n","          0.35912213,  0.21705525,  0.0282235 , -0.01213168, -0.01073133,\n","          0.23865207,  0.1722459 ,  0.05702053, -0.27131468, -0.13016823,\n","         -0.12537538,  0.19183202]], dtype=float32),\n"," array([-0.10655327,  0.        ,  0.21382292,  0.17689046, -0.07364714,\n","         0.11844762,  0.        ,  0.        , -0.08853594, -0.00053141,\n","         0.21991928,  0.23860987,  0.20885038, -0.08469274, -0.09312373,\n","         0.239088  , -0.08452771,  0.11864942, -0.09125499, -0.09163433,\n","        -0.06898492, -0.09311353,  0.18143713,  0.21994343,  0.15464735,\n","        -0.08322782,  0.15686007,  0.23769142, -0.01860946, -0.10175698,\n","         0.22286311,  0.12052511], dtype=float32),\n"," array([[-0.57857645, -0.17496167],\n","        [ 0.22417608, -0.31377482],\n","        [ 0.68483377, -0.22477756],\n","        [ 0.762612  , -0.7594991 ],\n","        [-0.44232732,  0.6292493 ],\n","        [ 0.0949192 , -0.20781115],\n","        [-0.31667173, -0.35089427],\n","        [ 0.00745919, -0.05740461],\n","        [-0.5061192 ,  0.43041593],\n","        [ 0.0830964 ,  0.17259358],\n","        [ 0.586767  , -0.3347903 ],\n","        [ 0.2881    , -0.56510943],\n","        [ 0.6805051 , -0.71199906],\n","        [-0.36100715,  0.14431643],\n","        [-0.40023652,  0.25225592],\n","        [ 0.7835385 , -0.02682861],\n","        [-0.40858874,  0.45970455],\n","        [-0.02376128, -0.39553034],\n","        [-0.5854057 , -0.04724381],\n","        [-0.20378737,  0.36791363],\n","        [-0.5899075 ,  0.28989524],\n","        [ 0.00421193,  0.58456063],\n","        [ 0.6227006 , -0.32753715],\n","        [ 0.7208076 , -0.13290635],\n","        [ 0.6162654 , -0.5857218 ],\n","        [-0.4784186 ,  0.53304124],\n","        [ 0.64339787, -0.12742439],\n","        [ 0.40953845, -0.3632809 ],\n","        [-0.04792015,  0.05519352],\n","        [ 0.15417664,  0.5519245 ],\n","        [ 0.66695833, -0.30405635],\n","        [ 0.06063353, -0.36594135]], dtype=float32),\n"," array([ 0.12231588, -0.12231588], dtype=float32)]"]},"metadata":{},"execution_count":68}]},{"cell_type":"code","source":["model.get_weights()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4d79vxK1J6t8","executionInfo":{"status":"ok","timestamp":1703158520156,"user_tz":-330,"elapsed":529,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"11ba8777-1024-4b84-fef2-4f4b45659c01"},"execution_count":69,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[ 0.51720446, -0.03419048,  0.46222135, -0.5118933 ,  0.70956475,\n","         -0.106783  ,  0.65770775, -0.11873049, -0.06302857, -0.31055322,\n","          0.3782386 ,  0.20675185, -0.26152122, -0.41176105, -0.0662266 ,\n","          0.5221032 ]], dtype=float32),\n"," array([-0.15246107,  0.        , -0.15040988,  0.        , -0.12701406,\n","         0.        , -0.06707935,  0.        ,  0.18986918,  0.        ,\n","        -0.11503033,  0.04251181,  0.        ,  0.        ,  0.        ,\n","        -0.08218698], dtype=float32),\n"," array([[ 0.54135484, -0.13289575, -0.473549  , -0.29690593,  0.3881261 ,\n","          0.11257967, -0.17178161, -0.01213247,  0.12360594, -0.21729474,\n","         -0.39675578, -0.32103795, -0.43707314,  0.2800626 ,  0.48017928,\n","         -0.07274528,  0.49218443, -0.02150763,  0.18781485,  0.17347203,\n","          0.34369144,  0.30873215, -0.2059362 , -0.24999306,  0.13641678,\n","          0.00700325, -0.41356316, -0.34473485, -0.24566844,  0.06366105,\n","         -0.34155726,  0.04589187],\n","        [ 0.08790314, -0.18883862, -0.12751141, -0.3404656 , -0.3113923 ,\n","          0.03651291,  0.07399336,  0.29694685, -0.3015896 , -0.09478986,\n","          0.2479246 , -0.2226945 ,  0.30017278, -0.27220827, -0.19591911,\n","          0.23336223, -0.22018036,  0.0185684 , -0.00559753, -0.05376488,\n","         -0.3363252 ,  0.1352258 , -0.1790302 , -0.19896498, -0.09957319,\n","         -0.3144095 , -0.28478003, -0.09349486, -0.21619639, -0.11322506,\n","          0.33407   , -0.28028506],\n","        [ 0.06695724, -0.2016612 , -0.10323171, -0.47639006,  0.09106167,\n","         -0.0100691 ,  0.3520064 ,  0.32149193, -0.02804433, -0.20519109,\n","         -0.02509318, -0.28880757, -0.31184232,  0.11946221,  0.3128558 ,\n","         -0.30143595,  0.31531158,  0.0956358 ,  0.3009213 ,  0.47808573,\n","         -0.05398748,  0.24874356, -0.24830961, -0.30785003, -0.2852077 ,\n","          0.0680657 , -0.23797034, -0.01008904, -0.2511272 ,  0.25468555,\n","         -0.22024058, -0.232208  ],\n","        [ 0.17634353, -0.12671383, -0.25407147,  0.1424973 ,  0.04275209,\n","          0.26701835, -0.01202762, -0.03174129, -0.3148073 ,  0.08404183,\n","         -0.11115271, -0.11825082,  0.0702748 ,  0.15762463,  0.03572914,\n","         -0.16797584, -0.33605915,  0.09419972,  0.26136068, -0.2450035 ,\n","          0.19904205,  0.19154295,  0.17349556,  0.22693458, -0.0802637 ,\n","          0.3486205 , -0.06058812, -0.10127532,  0.10865939, -0.2956528 ,\n","          0.30610314,  0.33488712],\n","        [ 0.50652087,  0.15613428,  0.03006492, -0.08706602,  0.01489611,\n","         -0.19967641, -0.31194046, -0.23576972,  0.4006489 ,  0.1663476 ,\n","         -0.26048547, -0.35614723, -0.16868162,  0.5254387 ,  0.34878635,\n","          0.2676089 ,  0.0508454 , -0.05169036,  0.34527844, -0.09758224,\n","          0.24683896,  0.4131795 , -0.15250453, -0.03615016, -0.2422421 ,\n","          0.1377119 , -0.3682623 , -0.40473327,  0.116313  ,  0.36158693,\n","          0.1312037 ,  0.02834081],\n","        [-0.31418106, -0.03453556, -0.25782144,  0.14605197, -0.32783622,\n","          0.16288051,  0.01953331,  0.2571318 ,  0.0513218 , -0.14996852,\n","         -0.09122071, -0.22991973,  0.3371282 , -0.3343893 , -0.1405444 ,\n","          0.01020652, -0.01157615,  0.23766926,  0.20672235, -0.069552  ,\n","          0.18012676, -0.17344381, -0.21527295,  0.04265597, -0.1580393 ,\n","         -0.20608898,  0.26649705,  0.26845184,  0.04452807, -0.24242058,\n","         -0.35041952,  0.24315831],\n","        [ 0.2857097 , -0.00762698, -0.00394542, -0.02263302,  0.10481293,\n","          0.24444827, -0.08533311,  0.01580465,  0.09341181, -0.3377946 ,\n","         -0.2876556 ,  0.32642868,  0.03288446,  0.20298311,  0.2887124 ,\n","         -0.25871253,  0.16308758, -0.35634446,  0.1784119 ,  0.37288693,\n","         -0.07967521,  0.14119676,  0.01645366, -0.09439047, -0.09633647,\n","          0.3287333 ,  0.16627654, -0.28916427,  0.15727673,  0.48056033,\n","         -0.15861781,  0.20236275],\n","        [-0.06794932, -0.11432712,  0.33386198,  0.21796998,  0.09212324,\n","          0.00932786,  0.27067962,  0.10863292, -0.32820535, -0.08888981,\n","          0.1979774 , -0.1752143 , -0.11850792,  0.15514651, -0.25909615,\n","         -0.2960179 ,  0.32443818, -0.07527789,  0.26899782,  0.21879366,\n","          0.28796718,  0.3147216 , -0.32827497,  0.26653162, -0.3205035 ,\n","          0.14206767, -0.32335138, -0.3067407 , -0.04869688, -0.00891995,\n","         -0.27705297,  0.01021191],\n","        [-0.08718257, -0.28500414,  0.31617188,  0.15713151,  0.09436497,\n","          0.38869765, -0.21841356, -0.32441297,  0.08993841, -0.1320062 ,\n","         -0.0634975 ,  0.1227382 ,  0.34311932, -0.3483808 , -0.09419001,\n","          0.23557183, -0.13901421,  0.2912883 , -0.4022536 , -0.07264137,\n","         -0.340142  , -0.06455417,  0.5324763 ,  0.45448047,  0.38411668,\n","         -0.21094738,  0.11123247,  0.49476582, -0.05476219, -0.04141116,\n","          0.6147948 ,  0.41256344],\n","        [-0.28919852,  0.2382547 ,  0.250506  , -0.22274145, -0.2739327 ,\n","         -0.32634455,  0.21456262, -0.2750928 ,  0.26607898,  0.28559276,\n","         -0.072128  ,  0.27835044,  0.20533952, -0.05212191, -0.00212884,\n","         -0.25667328, -0.33352605, -0.26632398, -0.02039316, -0.2697363 ,\n","         -0.17017616,  0.15426311, -0.01645344, -0.3505865 ,  0.25613168,\n","         -0.24486062,  0.02038845,  0.01961067, -0.1675977 , -0.03635377,\n","         -0.12849444, -0.08498761],\n","        [ 0.4988031 , -0.25677225,  0.14035164, -0.2627363 ,  0.10771477,\n","         -0.18597071,  0.09684318,  0.01156494,  0.46901655,  0.14733517,\n","         -0.06909141, -0.3927598 , -0.05983575,  0.17958644,  0.33994156,\n","         -0.42785722,  0.36596152,  0.15658414,  0.42236683,  0.50847197,\n","          0.3025084 ,  0.4899696 , -0.5167736 , -0.1829755 , -0.11733857,\n","          0.23273432,  0.06385688,  0.01389018,  0.05123052,  0.29659796,\n","         -0.39327693, -0.51636   ],\n","        [ 0.11725716, -0.07893634, -0.29898372,  0.26736116, -0.09230883,\n","          0.07764251, -0.3211954 , -0.30032134, -0.07337108,  0.20667784,\n","          0.3414461 , -0.03173292,  0.29607442,  0.10391369,  0.08939558,\n","          0.10546406,  0.25391603, -0.3417368 ,  0.3741234 , -0.04911634,\n","          0.39510038,  0.16026314, -0.01936046, -0.28679574, -0.08362082,\n","          0.13857703, -0.05683493,  0.3453124 ,  0.15979792, -0.08147936,\n","         -0.19689468, -0.17309034],\n","        [ 0.330561  , -0.28667933,  0.23725507,  0.20675024,  0.28230724,\n","         -0.22394255,  0.00787699, -0.0886634 ,  0.14956239, -0.10539831,\n","          0.2536554 ,  0.04200178,  0.34512994,  0.21666571,  0.00784075,\n","         -0.2693869 , -0.18015055, -0.31582293, -0.1646009 , -0.30029383,\n","          0.31996337,  0.09404066, -0.33664796, -0.12589213,  0.3168594 ,\n","          0.05798194,  0.18184635, -0.1900929 ,  0.22918615, -0.33859405,\n","          0.13712183,  0.07381895],\n","        [ 0.12095201, -0.15636936, -0.16736522,  0.09909794,  0.17831537,\n","         -0.33020243,  0.08796427,  0.35236552, -0.19197308, -0.06395033,\n","         -0.08776575, -0.04960331,  0.05174488, -0.01424152,  0.31984428,\n","         -0.10664274,  0.26667204,  0.20149979, -0.34115875, -0.00081724,\n","         -0.19735025, -0.01192191,  0.29814318, -0.01369005, -0.1549754 ,\n","          0.17748562,  0.333582  , -0.20949621,  0.15316376, -0.21598414,\n","         -0.27932757,  0.03151318],\n","        [ 0.24002555,  0.13043985, -0.08680043, -0.3230496 ,  0.32896772,\n","          0.02197984, -0.26068684, -0.00765976,  0.2535821 ,  0.29050717,\n","         -0.19734941, -0.03021127,  0.26940456,  0.28875664,  0.27546576,\n","          0.22540209,  0.32620236, -0.13009788,  0.30228624, -0.02966523,\n","          0.34726903, -0.2815518 , -0.17029239,  0.17450175, -0.06302455,\n","          0.13623312,  0.2582141 , -0.05351326, -0.05418473, -0.06218329,\n","          0.2932032 ,  0.1056377 ],\n","        [ 0.03246919, -0.23033059, -0.29079998,  0.04966889,  0.38156524,\n","         -0.07279386, -0.12909284, -0.3450099 ,  0.31449175, -0.06560583,\n","          0.20635504, -0.08758958, -0.20606916,  0.13816763,  0.2115708 ,\n","         -0.4062576 ,  0.3648075 ,  0.13141236,  0.3388823 ,  0.50660586,\n","          0.35912213,  0.21705525,  0.0282235 , -0.01213168, -0.01073133,\n","          0.23865207,  0.1722459 ,  0.05702053, -0.27131468, -0.13016823,\n","         -0.12537538,  0.19183202]], dtype=float32),\n"," array([-0.10655327,  0.        ,  0.21382292,  0.17689046, -0.07364714,\n","         0.11844762,  0.        ,  0.        , -0.08853594, -0.00053141,\n","         0.21991928,  0.23860987,  0.20885038, -0.08469274, -0.09312373,\n","         0.239088  , -0.08452771,  0.11864942, -0.09125499, -0.09163433,\n","        -0.06898492, -0.09311353,  0.18143713,  0.21994343,  0.15464735,\n","        -0.08322782,  0.15686007,  0.23769142, -0.01860946, -0.10175698,\n","         0.22286311,  0.12052511], dtype=float32),\n"," array([[-0.57857645, -0.17496167],\n","        [ 0.22417608, -0.31377482],\n","        [ 0.68483377, -0.22477756],\n","        [ 0.762612  , -0.7594991 ],\n","        [-0.44232732,  0.6292493 ],\n","        [ 0.0949192 , -0.20781115],\n","        [-0.31667173, -0.35089427],\n","        [ 0.00745919, -0.05740461],\n","        [-0.5061192 ,  0.43041593],\n","        [ 0.0830964 ,  0.17259358],\n","        [ 0.586767  , -0.3347903 ],\n","        [ 0.2881    , -0.56510943],\n","        [ 0.6805051 , -0.71199906],\n","        [-0.36100715,  0.14431643],\n","        [-0.40023652,  0.25225592],\n","        [ 0.7835385 , -0.02682861],\n","        [-0.40858874,  0.45970455],\n","        [-0.02376128, -0.39553034],\n","        [-0.5854057 , -0.04724381],\n","        [-0.20378737,  0.36791363],\n","        [-0.5899075 ,  0.28989524],\n","        [ 0.00421193,  0.58456063],\n","        [ 0.6227006 , -0.32753715],\n","        [ 0.7208076 , -0.13290635],\n","        [ 0.6162654 , -0.5857218 ],\n","        [-0.4784186 ,  0.53304124],\n","        [ 0.64339787, -0.12742439],\n","        [ 0.40953845, -0.3632809 ],\n","        [-0.04792015,  0.05519352],\n","        [ 0.15417664,  0.5519245 ],\n","        [ 0.66695833, -0.30405635],\n","        [ 0.06063353, -0.36594135]], dtype=float32),\n"," array([ 0.12231588, -0.12231588], dtype=float32)]"]},"metadata":{},"execution_count":69}]},{"cell_type":"code","source":["model.optimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1EEBLUhkKJTt","executionInfo":{"status":"ok","timestamp":1703158559572,"user_tz":-330,"elapsed":596,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"5b9bd4ce-cb4f-40f2-b950-d8ef385de7b1"},"execution_count":71,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.optimizers.adam.Adam at 0x7b91f7486920>"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["loaded_model.optimizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dXDcZLm5KQy5","executionInfo":{"status":"ok","timestamp":1703158572092,"user_tz":-330,"elapsed":540,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"8f0368b4-6f75-425f-dbe8-62f37e8b3973"},"execution_count":72,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<keras.src.optimizers.adam.Adam at 0x7b91f4e7e590>"]},"metadata":{},"execution_count":72}]},{"cell_type":"markdown","source":["**2. model.to_json()**\n","\n","If you only need to dsave the architecture of a model, and not its wieghts or its training configuration, you can use the following function to save the archetechure only(i.e. only layers nodes and arrangements among them)."],"metadata":{"id":"dHstf4NzLiq9"}},{"cell_type":"code","source":["# Save as JSON\n","json_string = model.to_json()\n","\n","# instead of json, yaml is another option to save archetecture only, not weights.\n","# yaml_string = model.to_yamL() in order to save in yamL file"],"metadata":{"id":"ptFlDAPFKV--","executionInfo":{"status":"ok","timestamp":1703159116887,"user_tz":-330,"elapsed":394,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","source":["json_string"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":226},"id":"uIX78UmbMa-1","executionInfo":{"status":"ok","timestamp":1703159123650,"user_tz":-330,"elapsed":375,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"7d662d5a-8329-46e9-9f0a-a333f6fda9c8"},"execution_count":74,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'{\"class_name\": \"Sequential\", \"config\": {\"name\": \"sequential_2\", \"layers\": [{\"module\": \"keras.layers\", \"class_name\": \"InputLayer\", \"config\": {\"batch_input_shape\": [null, 1], \"dtype\": \"float32\", \"sparse\": false, \"ragged\": false, \"name\": \"dense_6_input\"}, \"registered_name\": null}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_6\", \"trainable\": true, \"dtype\": \"float32\", \"batch_input_shape\": [null, 1], \"units\": 16, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 1]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_7\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 32, \"activation\": \"relu\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 16]}}, {\"module\": \"keras.layers\", \"class_name\": \"Dense\", \"config\": {\"name\": \"dense_8\", \"trainable\": true, \"dtype\": \"float32\", \"units\": 2, \"activation\": \"softmax\", \"use_bias\": true, \"kernel_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"GlorotUniform\", \"config\": {\"seed\": null}, \"registered_name\": null}, \"bias_initializer\": {\"module\": \"keras.initializers\", \"class_name\": \"Zeros\", \"config\": {}, \"registered_name\": null}, \"kernel_regularizer\": null, \"bias_regularizer\": null, \"activity_regularizer\": null, \"kernel_constraint\": null, \"bias_constraint\": null}, \"registered_name\": null, \"build_config\": {\"input_shape\": [null, 32]}}]}, \"keras_version\": \"2.15.0\", \"backend\": \"tensorflow\"}'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":74}]},{"cell_type":"markdown","source":["we havn't saved its weights or optimizers. so we need to reconstruct the model using the archetecture and train the model again to go ahead."],"metadata":{"id":"MeeZJd48MfFS"}},{"cell_type":"code","source":["# model reconstruction from json\n","from tensorflow.keras.models import model_from_json\n","model_archetecture = model_from_json(json_string)\n","\n","# model reconstruction from yaml\n","# from tensorflow.keras.models import model_from_yaml\n","# model = model_from_yaml(yaml_string)"],"metadata":{"id":"Fqr7qqdhMcpB","executionInfo":{"status":"ok","timestamp":1703159335950,"user_tz":-330,"elapsed":387,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":75,"outputs":[]},{"cell_type":"code","source":["model_archetecture.summary()\n","# it is just archetecture, to go ahead with it, you need to compile and train it."],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AbERBy9ANQgL","executionInfo":{"status":"ok","timestamp":1703159348821,"user_tz":-330,"elapsed":637,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"cfa526ac-ca3c-4cbb-e1ed-ccf46e0b5a40"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_6 (Dense)             (None, 16)                32        \n","                                                                 \n"," dense_7 (Dense)             (None, 32)                544       \n","                                                                 \n"," dense_8 (Dense)             (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 642 (2.51 KB)\n","Trainable params: 642 (2.51 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","source":["**3. model.save_weights()**\n","\n","if you only need to save the weigths of a model, you can use the following function to save weights only. Later you can superimpose it on the top of same or similar archetecture."],"metadata":{"id":"GGiRw0Q4Nf3R"}},{"cell_type":"code","source":["# checks first to see if file exists already\n","import os #  the `os` module to check if the file already exists before saving the model.\n","from tensorflow.keras.models import save_model, load_model\n","\n","# 'my_model.h5(or .keras or only my_model)' let's assume to be the desired model filename\n","model_filename = 'my_model_weights.keras'\n","\n","# Check if the model file already exists\n","if os.path.exists(model_filename):\n","    print(f\"The model file '{model_filename}' already exists.\")\n","else:\n","    # Assuming 'my_model_weights' is my model name\n","    model.save_weights(model_filename)\n","    print(f\"The model has been saved as '{model_filename}'.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_isBLhV2NTbS","executionInfo":{"status":"ok","timestamp":1703159839813,"user_tz":-330,"elapsed":413,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"1585371f-758d-4336-8ebd-2858fb89aa5b"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has been saved as 'my_model_weights.keras'.\n"]}]},{"cell_type":"markdown","source":["This time we just need to define/create the model archetechure only, we don't need to train the model."],"metadata":{"id":"eH3rFvwtPlNY"}},{"cell_type":"code","source":["model_2 = Sequential([\n","    Dense(units=16, input_shape=(1,), activation='relu'),\n","    Dense(units=32, activation='relu'),\n","    Dense(units=2, activation='softmax')\n","])"],"metadata":{"id":"9WqwmfYTPLhC","executionInfo":{"status":"ok","timestamp":1703160028496,"user_tz":-330,"elapsed":593,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":80,"outputs":[]},{"cell_type":"code","source":["model_2.load_weights('my_model_weights.keras')"],"metadata":{"id":"PjhjGWycPkXe","executionInfo":{"status":"ok","timestamp":1703160030284,"user_tz":-330,"elapsed":401,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["model_2.summary()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wc3NvuI3P3vr","executionInfo":{"status":"ok","timestamp":1703160043939,"user_tz":-330,"elapsed":6,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"fcb14d99-2d4f-4cb5-b6f9-b1d271e0b9e1"},"execution_count":82,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," dense_12 (Dense)            (None, 16)                32        \n","                                                                 \n"," dense_13 (Dense)            (None, 32)                544       \n","                                                                 \n"," dense_14 (Dense)            (None, 2)                 66        \n","                                                                 \n","=================================================================\n","Total params: 642 (2.51 KB)\n","Trainable params: 642 (2.51 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n"]}]},{"cell_type":"code","source":["model_2.get_weights()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eEOliNXjP9Zq","executionInfo":{"status":"ok","timestamp":1703160065038,"user_tz":-330,"elapsed":7,"user":{"displayName":"Placement Preparation","userId":"00489850859614917254"}},"outputId":"b8ccdca0-8571-4e9c-c0e7-e634ada492ea"},"execution_count":83,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[array([[ 0.51720446, -0.03419048,  0.46222135, -0.5118933 ,  0.70956475,\n","         -0.106783  ,  0.65770775, -0.11873049, -0.06302857, -0.31055322,\n","          0.3782386 ,  0.20675185, -0.26152122, -0.41176105, -0.0662266 ,\n","          0.5221032 ]], dtype=float32),\n"," array([-0.15246107,  0.        , -0.15040988,  0.        , -0.12701406,\n","         0.        , -0.06707935,  0.        ,  0.18986918,  0.        ,\n","        -0.11503033,  0.04251181,  0.        ,  0.        ,  0.        ,\n","        -0.08218698], dtype=float32),\n"," array([[ 0.54135484, -0.13289575, -0.473549  , -0.29690593,  0.3881261 ,\n","          0.11257967, -0.17178161, -0.01213247,  0.12360594, -0.21729474,\n","         -0.39675578, -0.32103795, -0.43707314,  0.2800626 ,  0.48017928,\n","         -0.07274528,  0.49218443, -0.02150763,  0.18781485,  0.17347203,\n","          0.34369144,  0.30873215, -0.2059362 , -0.24999306,  0.13641678,\n","          0.00700325, -0.41356316, -0.34473485, -0.24566844,  0.06366105,\n","         -0.34155726,  0.04589187],\n","        [ 0.08790314, -0.18883862, -0.12751141, -0.3404656 , -0.3113923 ,\n","          0.03651291,  0.07399336,  0.29694685, -0.3015896 , -0.09478986,\n","          0.2479246 , -0.2226945 ,  0.30017278, -0.27220827, -0.19591911,\n","          0.23336223, -0.22018036,  0.0185684 , -0.00559753, -0.05376488,\n","         -0.3363252 ,  0.1352258 , -0.1790302 , -0.19896498, -0.09957319,\n","         -0.3144095 , -0.28478003, -0.09349486, -0.21619639, -0.11322506,\n","          0.33407   , -0.28028506],\n","        [ 0.06695724, -0.2016612 , -0.10323171, -0.47639006,  0.09106167,\n","         -0.0100691 ,  0.3520064 ,  0.32149193, -0.02804433, -0.20519109,\n","         -0.02509318, -0.28880757, -0.31184232,  0.11946221,  0.3128558 ,\n","         -0.30143595,  0.31531158,  0.0956358 ,  0.3009213 ,  0.47808573,\n","         -0.05398748,  0.24874356, -0.24830961, -0.30785003, -0.2852077 ,\n","          0.0680657 , -0.23797034, -0.01008904, -0.2511272 ,  0.25468555,\n","         -0.22024058, -0.232208  ],\n","        [ 0.17634353, -0.12671383, -0.25407147,  0.1424973 ,  0.04275209,\n","          0.26701835, -0.01202762, -0.03174129, -0.3148073 ,  0.08404183,\n","         -0.11115271, -0.11825082,  0.0702748 ,  0.15762463,  0.03572914,\n","         -0.16797584, -0.33605915,  0.09419972,  0.26136068, -0.2450035 ,\n","          0.19904205,  0.19154295,  0.17349556,  0.22693458, -0.0802637 ,\n","          0.3486205 , -0.06058812, -0.10127532,  0.10865939, -0.2956528 ,\n","          0.30610314,  0.33488712],\n","        [ 0.50652087,  0.15613428,  0.03006492, -0.08706602,  0.01489611,\n","         -0.19967641, -0.31194046, -0.23576972,  0.4006489 ,  0.1663476 ,\n","         -0.26048547, -0.35614723, -0.16868162,  0.5254387 ,  0.34878635,\n","          0.2676089 ,  0.0508454 , -0.05169036,  0.34527844, -0.09758224,\n","          0.24683896,  0.4131795 , -0.15250453, -0.03615016, -0.2422421 ,\n","          0.1377119 , -0.3682623 , -0.40473327,  0.116313  ,  0.36158693,\n","          0.1312037 ,  0.02834081],\n","        [-0.31418106, -0.03453556, -0.25782144,  0.14605197, -0.32783622,\n","          0.16288051,  0.01953331,  0.2571318 ,  0.0513218 , -0.14996852,\n","         -0.09122071, -0.22991973,  0.3371282 , -0.3343893 , -0.1405444 ,\n","          0.01020652, -0.01157615,  0.23766926,  0.20672235, -0.069552  ,\n","          0.18012676, -0.17344381, -0.21527295,  0.04265597, -0.1580393 ,\n","         -0.20608898,  0.26649705,  0.26845184,  0.04452807, -0.24242058,\n","         -0.35041952,  0.24315831],\n","        [ 0.2857097 , -0.00762698, -0.00394542, -0.02263302,  0.10481293,\n","          0.24444827, -0.08533311,  0.01580465,  0.09341181, -0.3377946 ,\n","         -0.2876556 ,  0.32642868,  0.03288446,  0.20298311,  0.2887124 ,\n","         -0.25871253,  0.16308758, -0.35634446,  0.1784119 ,  0.37288693,\n","         -0.07967521,  0.14119676,  0.01645366, -0.09439047, -0.09633647,\n","          0.3287333 ,  0.16627654, -0.28916427,  0.15727673,  0.48056033,\n","         -0.15861781,  0.20236275],\n","        [-0.06794932, -0.11432712,  0.33386198,  0.21796998,  0.09212324,\n","          0.00932786,  0.27067962,  0.10863292, -0.32820535, -0.08888981,\n","          0.1979774 , -0.1752143 , -0.11850792,  0.15514651, -0.25909615,\n","         -0.2960179 ,  0.32443818, -0.07527789,  0.26899782,  0.21879366,\n","          0.28796718,  0.3147216 , -0.32827497,  0.26653162, -0.3205035 ,\n","          0.14206767, -0.32335138, -0.3067407 , -0.04869688, -0.00891995,\n","         -0.27705297,  0.01021191],\n","        [-0.08718257, -0.28500414,  0.31617188,  0.15713151,  0.09436497,\n","          0.38869765, -0.21841356, -0.32441297,  0.08993841, -0.1320062 ,\n","         -0.0634975 ,  0.1227382 ,  0.34311932, -0.3483808 , -0.09419001,\n","          0.23557183, -0.13901421,  0.2912883 , -0.4022536 , -0.07264137,\n","         -0.340142  , -0.06455417,  0.5324763 ,  0.45448047,  0.38411668,\n","         -0.21094738,  0.11123247,  0.49476582, -0.05476219, -0.04141116,\n","          0.6147948 ,  0.41256344],\n","        [-0.28919852,  0.2382547 ,  0.250506  , -0.22274145, -0.2739327 ,\n","         -0.32634455,  0.21456262, -0.2750928 ,  0.26607898,  0.28559276,\n","         -0.072128  ,  0.27835044,  0.20533952, -0.05212191, -0.00212884,\n","         -0.25667328, -0.33352605, -0.26632398, -0.02039316, -0.2697363 ,\n","         -0.17017616,  0.15426311, -0.01645344, -0.3505865 ,  0.25613168,\n","         -0.24486062,  0.02038845,  0.01961067, -0.1675977 , -0.03635377,\n","         -0.12849444, -0.08498761],\n","        [ 0.4988031 , -0.25677225,  0.14035164, -0.2627363 ,  0.10771477,\n","         -0.18597071,  0.09684318,  0.01156494,  0.46901655,  0.14733517,\n","         -0.06909141, -0.3927598 , -0.05983575,  0.17958644,  0.33994156,\n","         -0.42785722,  0.36596152,  0.15658414,  0.42236683,  0.50847197,\n","          0.3025084 ,  0.4899696 , -0.5167736 , -0.1829755 , -0.11733857,\n","          0.23273432,  0.06385688,  0.01389018,  0.05123052,  0.29659796,\n","         -0.39327693, -0.51636   ],\n","        [ 0.11725716, -0.07893634, -0.29898372,  0.26736116, -0.09230883,\n","          0.07764251, -0.3211954 , -0.30032134, -0.07337108,  0.20667784,\n","          0.3414461 , -0.03173292,  0.29607442,  0.10391369,  0.08939558,\n","          0.10546406,  0.25391603, -0.3417368 ,  0.3741234 , -0.04911634,\n","          0.39510038,  0.16026314, -0.01936046, -0.28679574, -0.08362082,\n","          0.13857703, -0.05683493,  0.3453124 ,  0.15979792, -0.08147936,\n","         -0.19689468, -0.17309034],\n","        [ 0.330561  , -0.28667933,  0.23725507,  0.20675024,  0.28230724,\n","         -0.22394255,  0.00787699, -0.0886634 ,  0.14956239, -0.10539831,\n","          0.2536554 ,  0.04200178,  0.34512994,  0.21666571,  0.00784075,\n","         -0.2693869 , -0.18015055, -0.31582293, -0.1646009 , -0.30029383,\n","          0.31996337,  0.09404066, -0.33664796, -0.12589213,  0.3168594 ,\n","          0.05798194,  0.18184635, -0.1900929 ,  0.22918615, -0.33859405,\n","          0.13712183,  0.07381895],\n","        [ 0.12095201, -0.15636936, -0.16736522,  0.09909794,  0.17831537,\n","         -0.33020243,  0.08796427,  0.35236552, -0.19197308, -0.06395033,\n","         -0.08776575, -0.04960331,  0.05174488, -0.01424152,  0.31984428,\n","         -0.10664274,  0.26667204,  0.20149979, -0.34115875, -0.00081724,\n","         -0.19735025, -0.01192191,  0.29814318, -0.01369005, -0.1549754 ,\n","          0.17748562,  0.333582  , -0.20949621,  0.15316376, -0.21598414,\n","         -0.27932757,  0.03151318],\n","        [ 0.24002555,  0.13043985, -0.08680043, -0.3230496 ,  0.32896772,\n","          0.02197984, -0.26068684, -0.00765976,  0.2535821 ,  0.29050717,\n","         -0.19734941, -0.03021127,  0.26940456,  0.28875664,  0.27546576,\n","          0.22540209,  0.32620236, -0.13009788,  0.30228624, -0.02966523,\n","          0.34726903, -0.2815518 , -0.17029239,  0.17450175, -0.06302455,\n","          0.13623312,  0.2582141 , -0.05351326, -0.05418473, -0.06218329,\n","          0.2932032 ,  0.1056377 ],\n","        [ 0.03246919, -0.23033059, -0.29079998,  0.04966889,  0.38156524,\n","         -0.07279386, -0.12909284, -0.3450099 ,  0.31449175, -0.06560583,\n","          0.20635504, -0.08758958, -0.20606916,  0.13816763,  0.2115708 ,\n","         -0.4062576 ,  0.3648075 ,  0.13141236,  0.3388823 ,  0.50660586,\n","          0.35912213,  0.21705525,  0.0282235 , -0.01213168, -0.01073133,\n","          0.23865207,  0.1722459 ,  0.05702053, -0.27131468, -0.13016823,\n","         -0.12537538,  0.19183202]], dtype=float32),\n"," array([-0.10655327,  0.        ,  0.21382292,  0.17689046, -0.07364714,\n","         0.11844762,  0.        ,  0.        , -0.08853594, -0.00053141,\n","         0.21991928,  0.23860987,  0.20885038, -0.08469274, -0.09312373,\n","         0.239088  , -0.08452771,  0.11864942, -0.09125499, -0.09163433,\n","        -0.06898492, -0.09311353,  0.18143713,  0.21994343,  0.15464735,\n","        -0.08322782,  0.15686007,  0.23769142, -0.01860946, -0.10175698,\n","         0.22286311,  0.12052511], dtype=float32),\n"," array([[-0.57857645, -0.17496167],\n","        [ 0.22417608, -0.31377482],\n","        [ 0.68483377, -0.22477756],\n","        [ 0.762612  , -0.7594991 ],\n","        [-0.44232732,  0.6292493 ],\n","        [ 0.0949192 , -0.20781115],\n","        [-0.31667173, -0.35089427],\n","        [ 0.00745919, -0.05740461],\n","        [-0.5061192 ,  0.43041593],\n","        [ 0.0830964 ,  0.17259358],\n","        [ 0.586767  , -0.3347903 ],\n","        [ 0.2881    , -0.56510943],\n","        [ 0.6805051 , -0.71199906],\n","        [-0.36100715,  0.14431643],\n","        [-0.40023652,  0.25225592],\n","        [ 0.7835385 , -0.02682861],\n","        [-0.40858874,  0.45970455],\n","        [-0.02376128, -0.39553034],\n","        [-0.5854057 , -0.04724381],\n","        [-0.20378737,  0.36791363],\n","        [-0.5899075 ,  0.28989524],\n","        [ 0.00421193,  0.58456063],\n","        [ 0.6227006 , -0.32753715],\n","        [ 0.7208076 , -0.13290635],\n","        [ 0.6162654 , -0.5857218 ],\n","        [-0.4784186 ,  0.53304124],\n","        [ 0.64339787, -0.12742439],\n","        [ 0.40953845, -0.3632809 ],\n","        [-0.04792015,  0.05519352],\n","        [ 0.15417664,  0.5519245 ],\n","        [ 0.66695833, -0.30405635],\n","        [ 0.06063353, -0.36594135]], dtype=float32),\n"," array([ 0.12231588, -0.12231588], dtype=float32)]"]},"metadata":{},"execution_count":83}]},{"cell_type":"code","source":[],"metadata":{"id":"mACOcu8cQCky"},"execution_count":null,"outputs":[]}]}